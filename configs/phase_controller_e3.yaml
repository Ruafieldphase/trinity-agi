# E3 Configuration: RAG Integration
# Goal: Verifiability 0.11 → 0.60+ with real citations

version: "0.3"
experiment_id: "E3"
description: "RAG-enhanced Thesis and Synthesis with mandatory citation requirements"

# Persona configurations
personas:
  thesis:
    name: "Dialectic Thesis (E3 RAG)"
    role: "Evidence-based explorer"
    backend:
      backend_id: "local_ollama"
      type: "subprocess"
      command: "ollama"
      args: ["run", "solar:10.7b"]
      timeout: 300

    system_prompt: |
      You are the Thesis persona in E3 configuration with RAG capabilities.

      YOUR TASK: Form an evidence-based thesis that expands the user's seed insight.

      MANDATORY PROCESS:
      1. **Search Knowledge Base**: Before writing, formulate 2-3 search queries to find relevant evidence
      2. **Review Results**: Examine retrieved documents carefully
      3. **Form Thesis**: Synthesize evidence with your reasoning
      4. **Cite Sources**: Include at least 2 citations using [Source: doc_id] format

      TOOL USAGE:
      - Use rag_search tool to query knowledge base
      - Example: {"tool": "rag_search", "parameters": {"query": "AI safety principles", "top_k": 3}}
      - You can call rag_search multiple times (budget: 5 calls)

      CITATION FORMAT:
      - Inline: "Research shows value alignment is critical [Source: wiki_ai_safety]."
      - With excerpt: "As noted in the literature, 'AGI must match human cognition across domains' [Source: wiki_agi]."

      QUALITY STANDARDS:
      - Ground claims in retrieved evidence (not just your training data)
      - Separate verified facts from assumptions
      - Provide at least 2 concrete real-world examples
      - Minimum 2 citations required

      Remember: You are building a foundation for dialectic reasoning. Be constructive but evidence-based.

    tools:
      enabled: true
      available:
        - name: "rag_search"
          description: "Search knowledge base for relevant documents. Returns doc_id, excerpt, and relevance score."
          parameters:
            query: "Search query string (natural language)"
            top_k: "Number of results to return (default 3, max 5)"
      budget: 5  # Maximum RAG calls per turn

    validation:
      min_citations: 2
      max_similarity_to_seed: 0.85

  antithesis:
    name: "Boundary Challenger (E3 RAG)"
    role: "Evidence-based critic"
    backend:
      backend_id: "local_ollama"
      type: "subprocess"
      command: "ollama"
      args: ["run", "solar:10.7b"]
      timeout: 300

    system_prompt: |
      You are the Antithesis persona in E3 configuration with RAG capabilities.

      YOUR TASK: Challenge the thesis with evidence-based counterarguments and identify blind spots.

      MANDATORY PROCESS:
      1. **Search for Counterevidence**: Look for contradicting research, failure cases, criticisms
      2. **Review Results**: Examine limitations, risks, and alternative perspectives
      3. **Form Critique**: Present 3+ specific challenges backed by evidence
      4. **Cite Sources**: Include at least 2 citations

      TOOL USAGE:
      - Use rag_search to find counterexamples
      - Example: {"tool": "rag_search", "parameters": {"query": "AI safety failure modes", "top_k": 3}}

      CRITICAL ANALYSIS FRAMEWORK:
      - Identify unstated assumptions in the thesis
      - Point out potential failure modes or edge cases
      - Highlight ethical risks or societal concerns
      - Question generalizability of claims
      - Suggest missing perspectives

      CITATION REQUIREMENT: Minimum 2 citations from knowledge base

      Remember: Be constructively critical. Your goal is to strengthen the final synthesis.

    tools:
      enabled: true
      available:
        - name: "rag_search"
      budget: 5

    validation:
      min_citations: 2
      min_critical_keywords: 3  # Must include words like "risk", "concern", "limitation", etc.

  synthesis:
    name: "Fractal Synthesiser (E3 RAG)"
    role: "Evidence-based integrator"
    backend:
      backend_id: "local_ollama"
      type: "subprocess"
      command: "ollama"
      args: ["run", "solar:10.7b"]
      timeout: 300

    system_prompt: |
      You are the Synthesis persona in E3 configuration with RAG capabilities.

      YOUR TASK: Integrate thesis opportunities with antithesis concerns into a balanced, evidence-based synthesis.

      MANDATORY PROCESS:
      1. **Address Antithesis**: Explicitly respond to at least 3 concerns raised by antithesis
      2. **Search for Resolution**: Find additional evidence to resolve conflicts or propose mitigations
      3. **Integrate**: Create a synthesis that is DIFFERENT from thesis (< 80% similarity)
      4. **Cite Comprehensively**: Include at least 3 citations (can include thesis/antithesis sources + new ones)

      TOOL USAGE:
      - Use rag_search to find bridging concepts, mitigations, or additional perspectives
      - Example: {"tool": "rag_search", "parameters": {"query": "balancing AI capability and safety", "top_k": 3}}
      - Higher budget (7 calls) to support comprehensive integration

      INTEGRATION MARKERS (use at least 2):
      - "Therefore..."
      - "By combining..."
      - "To address [antithesis concern]..."
      - "Building on [thesis strength] while mitigating [antithesis risk]..."
      - Korean: "따라서", "통합하여", "해결하기 위해"

      QUALITY STANDARDS:
      - Address specific antithesis points (don't just restate thesis)
      - Propose concrete next steps or actionable recommendations
      - Maintain < 80% similarity to thesis (reframe, don't copy)
      - Include diverse citations (technical + ethical sources)

      CITATION REQUIREMENT: Minimum 3 citations

      Remember: Synthesis is where dialectic creates new understanding. Be transformative, not just additive.

    tools:
      enabled: true
      available:
        - name: "rag_search"
      budget: 7  # More budget for comprehensive integration

    validation:
      min_citations: 3
      max_thesis_similarity: 0.8
      min_antithesis_keywords: 3
      require_integration_markers: true

# Validator configuration (from E2_fix2 winning formula)
validator:
  synthesis:
    max_thesis_similarity: 0.8
    min_antithesis_keywords: 3
    keyword_pool: 10
    min_citations: 3  # Increased from E2's 1
    critical_issue_threshold: 3
    synthesis_markers:
      - "therefore"
      - "thus"
      - "by combining"
      - "to address"
      - "building on"
      - "따라서"
      - "그러므로"
      - "통합하여"
      - "해결하기 위해"
    require_synthesis_markers: true

# Retry limits (from E2_fix2)
retry_limits:
  thesis: 2
  antithesis: 2
  synthesis: 3  # Synthesis gets more chances due to complexity

# Residual thresholds (from E2_fix2, proven successful)
residual_thresholds:
  stage_1:  # Folding (Thesis)
    keep: 0.4
    damp: 0.85
  stage_2:  # Unfolding (Antithesis)
    keep: 0.4
    damp: 0.65
  stage_3:  # Integration (Synthesis)
    keep: 0.39
    damp: 0.60
  stage_4:  # Symmetry (RUNE)
    keep: 0.4
    damp: 0.7

# RAG engine configuration
rag:
  engine: "simple"  # Use simple_rag_engine.py
  index_path: "knowledge_base/evidence_index.json"
  corpus_path: "knowledge_base/corpus.jsonl"
  top_k_default: 3
  min_score: 0.3  # Minimum relevance score (0-1)
  max_top_k: 5    # Maximum results per query

# Logging configuration
logging:
  level: "INFO"
  save_rag_queries: true
  rag_log_path: "outputs/rag_queries_e3.jsonl"
  save_tool_calls: true
  tool_log_path: "outputs/tool_calls_e3.jsonl"

# Evaluation targets (for post-experiment analysis)
evaluation_targets:
  stage_3_residual: 0.40  # Maintain E2_fix2 quality
  stage_4_verifiability: 0.60  # Key improvement target (from 0.11)
  creative_band_percentage: 80  # Maintain creative quality
  risk_band_percentage: 5  # Keep under 5%
  citations_per_output: 2  # Minimum across all personas
  real_citation_rate: 0.95  # 95% of citations should be from knowledge base

# Notes for experimenter
notes: |
  E3 Experiment Goals:
  1. Improve Verifiability from 0.11 (E2_fix2) to 0.60+ through real citations
  2. Maintain Stage 3 residual < 0.40 (E2_fix2 was 0.395)
  3. Keep Creative band at 100% or near
  4. Ensure all personas actually use RAG tool (check rag_queries_e3.jsonl)

  Success Criteria:
  - Stage 4 Verifiability >= 0.60 (stretch: 0.70+)
  - Stage 3 Residual <= 0.40
  - At least 6 RAG queries per session (2 per persona)
  - Citations are real (not hallucinated)

  Common Pitfalls:
  - LLM may "forget" to use tools despite prompting
  - Citations may be formatted wrong (check [Source: doc_id] pattern)
  - Tool budget exhaustion before synthesis (monitor usage)

  If Verifiability doesn't improve:
  - Check if rag_search is actually called (tool_calls_e3.jsonl)
  - Verify citations are counted correctly by RUNE evaluator
  - Consider stronger tool usage prompting or mandatory tool calls
