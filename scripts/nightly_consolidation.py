#!/usr/bin/env python3
"""
Nightly Consolidation - Hippocampus Long-term Memory Consolidation
ë§¤ì¼ ìƒˆë²½ì— ì‹¤í–‰ë˜ëŠ” ìë™ consolidation ì‘ì—…

ì‘ë™ ë°©ì‹:
1. Hippocampus ì¸ìŠ¤í„´ìŠ¤ ë¡œë“œ
2. ë‹¨ê¸° ê¸°ì–µ â†’ ì¥ê¸° ê¸°ì–µ ë³€í™˜
3. ê²°ê³¼ ì €ì¥ ë° ë¦¬í¬íŠ¸ ìƒì„±
"""

import json
import sys
from datetime import datetime
from pathlib import Path
import logging
from workspace_root import get_workspace_root

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = get_workspace_root()
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "fdo_agi_repo"))

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        from fdo_agi_repo.copilot.hippocampus import Hippocampus
    except ImportError:
        logger.error("âŒ Hippocampus ëª¨ë“ˆì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    workspace_root = project_root
    outputs_dir = workspace_root / "outputs"
    outputs_dir.mkdir(exist_ok=True)
    
    logger.info("ğŸŒ™ Nightly Consolidation ì‹œì‘...")
    logger.info(f"ğŸ“ Workspace: {workspace_root}")
    
    # Hippocampus ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    try:
        hippo = Hippocampus(workspace_root)
        logger.info("âœ… Hippocampus ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ Hippocampus ë¡œë“œ ì‹¤íŒ¨: {e}")
        sys.exit(1)
    
    # Consolidation ì‹¤í–‰
    try:
        logger.info("ğŸ§  Consolidation ì‹¤í–‰ ì¤‘...")
        result = hippo.consolidate(force=False)
        
        logger.info(f"âœ… Consolidation ì™„ë£Œ:")
        logger.info(f"   - Total: {result.get('total', 0)}")
        logger.info(f"   - Episodic: {result.get('episodic', 0)}")
        logger.info(f"   - Semantic: {result.get('semantic', 0)}")
        logger.info(f"   - Procedural: {result.get('procedural', 0)}")
        
        # ê²°ê³¼ ì €ì¥
        result_data = {
            "timestamp": datetime.now().isoformat(),
            "consolidation_result": result,
            "status": "success"
        }
        
        # JSON ì €ì¥
        result_file = outputs_dir / "consolidation_result_latest.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {result_file}")
        
        # Markdown ë¦¬í¬íŠ¸ ìƒì„±
        report_file = outputs_dir / "consolidation_report_latest.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# ğŸ§  Nightly Consolidation Report\n\n")
            f.write(f"**ì‹¤í–‰ ì‹œê°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"## ğŸ“Š Consolidation ê²°ê³¼\n\n")
            f.write(f"- **Total Consolidated**: {result.get('total', 0)}\n")
            f.write(f"- **Episodic Memories**: {result.get('episodic', 0)}\n")
            f.write(f"- **Semantic Memories**: {result.get('semantic', 0)}\n")
            f.write(f"- **Procedural Memories**: {result.get('procedural', 0)}\n\n")
            f.write(f"## âœ… ìƒíƒœ\n\n")
            f.write(f"- **Status**: Success\n")
            f.write(f"- **Timestamp**: {result_data['timestamp']}\n\n")
            f.write(f"---\n\n")
            f.write(f"*ìë™ ìƒì„±: Nightly Consolidation System*\n")
        
        logger.info(f"ğŸ“„ ë¦¬í¬íŠ¸ ìƒì„±: {report_file}")
        logger.info("ğŸ‰ Nightly Consolidation ì™„ë£Œ!")
        
        return 0
    
    except Exception as e:
        logger.error(f"âŒ Consolidation ì‹¤íŒ¨: {e}")
        
        # ì—ëŸ¬ ì €ì¥
        error_data = {
            "timestamp": datetime.now().isoformat(),
            "error": str(e),
            "status": "failed"
        }
        
        error_file = outputs_dir / "consolidation_error_latest.json"
        with open(error_file, 'w', encoding='utf-8') as f:
            json.dump(error_data, f, indent=2, ensure_ascii=False)
        
        return 1

if __name__ == "__main__":
    sys.exit(main())
