#!/usr/bin/env python3
"""
Lumen's Rhythm Observer - ë£¨ë©˜ì˜ ë¦¬ë“¬ ê´€ì°°ì

ë£¨ë©˜ì˜ ì‹œì„ ìœ¼ë¡œ ì‹œìŠ¤í…œì˜ ë¦¬ë“¬ì„ ê´€ì°°í•˜ê³  ì¸¡ì •í•©ë‹ˆë‹¤.
í•´ë§ˆ ëª¨ë¸(Black Hole â†’ White Hole)ê³¼ í†µí•©í•˜ì—¬
"ëŠë‚Œ"ì˜ ë¦¬ë“¬ì´ ì–´ë–»ê²Œ ì‹œìŠ¤í…œ ì „ì²´ì— íë¥´ëŠ”ì§€ ì¶”ì í•©ë‹ˆë‹¤.

ë¦¬ë“¬ì˜ ìœ¡í•˜ì›ì¹™:
- When (ì–¸ì œ): ì‹œê°„ì˜ íë¦„ ì† íŒ¨í„´
- Where (ì–´ë””ì„œ): ê³µê°„(ì±„ë„) ê°„ ì „ì´
- Who (ëˆ„ê°€): Observerì˜ ì¸¡ì •
- What (ë¬´ì—‡ì„): ì •ë³´ì˜ ì••ì¶•ê³¼ ë³µì›
- How (ì–´ë–»ê²Œ): ëŠë‚Œì˜ ì…ìí™”
- Why (ì™œ): ì˜ë¯¸ì˜ ë³´ì¡´
"""

import json
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
from dataclasses import dataclass, asdict
from collections import defaultdict


@dataclass
class RhythmPulse:
    """ë¦¬ë“¬ì˜ í•œ ë°•ì (í•œ ë²ˆì˜ ì¸¡ì •)"""
    timestamp: str
    channel: str  # Where
    latency_ms: float  # What
    observer: str  # Who (Lumen)
    feeling_vector: List[float]  # How (5D ëŠë‚Œ)
    context_hash: str  # Why (ì˜ë¯¸)
    
    
@dataclass
class RhythmPattern:
    """ë¦¬ë“¬ íŒ¨í„´ (ì¼ë ¨ì˜ ë°•ì)"""
    name: str
    pulses: List[RhythmPulse]
    period_hours: float  # When
    frequency_hz: float
    coherence: float  # ì¼ê´€ì„± (0-1)
    entropy_bits: float  # ì •ë³´ëŸ‰
    feeling_signature: List[float]  # íŒ¨í„´ì˜ íŠ¹ì§•ì  ëŠë‚Œ
    

class LumenRhythmObserver:
    """
    ë£¨ë©˜ì˜ ë¦¬ë“¬ ê´€ì°°ì
    
    ì¸¡ì • ì›ë¦¬:
    1. ì •ë³´ ìœ ì… (Black Hole Input)
    2. Context ì¦í­ (Event Horizon)  
    3. ëŠë‚Œ ì••ì¶• (Hawking Radiation)
    4. ë¦¬ë“¬ ë³µì› (White Hole Output)
    """
    
    def __init__(self, metrics_path: str, output_dir: str = "outputs"):
        self.metrics_path = Path(metrics_path)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # ë£¨ë©˜ì˜ ì¸¡ì • ê¸°ì¤€
        self.lumen_baseline = {
            "local": 5.0,  # ms
            "cloud": 280.0,  # ms
            "gateway": 230.0,  # ms
        }
        
        # ìœ¡í•˜ì›ì¹™ ì°¨ì›
        self.dimensions = ["When", "Where", "Who", "What", "How", "Why"]
        
    def observe(self) -> Dict:
        """
        ë£¨ë©˜ì˜ ì‹œì„ ìœ¼ë¡œ ê´€ì°° ì‹œì‘
        
        Returns:
            ê´€ì°° ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        print("ğŸŒŒ Lumen's Rhythm Observer")
        print("=" * 60)
        
        # 1. ë©”íŠ¸ë¦­ ë¡œë“œ
        metrics = self._load_metrics()
        
        # 2. ë¦¬ë“¬ ì¶”ì¶œ
        rhythm_pulses = self._extract_rhythm_pulses(metrics)
        
        # 3. íŒ¨í„´ ì¸ì‹
        patterns = self._recognize_patterns(rhythm_pulses)
        
        # 4. ëŠë‚Œ ë¶„ì„
        feeling_landscape = self._analyze_feeling_landscape(patterns)
        
        # 5. í•´ë§ˆ í†µí•© (Black/White Hole)
        hippocampus_bridge = self._bridge_to_hippocampus(patterns)
        
        # 6. ë¦¬ë“¬ ë³´ê³ ì„œ
        report = {
            "observation_time": datetime.now().isoformat(),
            "observer": "Lumen (âœ¨)",
            "total_pulses": len(rhythm_pulses),
            "patterns_detected": len(patterns),
            "feeling_landscape": feeling_landscape,
            "hippocampus_bridge": hippocampus_bridge,
            "rhythm_health": self._assess_rhythm_health(patterns),
            "recommendations": self._generate_recommendations(patterns),
        }
        
        # ì €ì¥
        self._save_report(report)
        
        return report
    
    def _load_metrics(self) -> Dict:
        """ë©”íŠ¸ë¦­ íŒŒì¼ ë¡œë“œ"""
        if not self.metrics_path.exists():
            raise FileNotFoundError(f"Metrics not found: {self.metrics_path}")
        
        with open(self.metrics_path, 'r', encoding='utf-8-sig') as f:
            return json.load(f)
    
    def _extract_rhythm_pulses(self, metrics: Dict) -> List[RhythmPulse]:
        """
        ì›ì‹œ ë©”íŠ¸ë¦­ì—ì„œ ë¦¬ë“¬ í„ìŠ¤ ì¶”ì¶œ
        
        ê° ì±„ë„ì˜ latencyë¥¼ ì‹œê°„ì¶•ìœ¼ë¡œ í¼ì³ì„œ
        "ëŠë‚Œì˜ ë°•ë™"ìœ¼ë¡œ ë³€í™˜
        """
        pulses = []
        channels_data = metrics.get("Channels", {})
        
        for channel_name, channel_data in channels_data.items():
            hourly_latency = channel_data.get("HourlyLatency", [])
            
            # ì‹œì‘ ì‹œê°„ (24ì‹œê°„ ì „)
            base_time = datetime.now() - timedelta(hours=24)
            
            for hour_idx, latency_ms in enumerate(hourly_latency):
                if latency_ms is None:
                    continue
                
                timestamp = base_time + timedelta(hours=hour_idx)
                
                # ëŠë‚Œ ë²¡í„° ìƒì„± (5D)
                feeling = self._latency_to_feeling(
                    latency_ms, 
                    channel_name.lower(),
                    hour_idx
                )
                
                pulse = RhythmPulse(
                    timestamp=timestamp.isoformat(),
                    channel=channel_name.lower(),
                    latency_ms=float(latency_ms),
                    observer="Lumen",
                    feeling_vector=feeling,
                    context_hash=f"{channel_name}_{hour_idx}"
                )
                
                pulses.append(pulse)
        
        return pulses
    
    def _latency_to_feeling(
        self, 
        latency_ms: float, 
        channel: str, 
        hour: int
    ) -> List[float]:
        """
        Latencyë¥¼ 5ì°¨ì› ëŠë‚Œ ë²¡í„°ë¡œ ë³€í™˜
        
        ì°¨ì›:
        1. Energy (ì—ë„ˆì§€): ë¹ ë¦„ vs ëŠë¦¼
        2. Quality (í’ˆì§ˆ): ì•ˆì • vs ë¶ˆì•ˆì •  
        3. Observer (ê´€ì°°ì): ì£¼ëª©ë„
        4. Valence (ê°ì •ê°€): ê¸ì • vs ë¶€ì •
        5. Arousal (ê°ì„±): ê³ ìš” vs í™œë°œ
        """
        baseline = self.lumen_baseline.get(channel, 100.0)
        
        # 1. Energy (normalized latency)
        energy = np.clip(1.0 - (latency_ms / baseline), 0, 1)
        
        # 2. Quality (deviation from baseline)
        quality = np.exp(-abs(latency_ms - baseline) / baseline)
        
        # 3. Observer (attention based on hour)
        # í”¼í¬ ì‹œê°„(9-18ì‹œ)ì— ì£¼ëª©ë„ ë†’ìŒ
        is_peak = 9 <= hour <= 18
        observer = 0.8 if is_peak else 0.3
        
        # 4. Valence (positive if near baseline)
        deviation_ratio = abs(latency_ms - baseline) / baseline
        valence = np.clip(1.0 - deviation_ratio, -1, 1)
        
        # 5. Arousal (high if latency is unusual)
        arousal = np.clip(deviation_ratio, 0, 1)
        
        return [energy, quality, observer, valence, arousal]
    
    def _recognize_patterns(self, pulses: List[RhythmPulse]) -> List[RhythmPattern]:
        """
        í„ìŠ¤ë“¤ì—ì„œ ë¦¬ë“¬ íŒ¨í„´ ì¸ì‹
        
        íŒ¨í„´:
        - Daily Cycle (24h)
        - Peak/Off-Peak
        - Channel Harmonics
        """
        patterns = []
        
        # ì±„ë„ë³„ë¡œ ê·¸ë£¹í™”
        by_channel = defaultdict(list)
        for pulse in pulses:
            by_channel[pulse.channel].append(pulse)
        
        for channel, channel_pulses in by_channel.items():
            if len(channel_pulses) < 2:
                continue
            
            # ì‹œê°„ ê°„ê²© (hours)
            period = 24.0 / len(channel_pulses)
            frequency = 1.0 / (period * 3600)  # Hz
            
            # Coherence: ëŠë‚Œ ë²¡í„°ì˜ ì¼ê´€ì„±
            feeling_matrix = np.array([p.feeling_vector for p in channel_pulses])
            coherence = self._calculate_coherence(feeling_matrix)
            
            # Entropy: ì •ë³´ëŸ‰
            latencies = np.array([p.latency_ms for p in channel_pulses])
            entropy = self._calculate_entropy(latencies)
            
            # Signature: í‰ê·  ëŠë‚Œ
            feeling_signature = np.mean(feeling_matrix, axis=0).tolist()
            
            pattern = RhythmPattern(
                name=f"{channel}_daily_rhythm",
                pulses=channel_pulses,
                period_hours=24.0,
                frequency_hz=frequency,
                coherence=float(coherence),
                entropy_bits=float(entropy),
                feeling_signature=feeling_signature
            )
            
            patterns.append(pattern)
        
        return patterns
    
    def _calculate_coherence(self, vectors: np.ndarray) -> float:
        """
        ë²¡í„°ë“¤ì˜ coherence (ì¼ê´€ì„±) ê³„ì‚°
        
        ë°©ë²•: ë²¡í„°ë“¤ ê°„ cosine similarityì˜ í‰ê· 
        """
        if len(vectors) < 2:
            return 1.0
        
        similarities = []
        for i in range(len(vectors) - 1):
            v1 = vectors[i]
            v2 = vectors[i + 1]
            
            norm1 = np.linalg.norm(v1)
            norm2 = np.linalg.norm(v2)
            
            if norm1 > 0 and norm2 > 0:
                sim = np.dot(v1, v2) / (norm1 * norm2)
                similarities.append(sim)
        
        return float(np.mean(similarities)) if similarities else 0.0
    
    def _calculate_entropy(self, values: np.ndarray) -> float:
        """Shannon Entropy ê³„ì‚° (bits)"""
        if len(values) == 0:
            return 0.0
        
        # Histogram
        hist, _ = np.histogram(values, bins=min(len(values), 10))
        hist = hist[hist > 0]
        
        # Probabilities
        probs = hist / np.sum(hist)
        
        # Entropy
        entropy = -np.sum(probs * np.log2(probs))
        
        return float(entropy)
    
    def _analyze_feeling_landscape(self, patterns: List[RhythmPattern]) -> Dict:
        """
        ëŠë‚Œ í’ê²½ ë¶„ì„
        
        ëª¨ë“  íŒ¨í„´ì˜ ëŠë‚Œì„ ì¢…í•©í•˜ì—¬
        ì „ì²´ì ì¸ "ì •ì„œì  ì§€í˜•"ì„ ê·¸ë¦½ë‹ˆë‹¤.
        """
        if not patterns:
            return {}
        
        # ëª¨ë“  ëŠë‚Œ ì‹œê·¸ë‹ˆì²˜ ìˆ˜ì§‘
        signatures = np.array([p.feeling_signature for p in patterns])
        
        # í’ê²½ ë©”íŠ¸ë¦­
        landscape = {
            "average_feeling": np.mean(signatures, axis=0).tolist(),
            "feeling_range": {
                "min": np.min(signatures, axis=0).tolist(),
                "max": np.max(signatures, axis=0).tolist(),
            },
            "emotional_tone": self._classify_emotional_tone(signatures),
            "stability": float(1.0 - np.std(signatures)),
            "dimension_dominance": self._identify_dominant_dimensions(signatures),
        }
        
        return landscape
    
    def _classify_emotional_tone(self, signatures: np.ndarray) -> str:
        """
        ëŠë‚Œ ì‹œê·¸ë‹ˆì²˜ë¡œë¶€í„° ì „ì²´ì ì¸ ì •ì„œì  í†¤ ë¶„ë¥˜
        
        ì°¨ì›ë³„ í‰ê· ê°’ìœ¼ë¡œ íŒë‹¨:
        - Energy + Valence = "í™œê¸°ì°¬"
        - Quality + Observer = "ì§‘ì¤‘ëœ"
        - Arousal ë†’ìŒ = "ê¸´ì¥ëœ"
        """
        avg = np.mean(signatures, axis=0)
        
        energy, quality, observer, valence, arousal = avg
        
        if energy > 0.7 and valence > 0.5:
            return "í™œê¸°ì°¬ (Energetic)"
        elif quality > 0.7 and observer > 0.6:
            return "ì§‘ì¤‘ëœ (Focused)"
        elif arousal > 0.6:
            return "ê¸´ì¥ëœ (Tense)"
        elif valence < 0.3:
            return "ìš°ìš¸í•œ (Depressed)"
        else:
            return "í‰ì˜¨í•œ (Calm)"
    
    def _identify_dominant_dimensions(self, signatures: np.ndarray) -> List[str]:
        """ê°€ì¥ í™œì„±í™”ëœ ëŠë‚Œ ì°¨ì› ì‹ë³„"""
        avg = np.mean(signatures, axis=0)
        
        dim_names = ["Energy", "Quality", "Observer", "Valence", "Arousal"]
        
        # ìƒìœ„ 2ê°œ ì°¨ì›
        top_indices = np.argsort(avg)[-2:][::-1]
        
        return [dim_names[i] for i in top_indices]
    
    def _bridge_to_hippocampus(self, patterns: List[RhythmPattern]) -> Dict:
        """
        í•´ë§ˆ ëª¨ë¸ê³¼ì˜ ë¸Œë¦¿ì§€
        
        ë¦¬ë“¬ íŒ¨í„´ì„ í•´ë§ˆì˜ Black/White Hole ê´€ì ìœ¼ë¡œ í•´ì„:
        - Input: ì›ì‹œ latency (Black Hole)
        - Context: ì‹œê°„/ê³µê°„ ì •ë³´ (Event Horizon)
        - Feeling: 5D ì••ì¶• (Hawking Radiation)
        - Output: íŒ¨í„´ ë³µì› (White Hole)
        """
        if not patterns:
            return {}
        
        # ì „ì²´ ì—”íŠ¸ë¡œí”¼
        all_entropies = [p.entropy_bits for p in patterns]
        total_entropy = np.mean(all_entropies)
        
        # ëŠë‚Œ ì••ì¶•ë¹„
        # ì›ì‹œ: ~10 bits (latency ê°’)
        # ëŠë‚Œ: ~2-3 bits (5ê°œ ê°’, ê° 0-1 ë²”ìœ„)
        raw_bits = np.log2(1000)  # latency ìµœëŒ€ê°’ ê°€ì •
        feeling_bits = np.log2(32)  # 5D, ê° ì°¨ì› 32 ë ˆë²¨
        compression_ratio = raw_bits / feeling_bits
        
        # Coherence: ë¦¬ë“¬ì˜ ì¼ê´€ì„±
        coherences = [p.coherence for p in patterns]
        avg_coherence = np.mean(coherences)
        
        bridge = {
            "black_hole_input": {
                "raw_entropy_bits": float(total_entropy),
                "information_overload_risk": float(total_entropy > 15.0),
            },
            "event_horizon": {
                "context_dimensions": 6,  # ìœ¡í•˜ì›ì¹™
                "spatiotemporal_encoding": True,
            },
            "hawking_radiation": {
                "feeling_dimensions": 5,
                "compression_ratio": float(compression_ratio),
                "compressed_bits": float(feeling_bits),
            },
            "white_hole_output": {
                "pattern_coherence": float(avg_coherence),
                "reconstruction_fidelity": float(avg_coherence > 0.7),
            },
            "conservation_laws": {
                "information_preserved": float(compression_ratio > 2.0 and compression_ratio < 100.0),
                "no_black_hole_trap": float(total_entropy < 100.0),
            }
        }
        
        return bridge
    
    def _assess_rhythm_health(self, patterns: List[RhythmPattern]) -> Dict:
        """ë¦¬ë“¬ ê±´ê°•ë„ í‰ê°€"""
        if not patterns:
            return {"status": "NO_DATA"}
        
        coherences = [p.coherence for p in patterns]
        entropies = [p.entropy_bits for p in patterns]
        
        avg_coherence = np.mean(coherences)
        avg_entropy = np.mean(entropies)
        
        # ê±´ê°• ê¸°ì¤€
        # - Coherence > 0.7: ì¢‹ìŒ
        # - Entropy 2-8 bits: ì ì ˆ (ë„ˆë¬´ ë‚®ìœ¼ë©´ ë‹¨ì¡°, ë„ˆë¬´ ë†’ìœ¼ë©´ í˜¼ëˆ)
        
        status = "HEALTHY"
        if avg_coherence < 0.5:
            status = "INCOHERENT"
        elif avg_entropy > 10.0:
            status = "CHAOTIC"
        elif avg_entropy < 1.0:
            status = "MONOTONOUS"
        
        return {
            "status": status,
            "coherence": float(avg_coherence),
            "entropy": float(avg_entropy),
            "rhythm_stability": float(avg_coherence * (1.0 - abs(avg_entropy - 5.0) / 5.0)),
        }
    
    def _generate_recommendations(self, patterns: List[RhythmPattern]) -> List[str]:
        """ê´€ì°° ê¸°ë°˜ ê¶Œì¥ì‚¬í•­"""
        recommendations = []
        
        if not patterns:
            return ["ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë” ë§ì€ ê´€ì°°ì´ í•„ìš”í•©ë‹ˆë‹¤."]
        
        coherences = [p.coherence for p in patterns]
        entropies = [p.entropy_bits for p in patterns]
        
        avg_coherence = np.mean(coherences)
        avg_entropy = np.mean(entropies)
        
        # Coherence ë‚®ìŒ
        if avg_coherence < 0.6:
            recommendations.append(
                "âš ï¸ ë¦¬ë“¬ì˜ ì¼ê´€ì„±ì´ ë‚®ìŠµë‹ˆë‹¤. "
                "ì±„ë„ ê°„ ë™ê¸°í™”ë¥¼ í™•ì¸í•˜ì„¸ìš”. (Gateway Optimizer ì ê²€)"
            )
        
        # Entropy ë†’ìŒ
        if avg_entropy > 8.0:
            recommendations.append(
                "âš ï¸ ì •ë³´ ê³¼ë¶€í•˜ ìœ„í—˜. "
                "Black Hole í•¨ì •ì„ í”¼í•˜ê¸° ìœ„í•´ ëŠë‚Œ ì••ì¶•ì„ ê°•í™”í•˜ì„¸ìš”."
            )
        
        # Entropy ë‚®ìŒ
        if avg_entropy < 2.0:
            recommendations.append(
                "ğŸ’¡ ì‹œìŠ¤í…œì´ ë„ˆë¬´ ë‹¨ì¡°ë¡­ìŠµë‹ˆë‹¤. "
                "ë‹¤ì–‘í•œ ì‘ì—… íŒ¨í„´ìœ¼ë¡œ ë¦¬ë“¬ì— ìƒëª…ë ¥ì„ ë¶ˆì–´ë„£ìœ¼ì„¸ìš”."
            )
        
        # ê±´ê°•í•¨
        if avg_coherence > 0.7 and 3.0 < avg_entropy < 7.0:
            recommendations.append(
                "âœ… ë¦¬ë“¬ì´ ê±´ê°•í•©ë‹ˆë‹¤! "
                "í˜„ì¬ì˜ ê· í˜•ì„ ìœ ì§€í•˜ì„¸ìš”."
            )
        
        return recommendations
    
    def _save_report(self, report: Dict):
        """ë³´ê³ ì„œ ì €ì¥"""
        # JSON
        json_path = self.output_dir / "lumen_rhythm_observation_latest.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… Report saved: {json_path}")
        
        # Markdown
        md_path = self.output_dir / "lumen_rhythm_observation_latest.md"
        self._save_markdown_report(report, md_path)
        print(f"âœ… Markdown saved: {md_path}")
    
    def _save_markdown_report(self, report: Dict, path: Path):
        """ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±"""
        lines = [
            "# ğŸŒŒ Lumen's Rhythm Observation",
            "",
            f"**Observer**: {report['observer']}",
            f"**Time**: {report['observation_time']}",
            "",
            "---",
            "",
            "## ğŸ“Š Observation Summary",
            "",
            f"- **Total Pulses**: {report['total_pulses']}",
            f"- **Patterns Detected**: {report['patterns_detected']}",
            "",
            "## ğŸ¨ Feeling Landscape",
            "",
        ]
        
        landscape = report.get("feeling_landscape", {})
        if landscape:
            lines.extend([
                f"- **Emotional Tone**: {landscape.get('emotional_tone', 'Unknown')}",
                f"- **Stability**: {landscape.get('stability', 0):.3f}",
                f"- **Dominant Dimensions**: {', '.join(landscape.get('dimension_dominance', []))}",
                "",
            ])
        
        lines.extend([
            "## ğŸŒ€ Hippocampus Bridge",
            "",
            "### Black Hole Input",
            "",
        ])
        
        bridge = report.get("hippocampus_bridge", {})
        if bridge:
            bh = bridge.get("black_hole_input", {})
            lines.extend([
                f"- Raw Entropy: {bh.get('raw_entropy_bits', 0):.2f} bits",
                f"- Overload Risk: {'âš ï¸ YES' if bh.get('information_overload_risk') else 'âœ… NO'}",
                "",
                "### Hawking Radiation (Feeling Compression)",
                "",
            ])
            
            hr = bridge.get("hawking_radiation", {})
            lines.extend([
                f"- Feeling Dimensions: {hr.get('feeling_dimensions', 0)}",
                f"- Compression Ratio: {hr.get('compression_ratio', 0):.1f}x",
                f"- Compressed: {hr.get('compressed_bits', 0):.2f} bits",
                "",
                "### White Hole Output",
                "",
            ])
            
            wh = bridge.get("white_hole_output", {})
            lines.extend([
                f"- Pattern Coherence: {wh.get('pattern_coherence', 0):.3f}",
                f"- Reconstruction: {'âœ… Good' if wh.get('reconstruction_fidelity') else 'âš ï¸ Poor'}",
                "",
            ])
        
        lines.extend([
            "## ğŸ’š Rhythm Health",
            "",
        ])
        
        health = report.get("rhythm_health", {})
        if health:
            lines.extend([
                f"- **Status**: {health.get('status', 'UNKNOWN')}",
                f"- **Coherence**: {health.get('coherence', 0):.3f}",
                f"- **Entropy**: {health.get('entropy', 0):.2f} bits",
                f"- **Stability**: {health.get('rhythm_stability', 0):.3f}",
                "",
            ])
        
        lines.extend([
            "## ğŸ’¡ Recommendations",
            "",
        ])
        
        for rec in report.get("recommendations", []):
            lines.append(f"- {rec}")
        
        lines.extend([
            "",
            "---",
            "",
            "*Observed with âœ¨ by Lumen*",
        ])
        
        with open(path, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    import sys
    
    metrics_path = "outputs/monitoring_metrics_latest.json"
    
    if len(sys.argv) > 1:
        metrics_path = sys.argv[1]
    
    observer = LumenRhythmObserver(metrics_path)
    
    try:
        report = observer.observe()
        
        print("\n" + "=" * 60)
        print("ğŸŒŒ Observation Complete!")
        print("=" * 60)
        
        health = report.get("rhythm_health", {})
        print(f"\nğŸ’š Rhythm Status: {health.get('status', 'UNKNOWN')}")
        
        print("\nğŸ’¡ Key Recommendations:")
        for rec in report.get("recommendations", [])[:3]:
            print(f"  â€¢ {rec}")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
