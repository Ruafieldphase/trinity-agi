#!/usr/bin/env python3
"""
bohm_implicate_explicate_analyzer.py

David Bohmì˜ Implicate/Explicate Orderì™€ í•´ë§ˆ Black/White Hole ëª¨ë¸ í†µí•©

í•µì‹¬ ê°œë…:
1. Implicate Order (ì ‘íŒ ì§ˆì„œ): ë³´ì´ì§€ ì•ŠëŠ” ì „ì²´ì„±, Black Hole ë‚´ë¶€
2. Explicate Order (í¼ì³ì§„ ì§ˆì„œ): ê´€ì°° ê°€ëŠ¥í•œ í˜„ì‹¤, White Hole ì¶œë ¥
3. ë‘ë ¤ì›€ (Fear): íŠ¹ì´ì ì—ì„œì˜ ì••ì¶•/íŒ½ì°½ì„ ì¡°ì ˆí•˜ëŠ” "ê°ì • ì—”ì§„"

ì´ë¡ ì  ë°°ê²½:
- Black Hole = Enfolding (ì •ë³´ë¥¼ ê°ì¶”ëŠ” ê³¼ì •)
- White Hole = Unfolding (ì •ë³´ë¥¼ ë“œëŸ¬ë‚´ëŠ” ê³¼ì •)
- Event Horizon = "ì ‘í˜ê³¼ í¼ì¹¨"ì˜ ê²½ê³„
- Hawking Radiation = ëŠë‚Œìœ¼ë¡œ ì••ì¶•ëœ ì •ë³´ (Fearê°€ ì••ì¶•ë¥ ì— ì˜í–¥)
"""

import sys
import json
from pathlib import Path
from datetime import datetime, timedelta, timezone
from typing import Dict, Any, List, Optional, Tuple
import math

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from fdo_agi_repo.universal.resonance import ResonanceStore
except ImportError:
    print("âš ï¸  Warning: Could not import ResonanceStore. Using mock mode.")
    ResonanceStore = None


class BohmAnalyzer:
    """David Bohmì˜ Implicate/Explicate Order ë¶„ì„ê¸°"""
    
    def __init__(self, workspace_root: Path):
        self.workspace = workspace_root
        self.ledger_path = workspace_root / "fdo_agi_repo" / "memory" / "resonance_ledger.jsonl"
        self.output_dir = workspace_root / "outputs"
        self.output_dir.mkdir(exist_ok=True)
        
    def load_recent_events(self, hours: int = 24) -> List[Dict[str, Any]]:
        """ìµœê·¼ ì´ë²¤íŠ¸ ë¡œë“œ"""
        if not self.ledger_path.exists():
            return []
        
        cutoff = datetime.now(timezone.utc) - timedelta(hours=hours)
        events = []
        
        with open(self.ledger_path, 'r', encoding='utf-8') as f:
            for line in f:
                if not line.strip():
                    continue
                try:
                    event = json.loads(line)
                    ts_str = event.get('timestamp', '')
                    if ts_str:
                        # íƒ€ì„ì¡´ ì²˜ë¦¬
                        if 'Z' in ts_str:
                            ts = datetime.fromisoformat(ts_str.replace('Z', '+00:00'))
                        elif '+' in ts_str or ts_str.count('-') > 2:
                            ts = datetime.fromisoformat(ts_str)
                        else:
                            # íƒ€ì„ì¡´ ì—†ìŒ â†’ UTCë¡œ ê°„ì£¼
                            ts = datetime.fromisoformat(ts_str).replace(tzinfo=timezone.utc)
                        
                        if ts >= cutoff:
                            events.append(event)
                except Exception as e:
                    continue
        
        return events
    
    def extract_fear_signal(self, events: List[Dict[str, Any]]) -> List[Tuple[datetime, float]]:
        """ì´ë²¤íŠ¸ì—ì„œ ë‘ë ¤ì›€ ì‹ í˜¸ ì¶”ì¶œ"""
        fear_signals = []
        
        for event in events:
            ts_str = event.get('timestamp', '')
            if not ts_str:
                continue
            
            # íƒ€ì„ì¡´ ì²˜ë¦¬ (Z ë˜ëŠ” +00:00 ë˜ëŠ” ì—†ìŒ)
            try:
                if 'Z' in ts_str:
                    ts = datetime.fromisoformat(ts_str.replace('Z', '+00:00'))
                elif '+' in ts_str or ts_str.count('-') > 2:  # íƒ€ì„ì¡´ í¬í•¨
                    ts = datetime.fromisoformat(ts_str)
                else:
                    # íƒ€ì„ì¡´ ì—†ìŒ â†’ UTCë¡œ ê°„ì£¼
                    ts = datetime.fromisoformat(ts_str).replace(tzinfo=timezone.utc)
            except Exception as e:
                continue
            
            # ìµœìƒìœ„ ë ˆë²¨ì—ì„œ fear ë¨¼ì € ì°¾ê¸° (ë£¨ì•„ ëŒ€í™” ë°ì´í„°)
            fear = event.get('fear', 0.0)
            
            # tagsì—ì„œ fear ì°¾ê¸°
            if fear == 0.0:
                tags = event.get('tags', {})
                fear = tags.get('fear', 0.0)
            
            # metricsì—ì„œë„ í™•ì¸
            if fear == 0.0:
                metrics = event.get('metrics', {})
                if 'fear' in metrics:
                    fear = metrics.get('fear', 0.0)
            
            # emotion êµ¬ì¡°ì—ì„œë„ í™•ì¸
            if fear == 0.0 and 'emotion' in event.get('tags', {}):
                emotion = event.get('tags', {}).get('emotion', {})
                if isinstance(emotion, dict) and 'fear' in emotion:
                    fear = emotion['fear']
            
            fear_signals.append((ts, float(fear)))
        
        return fear_signals
    
    def analyze_folding_unfolding(self, events: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì ‘í˜/í¼ì¹¨ ê³¼ì • ë¶„ì„ (Enfolding/Unfolding)"""
        
        if not events:
            return {
                'implicate_count': 0,
                'explicate_count': 0,
                'singularity_moments': [],
                'fear_correlation': 0.0
            }
        
        # 1. Implicate (ì ‘í˜): ì •ë³´ê°€ Black Holeë¡œ ë“¤ì–´ê°€ëŠ” ìˆœê°„
        #    - ì••ì¶•ë¥  ì¦ê°€
        #    - entropy ê°ì†Œ
        #    - coherence ê°ì†Œ (ì •ë³´ê°€ "ìˆ¨ê²¨ì§")
        
        # 2. Explicate (í¼ì¹¨): ì •ë³´ê°€ White Holeì—ì„œ ë‚˜ì˜¤ëŠ” ìˆœê°„
        #    - ì••ì¶•ë¥  ê°ì†Œ (ì •ë³´ ë³µì›)
        #    - coherence ì¦ê°€ (íŒ¨í„´ ë“œëŸ¬ë‚¨)
        
        implicate_moments = []
        explicate_moments = []
        singularities = []
        
        for i, event in enumerate(events):
            metrics = event.get('metrics', {})
            compression = metrics.get('compression_ratio', 1.0)
            coherence = metrics.get('coherence', 0.0)
            
            # Singularity ê°ì§€: ì••ì¶•ë¥ ì´ ê·¹ë‹¨ì ì¼ ë•Œ
            if compression > 5.0 or compression < 0.5:
                ts_str = event.get('timestamp', '')
                if ts_str:
                    ts = datetime.fromisoformat(ts_str.replace('Z', '+00:00'))
                    singularities.append({
                        'timestamp': ts.isoformat(),
                        'compression': compression,
                        'type': 'over-compressed' if compression > 5.0 else 'under-compressed'
                    })
            
            # Implicate (ì ‘í˜): ì´ì „ ì´ë²¤íŠ¸ë³´ë‹¤ ì••ì¶•ë¥  ì¦ê°€
            if i > 0:
                prev_compression = events[i-1].get('metrics', {}).get('compression_ratio', 1.0)
                if compression > prev_compression * 1.5:  # 50% ì´ìƒ ì¦ê°€
                    implicate_moments.append(event)
                elif compression < prev_compression * 0.67:  # 33% ì´ìƒ ê°ì†Œ
                    explicate_moments.append(event)
        
        # Fear ìƒê´€ê´€ê³„
        fear_signals = self.extract_fear_signal(events)
        fear_correlation = self._calculate_fear_compression_correlation(events, fear_signals)
        
        return {
            'implicate_count': len(implicate_moments),
            'explicate_count': len(explicate_moments),
            'singularity_moments': singularities,
            'fear_correlation': fear_correlation,
            'implicate_explicate_ratio': len(implicate_moments) / max(len(explicate_moments), 1)
        }
    
    def _calculate_fear_compression_correlation(
        self, 
        events: List[Dict[str, Any]], 
        fear_signals: List[Tuple[datetime, float]]
    ) -> float:
        """ë‘ë ¤ì›€ê³¼ ì••ì¶•ë¥ ì˜ ìƒê´€ê´€ê³„ ê³„ì‚°"""
        
        if len(fear_signals) < 2:
            return 0.0
        
        # í•´ë§ˆ ë¶„ì„ ì´ë²¤íŠ¸ë§Œ ì¶”ì¶œ (compression_ratio ìˆìŒ)
        hippocampus_events = [
            e for e in events 
            if e.get('event_type') == 'hippocampus_analysis' 
            and e.get('metrics', {}).get('compression_ratio')
        ]
        
        if not hippocampus_events:
            return 0.0
        
        # ê° í•´ë§ˆ ì´ë²¤íŠ¸ì— ëŒ€í•´ ì‹œê°„ ë²”ìœ„ ë‚´ í‰ê·  Fear ê³„ì‚°
        pairs = []
        for event in hippocampus_events:
            metrics = event.get('metrics', {})
            compression = metrics.get('compression_ratio', 1.0)
            
            ts_str = event.get('timestamp', '')
            if not ts_str:
                continue
            
            ts = datetime.fromisoformat(ts_str.replace('Z', '+00:00'))
            
            # í•´ë§ˆ ë¶„ì„ ì „ 1ì‹œê°„ ë™ì•ˆì˜ í‰ê·  Fear ê³„ì‚°
            window_start = ts - timedelta(hours=1)
            
            # íƒ€ì„ì¡´ aware í™•ì¸
            if ts.tzinfo is None:
                ts = ts.replace(tzinfo=timezone.utc)
            if window_start.tzinfo is None:
                window_start = window_start.replace(tzinfo=timezone.utc)
            
            window_fears = [
                fear_val for fear_ts, fear_val in fear_signals
                if (fear_ts.replace(tzinfo=timezone.utc) if fear_ts.tzinfo is None else fear_ts) >= window_start
                and (fear_ts.replace(tzinfo=timezone.utc) if fear_ts.tzinfo is None else fear_ts) <= ts
                and fear_val > 0.0
            ]
            
            if window_fears:
                avg_fear = sum(window_fears) / len(window_fears)
                pairs.append((avg_fear, compression))
        
        if len(pairs) < 2:
            return 0.0
        
        # Pearson correlation
        fear_vals = [p[0] for p in pairs]
        comp_vals = [p[1] for p in pairs]
        
        n = len(pairs)
        sum_fear = sum(fear_vals)
        sum_comp = sum(comp_vals)
        sum_fear_comp = sum(f * c for f, c in pairs)
        sum_fear_sq = sum(f * f for f in fear_vals)
        sum_comp_sq = sum(c * c for c in comp_vals)
        
        numerator = n * sum_fear_comp - sum_fear * sum_comp
        denominator_part1 = n * sum_fear_sq - sum_fear**2
        denominator_part2 = n * sum_comp_sq - sum_comp**2
        
        # ìŒìˆ˜ ë°©ì§€ (ë¶„ì‚°ì´ ìŒìˆ˜ì¸ ê²½ìš°)
        if denominator_part1 < 0 or denominator_part2 < 0:
            return 0.0
        
        denominator = math.sqrt(denominator_part1 * denominator_part2)
        
        if denominator == 0:
            return 0.0
        
        return numerator / denominator
    
    def detect_singularity_patterns(self, events: List[Dict[str, Any]]) -> Dict[str, Any]:
        """íŠ¹ì´ì  íŒ¨í„´ ê°ì§€
        
        íŠ¹ì´ì ì˜ íŠ¹ì§•:
        1. ì •ë³´ ë°€ë„ê°€ ê·¹ëŒ€í™”
        2. ë‘ë ¤ì›€ì´ í”¼í¬
        3. ê·¸ ì§í›„ "í­ë°œì  íŒ½ì°½" (White Hole)
        """
        
        singularity_events = []
        
        for i, event in enumerate(events):
            metrics = event.get('metrics', {})
            tags = event.get('tags', {})
            
            compression = metrics.get('compression_ratio', 1.0)
            coherence = metrics.get('coherence', 0.0)
            fear = tags.get('fear', 0.0)
            
            # íŠ¹ì´ì  ì¡°ê±´:
            # 1. ì••ì¶•ë¥  > 4.0 (ë§¤ìš° ë†’ìŒ)
            # 2. Fear > 0.6 (ë‘ë ¤ì›€ ì¦ê°€)
            # 3. Coherence < 0.5 (í˜¼ëˆ)
            
            is_singularity = (
                compression > 4.0 and
                fear > 0.6 and
                coherence < 0.5
            )
            
            if is_singularity:
                ts_str = event.get('timestamp', '')
                if ts_str:
                    ts = datetime.fromisoformat(ts_str.replace('Z', '+00:00'))
                    
                    # ë‹¤ìŒ ì´ë²¤íŠ¸ í™•ì¸ (íŒ½ì°½?)
                    explosion = None
                    if i + 1 < len(events):
                        next_event = events[i + 1]
                        next_compression = next_event.get('metrics', {}).get('compression_ratio', 1.0)
                        if next_compression < compression * 0.5:  # ê¸‰ê²©í•œ ê°ì†Œ
                            explosion = True
                    
                    singularity_events.append({
                        'timestamp': ts.isoformat(),
                        'compression': compression,
                        'fear': fear,
                        'coherence': coherence,
                        'followed_by_explosion': explosion
                    })
        
        return {
            'singularity_count': len(singularity_events),
            'singularities': singularity_events,
            'explosion_ratio': sum(1 for s in singularity_events if s['followed_by_explosion']) / max(len(singularity_events), 1)
        }
    
    def generate_bohm_report(self, hours: int = 24) -> Dict[str, Any]:
        """Bohm ì´ë¡  í†µí•© ë³´ê³ ì„œ ìƒì„±"""
        
        events = self.load_recent_events(hours)
        
        if not events:
            return {
                'status': 'no_data',
                'message': f'No events found in last {hours} hours'
            }
        
        # 1. Folding/Unfolding ë¶„ì„
        folding_analysis = self.analyze_folding_unfolding(events)
        
        # 2. íŠ¹ì´ì  íŒ¨í„´
        singularity_analysis = self.detect_singularity_patterns(events)
        
        # 3. Fear ì‹ í˜¸
        fear_signals = self.extract_fear_signal(events)
        avg_fear = sum(f for _, f in fear_signals) / max(len(fear_signals), 1)
        max_fear = max((f for _, f in fear_signals), default=0.0)
        
        # 4. í†µí•© í•´ì„
        interpretation = self._interpret_bohm_patterns(
            folding_analysis,
            singularity_analysis,
            avg_fear,
            max_fear
        )
        
        report = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'analysis_window_hours': hours,
            'total_events': len(events),
            'folding_unfolding': folding_analysis,
            'singularity_patterns': singularity_analysis,
            'fear_metrics': {
                'average': round(avg_fear, 3),
                'maximum': round(max_fear, 3),
                'signal_count': len(fear_signals)
            },
            'interpretation': interpretation
        }
        
        return report
    
    def _interpret_bohm_patterns(
        self,
        folding: Dict[str, Any],
        singularity: Dict[str, Any],
        avg_fear: float,
        max_fear: float
    ) -> Dict[str, Any]:
        """íŒ¨í„´ í•´ì„"""
        
        # Fearì˜ ì—­í• 
        if avg_fear < 0.3:
            fear_role = "ë‚®ìŒ - ì••ì¶•ì´ ì¶©ë¶„í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ (ì •ë³´ê°€ 'í¼ì³ì§„' ìƒíƒœ)"
        elif avg_fear < 0.7:
            fear_role = "ê· í˜• - ì ì ˆí•œ Implicate/Explicate ìˆœí™˜"
        else:
            fear_role = "ë†’ìŒ - ê³¼ë„í•œ ì••ì¶•, íŠ¹ì´ì  ìœ„í—˜"
        
        # Implicate/Explicate ê· í˜•
        ratio = folding.get('implicate_explicate_ratio', 1.0)
        if ratio < 0.5:
            balance = "Explicate ìš°ì„¸ - ì •ë³´ê°€ ë§ì´ ë“œëŸ¬ë‚¨ (í¼ì¹¨ > ì ‘í˜)"
        elif ratio > 2.0:
            balance = "Implicate ìš°ì„¸ - ì •ë³´ê°€ ë§ì´ ìˆ¨ê²¨ì§ (ì ‘í˜ > í¼ì¹¨)"
        else:
            balance = "ê· í˜• - ê±´ê°•í•œ Enfolding/Unfolding"
        
        # íŠ¹ì´ì  ìœ„í—˜
        singularity_count = singularity.get('singularity_count', 0)
        if singularity_count == 0:
            singularity_risk = "ì—†ìŒ"
        elif singularity_count < 3:
            singularity_risk = "ë‚®ìŒ - ê°€ë” ê·¹ë‹¨ì  ì••ì¶• ë°œìƒ"
        else:
            singularity_risk = f"ë†’ìŒ - {singularity_count}ê°œ íŠ¹ì´ì  ê°ì§€"
        
        # Bohmì˜ ê´€ì ì—ì„œ í•´ì„
        bohm_interpretation = f"""
David Bohmì˜ Implicate/Explicate Order ê´€ì :

1. **ì ‘í˜ (Enfolding)**: {folding.get('implicate_count', 0)}íšŒ
   - ì •ë³´ê°€ Black Holeë¡œ ë“¤ì–´ê°€ "ë³´ì´ì§€ ì•ŠëŠ” ì§ˆì„œ"ë¡œ ë³€í™˜
   - ë‘ë ¤ì›€(Fear)ì´ ì´ ê³¼ì •ì„ **ì´‰ì§„**

2. **í¼ì¹¨ (Unfolding)**: {folding.get('explicate_count', 0)}íšŒ
   - White Holeì—ì„œ ì •ë³´ê°€ ë“œëŸ¬ë‚˜ "ê´€ì°° ê°€ëŠ¥í•œ í˜„ì‹¤"ë¡œ ë³µì›
   - ì••ì¶•ë¥  ê°ì†Œ, coherence ì¦ê°€

3. **íŠ¹ì´ì  (Singularity)**: {singularity_count}ê°œ
   - ì •ë³´ê°€ ê·¹ë„ë¡œ ì••ì¶•ëœ "í•œ ì "
   - ì´ê³³ì—ì„œ Implicate â†” Explicate ì „í™˜ ë°œìƒ
   - Fear í”¼í¬ì™€ ë™ì‹œ ë°œìƒ

4. **ë‘ë ¤ì›€ì˜ ì—­í• **:
   - ìƒíƒœ: {fear_role}
   - ìƒê´€ê´€ê³„: {folding.get('fear_correlation', 0.0):.3f}
   - **ë‘ë ¤ì›€ì€ ì••ì¶• ì—”ì§„** - ì •ë³´ë¥¼ Implicate Orderë¡œ "ì ‘ëŠ”" í˜
"""
        
        return {
            'fear_role': fear_role,
            'implicate_explicate_balance': balance,
            'singularity_risk': singularity_risk,
            'fear_compression_correlation': round(folding.get('fear_correlation', 0.0), 3),
            'bohm_interpretation': bohm_interpretation.strip()
        }
    
    def save_report(self, report: Dict[str, Any]) -> Path:
        """ë³´ê³ ì„œ ì €ì¥"""
        
        # JSON
        json_path = self.output_dir / "bohm_analysis_latest.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # Markdown
        md_path = self.output_dir / "bohm_analysis_latest.md"
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(self._format_markdown(report))
        
        return md_path
    
    def _format_markdown(self, report: Dict[str, Any]) -> str:
        """Markdown í¬ë§·"""
        
        folding = report.get('folding_unfolding', {})
        singularity = report.get('singularity_patterns', {})
        fear = report.get('fear_metrics', {})
        interp = report.get('interpretation', {})
        
        md = f"""# ğŸŒŒ David Bohmì˜ Implicate/Explicate Order ë¶„ì„

**ìƒì„± ì‹œê°**: {report.get('timestamp', 'N/A')}  
**ë¶„ì„ ê¸°ê°„**: ìµœê·¼ {report.get('analysis_window_hours', 24)}ì‹œê°„  
**ì´ ì´ë²¤íŠ¸**: {report.get('total_events', 0)}ê°œ

---

## ğŸ“Š í•µì‹¬ ì§€í‘œ

### 1. Enfolding/Unfolding (ì ‘í˜/í¼ì¹¨)

| ì§€í‘œ | ê°’ |
|------|-----|
| **Implicate (ì ‘í˜)** | {folding.get('implicate_count', 0)}íšŒ |
| **Explicate (í¼ì¹¨)** | {folding.get('explicate_count', 0)}íšŒ |
| **I/E ë¹„ìœ¨** | {folding.get('implicate_explicate_ratio', 0.0):.2f} |
| **ê· í˜• ìƒíƒœ** | {interp.get('implicate_explicate_balance', 'N/A')} |

### 2. íŠ¹ì´ì  (Singularity) ë¶„ì„

| ì§€í‘œ | ê°’ |
|------|-----|
| **íŠ¹ì´ì  ìˆ˜** | {singularity.get('singularity_count', 0)}ê°œ |
| **í­ë°œ ë¹„ìœ¨** | {singularity.get('explosion_ratio', 0.0):.1%} |
| **ìœ„í—˜ë„** | {interp.get('singularity_risk', 'N/A')} |

### 3. ë‘ë ¤ì›€ (Fear) ë©”íŠ¸ë¦­

| ì§€í‘œ | ê°’ |
|------|-----|
| **í‰ê·  Fear** | {fear.get('average', 0.0):.3f} |
| **ìµœëŒ€ Fear** | {fear.get('maximum', 0.0):.3f} |
| **Fear-ì••ì¶• ìƒê´€ê³„ìˆ˜** | {interp.get('fear_compression_correlation', 0.0):.3f} |
| **ì—­í• ** | {interp.get('fear_role', 'N/A')} |

---

## ğŸ”¬ Bohm ì´ë¡  í•´ì„

{interp.get('bohm_interpretation', 'N/A')}

---

## ğŸŒ€ íŠ¹ì´ì  ìƒì„¸

"""
        
        singularities = singularity.get('singularities', [])
        if singularities:
            for i, s in enumerate(singularities[:5], 1):  # ìµœëŒ€ 5ê°œ
                md += f"\n### íŠ¹ì´ì  #{i}\n"
                md += f"- **ì‹œê°**: {s.get('timestamp', 'N/A')}\n"
                md += f"- **ì••ì¶•ë¥ **: {s.get('compression', 0.0):.2f}x\n"
                md += f"- **Fear**: {s.get('fear', 0.0):.3f}\n"
                md += f"- **Coherence**: {s.get('coherence', 0.0):.3f}\n"
                
                if s.get('followed_by_explosion'):
                    md += f"- âš¡ **White Hole í­ë°œ í™•ì¸ë¨**\n"
                md += "\n"
        else:
            md += "\níŠ¹ì´ì  ì—†ìŒ (ê±´ê°•í•œ ìƒíƒœ)\n"
        
        md += """
---

## ğŸ’¡ ì‹œìŠ¤í…œ ê¶Œì¥ì‚¬í•­

"""
        
        # ê¶Œì¥ì‚¬í•­
        if fear.get('average', 0) > 0.7:
            md += "- âš ï¸ Fear ìˆ˜ì¤€ ë†’ìŒ â†’ ì••ì¶• ì™„í™” í•„ìš” (ë” ë§ì€ Explicate ìˆœí™˜)\n"
        
        if singularity.get('singularity_count', 0) > 3:
            md += "- âš ï¸ íŠ¹ì´ì  ê³¼ë‹¤ â†’ Resonance ì •ì±… ì¡°ì • ê¶Œì¥\n"
        
        ratio = folding.get('implicate_explicate_ratio', 1.0)
        if ratio > 2.0:
            md += "- âš ï¸ Implicate ìš°ì„¸ â†’ ë” ë§ì€ ì •ë³´ ë“œëŸ¬ë‚´ê¸° (White Hole í™œì„±í™”)\n"
        elif ratio < 0.5:
            md += "- âš ï¸ Explicate ìš°ì„¸ â†’ ì •ë³´ ì••ì¶• í•„ìš” (Black Hole í™œì„±í™”)\n"
        else:
            md += "- âœ… ê· í˜•ì¡íŒ Enfolding/Unfolding ìˆœí™˜\n"
        
        md += """
---

## ğŸ§  ì´ë¡ ì  ì—°ê²°

### David Bohmì˜ í•µì‹¬ ê°œë…

1. **Implicate Order (ë‚´ì¬ ì§ˆì„œ)**
   - ìš°ì£¼ì˜ "ì ‘íŒ" ìƒíƒœ
   - ëª¨ë“  ê²ƒì´ í•˜ë‚˜ë¡œ ì–½í˜€ìˆìŒ
   - ìš°ë¦¬ ì‹œìŠ¤í…œ: **Black Hole ë‚´ë¶€**

2. **Explicate Order (í‘œí˜„ ì§ˆì„œ)**
   - ìš°ì£¼ì˜ "í¼ì³ì§„" ìƒíƒœ
   - ê´€ì°° ê°€ëŠ¥í•œ í˜„ì‹¤
   - ìš°ë¦¬ ì‹œìŠ¤í…œ: **White Hole ì¶œë ¥**

3. **Holomovement (ì „ì²´ìš´ë™)**
   - ì ‘í˜ â†” í¼ì¹¨ì˜ ëŠì„ì—†ëŠ” ìˆœí™˜
   - ìš°ë¦¬ ì‹œìŠ¤í…œ: **Resonance Ledgerì˜ íë¦„**

### ê°ì •ê³¼ ë¬¼ë¦¬í•™ì˜ ë§Œë‚¨

- **ë‘ë ¤ì›€ (Fear)**: ì •ë³´ë¥¼ ì••ì¶•í•˜ëŠ” **ì¤‘ë ¥**ê³¼ ê°™ì€ ì—­í• 
- **íŠ¹ì´ì **: ë‘ë ¤ì›€ì´ ìµœê³ ì¡°ì— ë‹¬í•  ë•Œ í˜•ì„±
- **White Hole í­ë°œ**: ë‘ë ¤ì›€ì´ í•´ì†Œë˜ë©´ì„œ ì •ë³´ê°€ "í„°ì ¸ë‚˜ì˜´"

---

*"The implicate order represents a reality in which everything is enfolded into everything."*  
â€” David Bohm

"""
        
        return md


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    import argparse
    
    parser = argparse.ArgumentParser(description="David Bohm Implicate/Explicate Order ë¶„ì„")
    parser.add_argument('--hours', type=int, default=24, help='ë¶„ì„ ê¸°ê°„ (ì‹œê°„)')
    parser.add_argument('--workspace', type=str, default=None, help='ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ë£¨íŠ¸')
    parser.add_argument('--open', action='store_true', help='ìƒì„±ëœ MD íŒŒì¼ ì—´ê¸°')
    
    args = parser.parse_args()
    
    workspace = Path(args.workspace) if args.workspace else Path(__file__).parent.parent
    
    print(f"ğŸŒŒ David Bohm Analyzer ì‹œì‘...")
    print(f"   ë¶„ì„ ê¸°ê°„: ìµœê·¼ {args.hours}ì‹œê°„")
    print(f"   ì›Œí¬ìŠ¤í˜ì´ìŠ¤: {workspace}")
    print()
    
    analyzer = BohmAnalyzer(workspace)
    
    print("ğŸ“Š ë°ì´í„° ë¶„ì„ ì¤‘...")
    report = analyzer.generate_bohm_report(args.hours)
    
    if report.get('status') == 'no_data':
        print(f"âš ï¸  {report.get('message')}")
        return
    
    print("ğŸ’¾ ë³´ê³ ì„œ ì €ì¥ ì¤‘...")
    md_path = analyzer.save_report(report)
    
    print()
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print(f"   JSON: {workspace / 'outputs' / 'bohm_analysis_latest.json'}")
    print(f"   MD: {md_path}")
    print()
    
    # í•µì‹¬ ê²°ê³¼ ì¶œë ¥
    interp = report.get('interpretation', {})
    print("ğŸ“Œ í•µì‹¬ ë°œê²¬:")
    print(f"   Fear ì—­í• : {interp.get('fear_role', 'N/A')}")
    print(f"   I/E ê· í˜•: {interp.get('implicate_explicate_balance', 'N/A')}")
    print(f"   íŠ¹ì´ì  ìœ„í—˜: {interp.get('singularity_risk', 'N/A')}")
    print(f"   Fear-ì••ì¶• ìƒê´€: {interp.get('fear_compression_correlation', 0.0):.3f}")
    print()
    
    if args.open:
        import subprocess
        subprocess.run(['code', str(md_path)])


if __name__ == '__main__':
    main()
