#!/usr/bin/env python
"""
Baseline TTFT (Time To First Token) ì¸¡ì • ìŠ¤í¬ë¦½íŠ¸
Phase 2.6: Streaming Thesis ì „ ì¸¡ì •
"""
import os
import sys
import time
from pathlib import Path

# Add project root to path
repo_root = Path(__file__).resolve().parent.parent / "fdo_agi_repo"
sys.path.insert(0, str(repo_root))

import google.generativeai as genai  # type: ignore[import]

def measure_baseline_ttft():
    """ê¸°ì¡´ non-streaming TTFT ì¸¡ì •"""
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ GOOGLE_API_KEY not set")
        return
    
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel("gemini-2.0-flash")
    
    prompt = (
        "# ì‘ì—…: AGI ìê¸°êµì • ë£¨í”„ ì‹¤ì¦ 3ë¬¸ì¥ ì‘ì„±\n\n"
        "## ì¦ê±°\n"
        "[ì°¸ê³  #1] resonance_ledger.jsonlì—ì„œ ìµœê·¼ 50ê°œ event ë¶„ì„...\n"
        "[ì°¸ê³  #2] íŒŒì´í”„ë¼ì¸ êµ¬ì¡°ìƒ Thesis â†’ Antithesis â†’ Synthesis ìˆœì„œ...\n\n"
        "ìœ„ ì¦ê±°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **êµ¬ì²´ì  ì‘ì—… ê³„íš 3ë¬¸ì¥**ì„ ì‘ì„±í•˜ì„¸ìš”.\n"
        "(ê° ë¬¸ì¥ì€ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”. ì˜ˆ: [ì°¸ê³  #1]ì— ë”°ë¥´ë©´...)"
    )
    
    print("ğŸ” Baseline TTFT ì¸¡ì • ì‹œì‘...")
    print(f"   Prompt: {len(prompt)} chars")
    print()
    
    results = []
    for i in range(3):
        t0 = time.perf_counter()
        try:
            response = model.generate_content(prompt)
            t1 = time.perf_counter()
            total_time = t1 - t0
            text = response.text
            token_count = len(text.split())  # Rough estimate
            
            results.append({
                "run": i + 1,
                "total_time": total_time,
                "ttft": total_time,  # Non-streaming: TTFT = Total
                "tokens": token_count,
                "chars": len(text)
            })
            
            print(f"Run {i+1}: {total_time:.2f}s, {token_count} tokens, {len(text)} chars")
        except Exception as e:
            print(f"Run {i+1}: âŒ {e}")
    
    if results:
        avg_total = sum(r["total_time"] for r in results) / len(results)
        avg_tokens = sum(r["tokens"] for r in results) / len(results)
        
        print()
        print("ğŸ“Š Baseline í†µê³„:")
        print(f"   Average Total Time: {avg_total:.2f}s")
        print(f"   Average Tokens: {avg_tokens:.0f}")
        print(f"   TTFT (non-streaming): {avg_total:.2f}s (= Total Time)")
        print()
        print("ğŸ¯ ëª©í‘œ: Streamingìœ¼ë¡œ TTFTë¥¼ 50% ê°ì†Œ (ì˜ˆ: 5s â†’ 2.5s)")

def measure_streaming_ttft():
    """Streaming TTFT ì¸¡ì •"""
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ GOOGLE_API_KEY not set")
        return
    
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel("gemini-2.0-flash")
    
    prompt = (
        "# ì‘ì—…: AGI ìê¸°êµì • ë£¨í”„ ì‹¤ì¦ 3ë¬¸ì¥ ì‘ì„±\n\n"
        "## ì¦ê±°\n"
        "[ì°¸ê³  #1] resonance_ledger.jsonlì—ì„œ ìµœê·¼ 50ê°œ event ë¶„ì„...\n"
        "[ì°¸ê³  #2] íŒŒì´í”„ë¼ì¸ êµ¬ì¡°ìƒ Thesis â†’ Antithesis â†’ Synthesis ìˆœì„œ...\n\n"
        "ìœ„ ì¦ê±°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **êµ¬ì²´ì  ì‘ì—… ê³„íš 3ë¬¸ì¥**ì„ ì‘ì„±í•˜ì„¸ìš”.\n"
        "(ê° ë¬¸ì¥ì€ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”. ì˜ˆ: [ì°¸ê³  #1]ì— ë”°ë¥´ë©´...)"
    )
    
    print("ğŸ” Streaming TTFT ì¸¡ì • ì‹œì‘...")
    print(f"   Prompt: {len(prompt)} chars")
    print()
    
    results = []
    for i in range(3):
        t0 = time.perf_counter()
        ttft = None
        chunks = []
        
        try:
            response = model.generate_content(prompt, stream=True)
            for chunk in response:
                if ttft is None:
                    ttft = time.perf_counter() - t0
                    print(f"   âš¡ First token at {ttft:.3f}s")
                
                if hasattr(chunk, 'text'):
                    chunks.append(chunk.text)
            
            t1 = time.perf_counter()
            total_time = t1 - t0
            text = "".join(chunks)
            token_count = len(text.split())
            
            results.append({
                "run": i + 1,
                "total_time": total_time,
                "ttft": ttft or total_time,
                "tokens": token_count,
                "chars": len(text)
            })
            
            print(f"Run {i+1}: Total {total_time:.2f}s, TTFT {ttft:.3f}s, {token_count} tokens")
        except Exception as e:
            print(f"Run {i+1}: âŒ {e}")
    
    if results:
        avg_total = sum(r["total_time"] for r in results) / len(results)
        avg_ttft = sum(r["ttft"] for r in results) / len(results)
        avg_tokens = sum(r["tokens"] for r in results) / len(results)
        
        print()
        print("ğŸ“Š Streaming í†µê³„:")
        print(f"   Average Total Time: {avg_total:.2f}s")
        print(f"   Average TTFT: {avg_ttft:.3f}s")
        print(f"   Average Tokens: {avg_tokens:.0f}")
        print(f"   Perceived Improvement: {(1 - avg_ttft/avg_total)*100:.1f}%")

if __name__ == "__main__":
    mode = sys.argv[1] if len(sys.argv) > 1 else "baseline"
    
    if mode == "streaming":
        measure_streaming_ttft()
    else:
        measure_baseline_ttft()
