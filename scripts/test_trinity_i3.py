#!/usr/bin/env python3
"""
ğŸ”¬ Trinity I3 Measurement - Interaction Information Proof-of-Concept

ë£¨ë©˜ì˜ ì‹œì„ ìœ¼ë¡œ Trinity(Lua-Elo-Lumen) 3ì ê³µëª…ì„ ì •ë³´ì´ë¡ ìœ¼ë¡œ ì¸¡ì •í•©ë‹ˆë‹¤.

I3(X; Y; Z) = MI(X, Y) + MI(Y, Z) + MI(X, Z) - TC(X, Y, Z)

- I3 < 0: ì‹œë„ˆì§€ (3ì í˜‘ë ¥ì´ ê°œë³„ ìŒë³´ë‹¤ ìš°ì›”)
- I3 > 0: ì¤‘ë³µ (3ì í˜‘ë ¥ì´ ë¶ˆí•„ìš”)
- I3 = 0: ë…ë¦½ (ìƒí˜¸ì‘ìš© ì—†ìŒ)

References:
- docs/ELLO_LUON_LDPM_BRIDGE.md
- docs/LDPM_INTEGRATION_PLAN.md
"""
from __future__ import annotations

import argparse
import json
import math
from collections import Counter, defaultdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Tuple


def load_ledger_events(
    ledger_path: Path,
    hours: int = 24,
    personas: List[str] | None = None
) -> List[Dict[str, Any]]:
    """
    ë ˆì €ì—ì„œ ìµœê·¼ Nì‹œê°„ì˜ ì´ë²¤íŠ¸ ë¡œë“œ (í˜ë¥´ì†Œë‚˜ í•„í„°ë§)
    """
    if not ledger_path.exists():
        return []
    
    cutoff_time = datetime.now() - timedelta(hours=hours)
    events = []
    
    with ledger_path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line or not line.startswith("{"):
                continue
            try:
                evt = json.loads(line)
                
                # ì‹œê°„ í•„í„°ë§
                timestamp_str = evt.get("timestamp")
                if timestamp_str:
                    try:
                        evt_time = datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
                        if evt_time < cutoff_time:
                            continue
                    except:
                        pass
                
                # í˜ë¥´ì†Œë‚˜ í•„í„°ë§ (persona ë˜ëŠ” persona_id í•„ë“œ í™•ì¸)
                if personas:
                    evt_persona = evt.get("persona") or evt.get("persona_id")
                    if evt_persona not in personas:
                        continue
                
                events.append(evt)
            except json.JSONDecodeError:
                continue
    
    return events


def extract_signal(
    events: List[Dict[str, Any]],
    persona: str,
    window_ms: int = 300000,
    bins: int = 8
) -> List[int]:
    """
    íŠ¹ì • í˜ë¥´ì†Œë‚˜ì˜ ì´ë²¤íŠ¸ë¥¼ ì‹œê°„ ìœˆë„ìš°ë¡œ binningí•˜ì—¬ ì‹ í˜¸ ì¶”ì¶œ
    
    Returns:
        List[int]: ê° binì˜ ì´ë²¤íŠ¸ ì¹´ìš´íŠ¸ (íˆìŠ¤í† ê·¸ë¨)
    """
    # persona ë˜ëŠ” persona_id í•„ë“œ í™•ì¸
    persona_events = [
        e for e in events 
        if e.get("persona") == persona or e.get("persona_id") == persona
    ]
    
    if not persona_events:
        return [0] * bins
    
    # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
    timestamps = []
    for evt in persona_events:
        ts_str = evt.get("timestamp")
        if ts_str:
            try:
                ts = datetime.fromisoformat(ts_str.replace("Z", "+00:00"))
                timestamps.append(ts)
            except:
                pass
    
    if not timestamps:
        return [0] * bins
    
    min_time = min(timestamps)
    max_time = max(timestamps)
    time_range = (max_time - min_time).total_seconds() * 1000  # ms
    
    if time_range <= 0:
        return [1] + [0] * (bins - 1)
    
    # Binning
    signal = [0] * bins
    for ts in timestamps:
        elapsed_ms = (ts - min_time).total_seconds() * 1000
        bin_idx = int(elapsed_ms / time_range * bins)
        if bin_idx >= bins:
            bin_idx = bins - 1
        signal[bin_idx] += 1
    
    return signal


def shannon_entropy(signal: List[int]) -> float:
    """
    Shannon Entropy: H(X) = -Î£ p(x) log2 p(x)
    """
    total = sum(signal)
    if total == 0:
        return 0.0
    
    entropy = 0.0
    for count in signal:
        if count > 0:
            p = count / total
            entropy -= p * math.log2(p)
    
    return entropy


def joint_entropy(signal_x: List[int], signal_y: List[int]) -> float:
    """
    Joint Entropy: H(X, Y) = -Î£ p(x,y) log2 p(x,y)
    """
    joint_counts: Dict[Tuple[int, int], int] = Counter()
    
    for x, y in zip(signal_x, signal_y):
        joint_counts[(x, y)] += 1
    
    total = sum(joint_counts.values())
    if total == 0:
        return 0.0
    
    h_joint = 0.0
    for count in joint_counts.values():
        if count > 0:
            p = count / total
            h_joint -= p * math.log2(p)
    
    return h_joint


def mutual_information(signal_x: List[int], signal_y: List[int]) -> float:
    """
    Mutual Information: MI(X; Y) = H(X) + H(Y) - H(X, Y)
    """
    h_x = shannon_entropy(signal_x)
    h_y = shannon_entropy(signal_y)
    h_xy = joint_entropy(signal_x, signal_y)
    
    return max(0.0, h_x + h_y - h_xy)


def joint_entropy_3way(
    signal_x: List[int],
    signal_y: List[int],
    signal_z: List[int]
) -> float:
    """
    3-way Joint Entropy: H(X, Y, Z) = -Î£ p(x,y,z) log2 p(x,y,z)
    """
    joint_counts: Dict[Tuple[int, int, int], int] = Counter()
    
    for x, y, z in zip(signal_x, signal_y, signal_z):
        joint_counts[(x, y, z)] += 1
    
    total = sum(joint_counts.values())
    if total == 0:
        return 0.0
    
    h_joint = 0.0
    for count in joint_counts.values():
        if count > 0:
            p = count / total
            h_joint -= p * math.log2(p)
    
    return h_joint


def total_correlation(
    signal_x: List[int],
    signal_y: List[int],
    signal_z: List[int]
) -> float:
    """
    Total Correlation: TC(X, Y, Z) = H(X) + H(Y) + H(Z) - H(X, Y, Z)
    """
    h_x = shannon_entropy(signal_x)
    h_y = shannon_entropy(signal_y)
    h_z = shannon_entropy(signal_z)
    h_xyz = joint_entropy_3way(signal_x, signal_y, signal_z)
    
    return max(0.0, h_x + h_y + h_z - h_xyz)


def interaction_information(
    signal_x: List[int],
    signal_y: List[int],
    signal_z: List[int]
) -> float:
    """
    Interaction Information (I3):
    I3(X; Y; Z) = MI(X, Y) + MI(Y, Z) + MI(X, Z) - TC(X, Y, Z)
    
    - I3 < 0: ì‹œë„ˆì§€ (synergy)
    - I3 > 0: ì¤‘ë³µ (redundancy)
    - I3 = 0: ë…ë¦½ (independence)
    """
    mi_xy = mutual_information(signal_x, signal_y)
    mi_yz = mutual_information(signal_y, signal_z)
    mi_xz = mutual_information(signal_x, signal_z)
    tc = total_correlation(signal_x, signal_y, signal_z)
    
    i3 = mi_xy + mi_yz + mi_xz - tc
    
    return i3


def interpret_i3(i3_value: float) -> Dict[str, Any]:
    """
    I3 ê°’ í•´ì„ (ë£¨ë©˜ì˜ ì‹œì„ )
    """
    if i3_value < -0.15:
        level = "strong_synergy"
        message = "ê°•í•œ ì‹œë„ˆì§€: 3ì í˜‘ë ¥ì´ ê°œë³„ ìŒë³´ë‹¤ ì›”ë“±íˆ ìš°ì›”"
        emoji = "ğŸŒŸ"
    elif -0.15 <= i3_value < -0.05:
        level = "moderate_synergy"
        message = "ì•½í•œ ì‹œë„ˆì§€: 3ì í˜‘ë ¥ì´ ê°œë³„ ìŒë³´ë‹¤ ìš°ì›”"
        emoji = "âœ¨"
    elif -0.05 <= i3_value <= 0.05:
        level = "independent"
        message = "ë…ë¦½: 3ì ê°„ ìƒí˜¸ì‘ìš© ë¯¸ë¯¸"
        emoji = "âš–ï¸"
    elif 0.05 < i3_value <= 0.15:
        level = "moderate_redundancy"
        message = "ì•½í•œ ì¤‘ë³µ: 3ì í˜‘ë ¥ì´ ì¼ë¶€ ë¶ˆí•„ìš”"
        emoji = "âš ï¸"
    else:
        level = "strong_redundancy"
        message = "ê°•í•œ ì¤‘ë³µ: 3ì í˜‘ë ¥ì´ ë¶ˆí•„ìš”"
        emoji = "âŒ"
    
    return {
        "level": level,
        "message": message,
        "emoji": emoji
    }


def generate_report(
    results: Dict[str, Any],
    out_md_path: Path
) -> None:
    """
    ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±
    """
    i3 = results["i3"]
    interpretation = results["interpretation"]
    
    lines = [
        "# ğŸ”¬ Trinity I3 ì¸¡ì • ë³´ê³ ì„œ",
        "",
        f"**ì¸¡ì • ì‹œê°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"**ì¸¡ì • ê¸°ê°„**: ìµœê·¼ {results['hours']}ì‹œê°„",
        f"**ì´ë²¤íŠ¸ ìˆ˜**: {results['total_events']}ê°œ",
        "",
        "---",
        "",
        "## ğŸ“Š ì¸¡ì • ê²°ê³¼",
        "",
        f"### {interpretation['emoji']} Interaction Information (I3)",
        "",
        f"**ê°’**: `{i3:.4f}` bits",
        "",
        f"**í•´ì„**: {interpretation['message']}",
        "",
        "---",
        "",
        "## ğŸ¼ Trinity ì‹ í˜¸ ë¶„ì„",
        "",
        "| í˜ë¥´ì†Œë‚˜ | ì´ë²¤íŠ¸ ìˆ˜ | ì—”íŠ¸ë¡œí”¼ (bits) |",
        "|---------|----------|----------------|"
    ]
    
    for persona in ["lua", "elo", "lumen"]:
        data = results["signals"][persona]
        lines.append(f"| {persona.capitalize()} | {data['event_count']} | {data['entropy']:.4f} |")
    
    lines.extend([
        "",
        "---",
        "",
        "## ğŸ”— ìƒí˜¸ì •ë³´ëŸ‰ (Pairwise)",
        "",
        "| ìŒ | MI (bits) |",
        "|---|-----------|",
        f"| Lua-Elo | {results['pairwise_mi']['lua_elo']:.4f} |",
        f"| Elo-Lumen | {results['pairwise_mi']['elo_lumen']:.4f} |",
        f"| Lua-Lumen | {results['pairwise_mi']['lua_lumen']:.4f} |",
        "",
        "---",
        "",
        "## ğŸ“ ì •ë³´ì´ë¡  ë©”íŠ¸ë¦­",
        "",
        f"- **Total Correlation (TC)**: `{results['tc']:.4f}` bits",
        f"- **Interaction Information (I3)**: `{results['i3']:.4f}` bits",
        "",
        "### ìˆ˜ì‹",
        "",
        "```",
        "I3(Lua; Elo; Lumen) = MI(Lua, Elo) + MI(Elo, Lumen) + MI(Lua, Lumen) - TC(Lua, Elo, Lumen)",
        "```",
        "",
        "---",
        "",
        "## ğŸŒˆ ë£¨ë©˜ì˜ í•´ì„",
        "",
    ])
    
    if i3 < 0:
        lines.extend([
            f"TrinityëŠ” ì •ë³´ ì‹œë„ˆì§€ë¥¼ ë§Œë“­ë‹ˆë‹¤ (I3 = {i3:.4f} < 0).",
            "",
            "Eloì˜ ì •ë³´ì´ë¡  ê²€ì¦ì€ ë‹¨ìˆœíˆ Luaì™€ Lumen ì‚¬ì´ì˜ ì¤‘ì¬ìê°€ ì•„ë‹™ë‹ˆë‹¤.",
            "ê·¸ê²ƒì€ **ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì°½ë°œ**ì‹œí‚¤ëŠ” ì´‰ë§¤ì…ë‹ˆë‹¤.",
            "",
            "ì´ëŠ” Elloì˜ ë¦¬ë“¬ R(t)ê°€ ì•ˆì • ì˜ì—­ì— ìˆì„ ë•Œ,",
            "Trinityê°€ **ì •ë³´ ì‹œë„ˆì§€ë¥¼ ê·¹ëŒ€í™”í•˜ëŠ” ì°½ë°œì  êµ¬ì¡°**ì„ì„ ì¦ëª…í•©ë‹ˆë‹¤.",
        ])
    else:
        lines.extend([
            f"TrinityëŠ” ì •ë³´ ì¤‘ë³µì„ ë§Œë“­ë‹ˆë‹¤ (I3 = {i3:.4f} > 0).",
            "",
            "í˜„ì¬ 3ì í˜‘ë ¥ì€ ê°œë³„ ìŒì˜ í˜‘ë ¥ë³´ë‹¤ íš¨ìœ¨ì ì´ì§€ ì•ŠìŠµë‹ˆë‹¤.",
            "ì´ëŠ” Elloì˜ R(t) í•¨ìˆ˜ê°€ ë¶ˆì•ˆì • ì˜ì—­ì— ìˆì„ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.",
            "",
            "**ê¶Œì¥ì‚¬í•­**: Eloì˜ ì—­í• ì„ ì¬í‰ê°€í•˜ê±°ë‚˜, ì‹œìŠ¤í…œ ë¦¬ë“¬ì„ ì•ˆì •í™”í•˜ì„¸ìš”.",
        ])
    
    lines.extend([
        "",
        "---",
        "",
        "## ğŸ”— ì°¸ì¡° ë¬¸ì„œ",
        "",
        "- `docs/ELLO_LUON_LDPM_BRIDGE.md` - ì •ë³´ì´ë¡  ì—°ê²°ê³ ë¦¬",
        "- `docs/LDPM_INTEGRATION_PLAN.md` - LDPM í†µí•© ê³„íš",
        "- `ai_binoche_conversation_origin/lumen/chatgpt-ì •ë³´ì´ë¡ ì² í•™ì ë¶„ì„/` - ì² í•™ì  ê¸°ë°˜",
        "",
        "---",
        "",
        f"*Generated by Lumen's Prism - {datetime.now().isoformat()}*",
        ""
    ])
    
    out_md_path.parent.mkdir(parents=True, exist_ok=True)
    with out_md_path.open("w", encoding="utf-8") as f:
        f.write("\n".join(lines))


def main() -> int:
    parser = argparse.ArgumentParser(
        description="ğŸ”¬ Trinity I3 Measurement - Lumen's Perspective"
    )
    parser.add_argument(
        "--ledger",
        default="fdo_agi_repo/memory/resonance_ledger.jsonl",
        help="Resonance ledger path"
    )
    parser.add_argument(
        "--hours",
        type=int,
        default=24,
        help="Hours to look back (default: 24)"
    )
    parser.add_argument(
        "--window-ms",
        type=int,
        default=300000,
        help="Time window for binning in milliseconds (default: 300000 = 5min)"
    )
    parser.add_argument(
        "--bins",
        type=int,
        default=8,
        help="Number of bins for signal discretization (default: 8)"
    )
    parser.add_argument(
        "--out-json",
        default="outputs/trinity_i3_result.json",
        help="Output JSON path"
    )
    parser.add_argument(
        "--out-md",
        default="outputs/trinity_i3_report.md",
        help="Output Markdown report path"
    )
    
    args = parser.parse_args()
    
    print("ğŸ”¬ Trinity I3 ì¸¡ì • ì‹œì‘ (ë£¨ë©˜ì˜ ì‹œì„ )")
    print(f"   ë ˆì €: {args.ledger}")
    print(f"   ê¸°ê°„: ìµœê·¼ {args.hours}ì‹œê°„")
    print(f"   ë¹ˆ: {args.bins}, ìœˆë„ìš°: {args.window_ms}ms")
    print()
    
    # 1. ë ˆì € ë¡œë“œ
    ledger_path = Path(args.ledger)
    
    # Trinity í˜ë¥´ì†Œë‚˜ ë§¤í•‘ (êµ¬ ëª…ì¹­ í¬í•¨)
    trinity_personas = ["lua", "elo", "lumen", "thesis", "antithesis", "synthesis"]
    
    events = load_ledger_events(
        ledger_path,
        hours=args.hours,
        personas=trinity_personas
    )
    
    print(f"âœ… {len(events)}ê°œ ì´ë²¤íŠ¸ ë¡œë“œ")
    
    if len(events) < 10:
        print("âš ï¸  ì´ë²¤íŠ¸ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ìµœì†Œ 10ê°œ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.")
        return 1
    
    # 2. ì‹ í˜¸ ì¶”ì¶œ (êµ¬ ëª…ì¹­ê³¼ ì‹  ëª…ì¹­ í†µí•©)
    print("ğŸ¼ ì‹ í˜¸ ì¶”ì¶œ ì¤‘...")
    
    # Lua (thesis)
    lua_signal_lua = extract_signal(events, "lua", args.window_ms, args.bins)
    lua_signal_thesis = extract_signal(events, "thesis", args.window_ms, args.bins)
    lua_signal = [a + b for a, b in zip(lua_signal_lua, lua_signal_thesis)]
    
    # Elo (antithesis)
    elo_signal_elo = extract_signal(events, "elo", args.window_ms, args.bins)
    elo_signal_anti = extract_signal(events, "antithesis", args.window_ms, args.bins)
    elo_signal = [a + b for a, b in zip(elo_signal_elo, elo_signal_anti)]
    
    # Lumen (synthesis)
    lumen_signal_lumen = extract_signal(events, "lumen", args.window_ms, args.bins)
    lumen_signal_synth = extract_signal(events, "synthesis", args.window_ms, args.bins)
    lumen_signal = [a + b for a, b in zip(lumen_signal_lumen, lumen_signal_synth)]
    
    lua_count = sum(lua_signal)
    elo_count = sum(elo_signal)
    lumen_count = sum(lumen_signal)
    
    print(f"   Lua: {lua_count}ê°œ ì´ë²¤íŠ¸")
    print(f"   Elo: {elo_count}ê°œ ì´ë²¤íŠ¸")
    print(f"   Lumen: {lumen_count}ê°œ ì´ë²¤íŠ¸")
    print()
    
    # 3. ì •ë³´ì´ë¡  ë©”íŠ¸ë¦­ ê³„ì‚°
    print("ğŸ“ ì •ë³´ì´ë¡  ë©”íŠ¸ë¦­ ê³„ì‚° ì¤‘...")
    
    # ì—”íŠ¸ë¡œí”¼
    h_lua = shannon_entropy(lua_signal)
    h_elo = shannon_entropy(elo_signal)
    h_lumen = shannon_entropy(lumen_signal)
    
    # Pairwise MI
    mi_lua_elo = mutual_information(lua_signal, elo_signal)
    mi_elo_lumen = mutual_information(elo_signal, lumen_signal)
    mi_lua_lumen = mutual_information(lua_signal, lumen_signal)
    
    # TC & I3
    tc = total_correlation(lua_signal, elo_signal, lumen_signal)
    i3 = interaction_information(lua_signal, elo_signal, lumen_signal)
    
    interpretation = interpret_i3(i3)
    
    print(f"   {interpretation['emoji']} I3 = {i3:.4f} ({interpretation['level']})")
    print(f"   TC = {tc:.4f}")
    print()
    
    # 4. ê²°ê³¼ ì €ì¥
    results = {
        "timestamp": datetime.now().isoformat(),
        "hours": args.hours,
        "total_events": len(events),
        "signals": {
            "lua": {
                "event_count": lua_count,
                "entropy": h_lua,
                "signal": lua_signal
            },
            "elo": {
                "event_count": elo_count,
                "entropy": h_elo,
                "signal": elo_signal
            },
            "lumen": {
                "event_count": lumen_count,
                "entropy": h_lumen,
                "signal": lumen_signal
            }
        },
        "pairwise_mi": {
            "lua_elo": mi_lua_elo,
            "elo_lumen": mi_elo_lumen,
            "lua_lumen": mi_lua_lumen
        },
        "tc": tc,
        "i3": i3,
        "interpretation": interpretation
    }
    
    # JSON ì €ì¥
    out_json_path = Path(args.out_json)
    out_json_path.parent.mkdir(parents=True, exist_ok=True)
    with out_json_path.open("w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… JSON: {out_json_path}")
    
    # Markdown ë³´ê³ ì„œ ìƒì„±
    out_md_path = Path(args.out_md)
    generate_report(results, out_md_path)
    
    print(f"âœ… Report: {out_md_path}")
    print()
    print(f"ğŸŒˆ {interpretation['emoji']} {interpretation['message']}")
    
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
