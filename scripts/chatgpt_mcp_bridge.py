#!/usr/bin/env python3
"""
ChatGPT + OpenAI API + MCP Integration Bridge
==============================================

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ChatGPTì™€ OpenAI APIë¥¼ MCP(Model Context Protocol)ì™€ í†µí•©í•˜ì—¬
ìë™í™”ëœ AI ì›Œí¬í”Œë¡œìš°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. ChatGPT ëŒ€í™”ë¥¼ MCP ë„êµ¬ë¡œ ë³€í™˜
2. OpenAI APIë¥¼ í†µí•œ ìë™ ì‘ë‹µ ìƒì„±
3. Lua ìŠ¤í¬ë¦½íŠ¸ì™€ì˜ ë¸Œë¦¿ì§€ ì—°ê²°
4. VS Code ì•¡ì…˜ ìë™ ì‹¤í–‰

Author: Ruafieldphase
Date: 2025-11-14
Philosophy: Connectivity > Depth
"""

import json
import os
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
import re

# OpenAI API
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸  OpenAI not installed. Run: pip install openai")


class ChatGPTMCPBridge:
    """ChatGPT + OpenAI API + MCP í†µí•© ë¸Œë¦¿ì§€"""
    
    def __init__(self, workspace_root: Path):
        self.workspace = workspace_root
        self.outputs_dir = workspace_root / "outputs" / "chatgpt_mcp"
        self.outputs_dir.mkdir(parents=True, exist_ok=True)
        
        # ë¡œê·¸ íŒŒì¼
        self.conversation_log = self.outputs_dir / "conversations.jsonl"
        self.mcp_actions_log = self.outputs_dir / "mcp_actions.jsonl"
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = None
        if OPENAI_AVAILABLE:
            api_key = os.environ.get("OPENAI_API_KEY")
            if api_key:
                self.client = OpenAI(api_key=api_key)
                print("âœ… OpenAI API initialized")
            else:
                print("âš ï¸  OPENAI_API_KEY not found in environment")
        
        # MCP ë„êµ¬ ë§¤í•‘
        self.mcp_tools = {
            "create_file": self._mcp_create_file,
            "read_file": self._mcp_read_file,
            "edit_file": self._mcp_edit_file,
            "run_command": self._mcp_run_command,
            "search_code": self._mcp_search_code,
            "open_browser": self._mcp_open_browser,
        }
    
    def chat_with_gpt(self, prompt: str, model: str = "gpt-4o-mini") -> Optional[str]:
        """OpenAI ChatGPT API í˜¸ì¶œ"""
        if not self.client:
            print("âŒ OpenAI client not initialized")
            return None
        
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "You are a helpful AI assistant integrated with VS Code."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            answer = response.choices[0].message.content
            
            # ë¡œê·¸ ì €ì¥
            self._log_conversation(prompt, answer, model)
            
            return answer
        
        except Exception as e:
            print(f"âŒ OpenAI API error: {e}")
            return None
    
    def extract_mcp_actions(self, text: str) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ì—ì„œ MCP ì•¡ì…˜ ì¶”ì¶œ"""
        actions = []
        
        # íŒŒì¼ ìƒì„± íŒ¨í„´
        create_file_pattern = r"create.*?file.*?[`'\"]([^`'\"]+)[`'\"]"
        for match in re.finditer(create_file_pattern, text, re.IGNORECASE):
            actions.append({
                "type": "create_file",
                "file_path": match.group(1),
                "content": ""  # ë‚´ìš©ì€ ë³„ë„ ì¶”ì¶œ í•„ìš”
            })
        
        # íŒŒì¼ í¸ì§‘ íŒ¨í„´
        edit_pattern = r"edit.*?[`'\"]([^`'\"]+)[`'\"]"
        for match in re.finditer(edit_pattern, text, re.IGNORECASE):
            actions.append({
                "type": "edit_file",
                "file_path": match.group(1)
            })
        
        # ëª…ë ¹ ì‹¤í–‰ íŒ¨í„´
        run_pattern = r"run.*?[`'\"]([^`'\"]+)[`'\"]"
        for match in re.finditer(run_pattern, text, re.IGNORECASE):
            actions.append({
                "type": "run_command",
                "command": match.group(1)
            })
        
        return actions
    
    def execute_mcp_action(self, action: Dict[str, Any]) -> Dict[str, Any]:
        """MCP ì•¡ì…˜ ì‹¤í–‰"""
        action_type = action.get("type")
        
        if action_type not in self.mcp_tools:
            return {
                "success": False,
                "error": f"Unknown action type: {action_type}"
            }
        
        try:
            result = self.mcp_tools[action_type](action)
            
            # ì•¡ì…˜ ë¡œê·¸ ì €ì¥
            self._log_mcp_action(action, result)
            
            return result
        
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def process_conversation(self, user_input: str, auto_execute: bool = False) -> Dict[str, Any]:
        """
        ëŒ€í™” ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°
        1. ChatGPTì— ì§ˆë¬¸
        2. ì‘ë‹µì—ì„œ MCP ì•¡ì…˜ ì¶”ì¶œ
        3. (ì„ íƒì ) ìë™ ì‹¤í–‰
        """
        print(f"\nğŸ’¬ User: {user_input}")
        
        # 1. ChatGPT ì‘ë‹µ
        gpt_response = self.chat_with_gpt(user_input)
        if not gpt_response:
            return {"success": False, "error": "Failed to get GPT response"}
        
        print(f"ğŸ¤– GPT: {gpt_response[:200]}...")
        
        # 2. MCP ì•¡ì…˜ ì¶”ì¶œ
        actions = self.extract_mcp_actions(gpt_response)
        print(f"\nğŸ”§ Extracted {len(actions)} MCP actions")
        
        # 3. ìë™ ì‹¤í–‰
        results = []
        if auto_execute and actions:
            print("\nâš¡ Auto-executing actions...")
            for i, action in enumerate(actions, 1):
                print(f"  {i}. {action['type']}: {action.get('file_path', action.get('command', ''))}")
                result = self.execute_mcp_action(action)
                results.append(result)
                
                if result.get("success"):
                    print(f"     âœ… Success")
                else:
                    print(f"     âŒ Failed: {result.get('error')}")
        
        return {
            "success": True,
            "gpt_response": gpt_response,
            "actions": actions,
            "execution_results": results if auto_execute else None
        }
    
    # MCP ë„êµ¬ êµ¬í˜„
    
    def _mcp_create_file(self, action: Dict[str, Any]) -> Dict[str, Any]:
        """íŒŒì¼ ìƒì„± (MCP ë„êµ¬)"""
        file_path = self.workspace / action["file_path"]
        content = action.get("content", "")
        
        try:
            file_path.parent.mkdir(parents=True, exist_ok=True)
            file_path.write_text(content, encoding='utf-8')
            return {"success": True, "file_path": str(file_path)}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _mcp_read_file(self, action: Dict[str, Any]) -> Dict[str, Any]:
        """íŒŒì¼ ì½ê¸° (MCP ë„êµ¬)"""
        file_path = self.workspace / action["file_path"]
        
        try:
            content = file_path.read_text(encoding='utf-8')
            return {"success": True, "content": content}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _mcp_edit_file(self, action: Dict[str, Any]) -> Dict[str, Any]:
        """íŒŒì¼ í¸ì§‘ (MCP ë„êµ¬)"""
        # ê°„ë‹¨ êµ¬í˜„: íŒŒì¼ ì¡´ì¬ í™•ì¸ë§Œ
        file_path = self.workspace / action["file_path"]
        return {"success": file_path.exists(), "file_path": str(file_path)}
    
    def _mcp_run_command(self, action: Dict[str, Any]) -> Dict[str, Any]:
        """ëª…ë ¹ ì‹¤í–‰ (MCP ë„êµ¬)"""
        # ë³´ì•ˆìƒ ì‹¤ì œ ì‹¤í–‰ì€ í•˜ì§€ ì•Šê³  ë¡œê·¸ë§Œ
        return {"success": True, "command": action["command"], "note": "Command logged, not executed"}
    
    def _mcp_search_code(self, action: Dict[str, Any]) -> Dict[str, Any]:
        """ì½”ë“œ ê²€ìƒ‰ (MCP ë„êµ¬)"""
        query = action.get("query", "")
        return {"success": True, "query": query, "note": "Search logged"}
    
    def _mcp_open_browser(self, action: Dict[str, Any]) -> Dict[str, Any]:
        """ë¸Œë¼ìš°ì € ì—´ê¸° (MCP ë„êµ¬)"""
        url = action.get("url", "")
        return {"success": True, "url": url, "note": "Browser action logged"}
    
    # ë¡œê¹…
    
    def _log_conversation(self, prompt: str, response: str, model: str):
        """ëŒ€í™” ë¡œê·¸"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "prompt": prompt,
            "response": response,
            "model": model
        }
        
        with open(self.conversation_log, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
    
    def _log_mcp_action(self, action: Dict[str, Any], result: Dict[str, Any]):
        """MCP ì•¡ì…˜ ë¡œê·¸"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "action": action,
            "result": result
        }
        
        with open(self.mcp_actions_log, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')


class LuaBridgeIntegration:
    """Lua ìŠ¤í¬ë¦½íŠ¸ì™€ì˜ ë¸Œë¦¿ì§€ í†µí•©"""
    
    def __init__(self, workspace_root: Path):
        self.workspace = workspace_root
        self.lua_requests_dir = workspace_root / "outputs" / "lua_requests"
        self.lua_responses_dir = workspace_root / "outputs" / "lua_responses"
        
        self.lua_requests_dir.mkdir(parents=True, exist_ok=True)
        self.lua_responses_dir.mkdir(parents=True, exist_ok=True)
        
        self.bridge = ChatGPTMCPBridge(workspace_root)
    
    def process_lua_request(self, request_file: Path) -> Optional[Path]:
        """Lua ìš”ì²­ íŒŒì¼ ì²˜ë¦¬"""
        try:
            request_data = json.loads(request_file.read_text(encoding='utf-8'))
            
            prompt = request_data.get("prompt", "")
            request_id = request_data.get("request_id", "")
            
            # ChatGPT + MCP ì²˜ë¦¬
            result = self.bridge.process_conversation(prompt, auto_execute=False)
            
            # Lua ì‘ë‹µ íŒŒì¼ ìƒì„±
            response_file = self.lua_responses_dir / f"response_{request_id}.json"
            response_data = {
                "request_id": request_id,
                "timestamp": datetime.now().isoformat(),
                "success": result.get("success", False),
                "response": result.get("gpt_response", ""),
                "actions": result.get("actions", [])
            }
            
            response_file.write_text(json.dumps(response_data, ensure_ascii=False, indent=2), encoding='utf-8')
            
            print(f"âœ… Lua response created: {response_file.name}")
            return response_file
        
        except Exception as e:
            print(f"âŒ Error processing Lua request: {e}")
            return None
    
    def monitor_lua_requests(self, interval_seconds: int = 5):
        """Lua ìš”ì²­ ëª¨ë‹ˆí„°ë§ (ë°±ê·¸ë¼ìš´ë“œ)"""
        print(f"ğŸ” Monitoring Lua requests (interval: {interval_seconds}s)")
        print(f"   Watching: {self.lua_requests_dir}")
        
        processed_files = set()
        
        while True:
            try:
                for request_file in self.lua_requests_dir.glob("*.json"):
                    if request_file in processed_files:
                        continue
                    
                    print(f"\nğŸ“¨ New Lua request: {request_file.name}")
                    response_file = self.process_lua_request(request_file)
                    
                    if response_file:
                        processed_files.add(request_file)
                        # ì²˜ë¦¬ëœ íŒŒì¼ ì´ë™
                        processed_dir = self.lua_requests_dir / "processed"
                        processed_dir.mkdir(exist_ok=True)
                        request_file.rename(processed_dir / request_file.name)
                
                time.sleep(interval_seconds)
            
            except KeyboardInterrupt:
                print("\nğŸ›‘ Monitoring stopped")
                break
            except Exception as e:
                print(f"âŒ Monitor error: {e}")
                time.sleep(interval_seconds)


def main():
    """ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ChatGPT + OpenAI API + MCP Bridge")
    parser.add_argument("--workspace", type=Path, default=Path("c:/workspace/agi"),
                        help="Workspace root directory")
    parser.add_argument("--mode", choices=["chat", "monitor"], default="chat",
                        help="Operation mode")
    parser.add_argument("--prompt", type=str, help="Chat prompt (for chat mode)")
    parser.add_argument("--auto-execute", action="store_true",
                        help="Auto-execute MCP actions")
    parser.add_argument("--interval", type=int, default=5,
                        help="Monitor interval in seconds")
    
    args = parser.parse_args()
    
    if args.mode == "chat":
        # ëŒ€í™” ëª¨ë“œ
        bridge = ChatGPTMCPBridge(args.workspace)
        
        if args.prompt:
            result = bridge.process_conversation(args.prompt, auto_execute=args.auto_execute)
            print(f"\nğŸ“Š Result: {json.dumps(result, indent=2, ensure_ascii=False)}")
        else:
            print("ğŸ’¬ Interactive Chat Mode")
            print("   Type 'quit' to exit\n")
            
            while True:
                try:
                    user_input = input("You: ").strip()
                    if user_input.lower() in ("quit", "exit", "q"):
                        break
                    
                    if not user_input:
                        continue
                    
                    result = bridge.process_conversation(user_input, auto_execute=args.auto_execute)
                
                except KeyboardInterrupt:
                    print("\nğŸ‘‹ Goodbye!")
                    break
    
    elif args.mode == "monitor":
        # Lua ë¸Œë¦¿ì§€ ëª¨ë‹ˆí„°ë§ ëª¨ë“œ
        lua_bridge = LuaBridgeIntegration(args.workspace)
        lua_bridge.monitor_lua_requests(interval_seconds=args.interval)


if __name__ == "__main__":
    main()
