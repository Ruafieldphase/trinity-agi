#!/usr/bin/env python3
"""
Realtime Music Analyzer
ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„ ë° ë¦¬ë“¬ í˜ì´ì¦ˆ ë§¤ì¹­ ì‹œìŠ¤í…œ

- í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ìŒì•…ì˜ í…œí¬/ì—ë„ˆì§€ ì‹¤ì‹œê°„ ë¶„ì„
- ë¦¬ë“¬ í˜ì´ì¦ˆì™€ ë§¤ì¹­ë„ ê³„ì‚°
- ë¶€ì í•©í•œ ìŒì•… ê°ì§€ ì‹œ ìë™ ì „í™˜ ì œì•ˆ
"""

import json
import time
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, Optional, Tuple

try:
    import librosa
    import numpy as np
    import sounddevice as sd
    AUDIO_AVAILABLE = True
except ImportError:
    AUDIO_AVAILABLE = False
    print("âš ï¸ librosa or sounddevice not available. Install with: pip install librosa sounddevice")


class RealtimeMusicAnalyzer:
    """ì‹¤ì‹œê°„ ìŒì•… ë¶„ì„ê¸°"""
    
    def __init__(self, workspace_root: Path):
        self.workspace_root = workspace_root
        self.outputs_dir = workspace_root / "outputs"
        self.rhythm_status_file = self.outputs_dir / "RHYTHM_SYSTEM_STATUS_REPORT.md"
        
        # ë¶„ì„ íŒŒë¼ë¯¸í„°
        self.sample_rate = 22050
        self.buffer_duration = 3  # 3ì´ˆ ë²„í¼
        self.hop_length = 512
        
        # í˜ì´ì¦ˆë³„ ê¸°ì¤€ê°’
        self.phase_criteria = {
            "WAKING": {"bpm": (120, 150), "energy": (0.6, 0.9)},
            "FOCUS": {"bpm": (100, 130), "energy": (0.5, 0.75)},
            "CODING": {"bpm": (90, 120), "energy": (0.4, 0.7)},
            "REST": {"bpm": (60, 90), "energy": (0.2, 0.5)},
            "DEEP_REST": {"bpm": (40, 70), "energy": (0.1, 0.4)},
        }
        
    def get_current_rhythm_phase(self) -> Optional[str]:
        """í˜„ì¬ ë¦¬ë“¬ í˜ì´ì¦ˆ ì½ê¸°"""
        if not self.rhythm_status_file.exists():
            return None
            
        try:
            content = self.rhythm_status_file.read_text(encoding="utf-8")
            # "Current Phase: FOCUS (90.9%)" í˜•ì‹ íŒŒì‹±
            for line in content.split("\n"):
                if "Current Phase:" in line:
                    phase = line.split(":")[1].strip().split()[0]
                    return phase
        except Exception as e:
            print(f"âš ï¸ Failed to read rhythm phase: {e}")
            
        return None
    
    def analyze_audio_buffer(self, audio_data: np.ndarray) -> Dict:
        """ì˜¤ë””ì˜¤ ë²„í¼ ë¶„ì„"""
        if not AUDIO_AVAILABLE:
            return {"error": "librosa not available"}
        
        try:
            # í…œí¬ ì¶”ì •
            tempo, _ = librosa.beat.beat_track(
                y=audio_data, 
                sr=self.sample_rate,
                hop_length=self.hop_length
            )
            
            # ì—ë„ˆì§€ ê³„ì‚° (RMS)
            rms = librosa.feature.rms(
                y=audio_data,
                hop_length=self.hop_length
            )
            energy = float(np.mean(rms))
            
            # ìŠ¤í™íŠ¸ëŸ¼ ì¤‘ì‹¬ (ë°ê¸°)
            spectral_centroid = librosa.feature.spectral_centroid(
                y=audio_data,
                sr=self.sample_rate,
                hop_length=self.hop_length
            )
            brightness = float(np.mean(spectral_centroid))
            
            # ì œë¡œ í¬ë¡œì‹± ë ˆì´íŠ¸ (ë³µì¡ë„)
            zcr = librosa.feature.zero_crossing_rate(
                y=audio_data,
                hop_length=self.hop_length
            )
            complexity = float(np.mean(zcr))
            
            return {
                "tempo": float(tempo),
                "energy": energy,
                "brightness": brightness,
                "complexity": complexity,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {"error": str(e)}
    
    def calculate_phase_match(
        self, 
        music_features: Dict, 
        target_phase: str
    ) -> Tuple[float, str]:
        """ìŒì•… íŠ¹ì„±ê³¼ í˜ì´ì¦ˆ ë§¤ì¹­ë„ ê³„ì‚° (0.0 ~ 1.0)"""
        if target_phase not in self.phase_criteria:
            return 0.0, "Unknown phase"
        
        criteria = self.phase_criteria[target_phase]
        tempo = music_features.get("tempo", 0)
        energy = music_features.get("energy", 0)
        
        # BPM ë§¤ì¹­ë„
        bpm_min, bpm_max = criteria["bpm"]
        if bpm_min <= tempo <= bpm_max:
            bpm_match = 1.0
        elif tempo < bpm_min:
            bpm_match = max(0, 1 - (bpm_min - tempo) / 30)
        else:
            bpm_match = max(0, 1 - (tempo - bpm_max) / 30)
        
        # ì—ë„ˆì§€ ë§¤ì¹­ë„
        energy_min, energy_max = criteria["energy"]
        if energy_min <= energy <= energy_max:
            energy_match = 1.0
        elif energy < energy_min:
            energy_match = max(0, 1 - (energy_min - energy) / 0.3)
        else:
            energy_match = max(0, 1 - (energy - energy_max) / 0.3)
        
        # ì¢…í•© ë§¤ì¹­ë„ (ê°€ì¤‘ í‰ê· )
        overall_match = (bpm_match * 0.6 + energy_match * 0.4)
        
        # íŒì •
        if overall_match >= 0.8:
            verdict = "âœ… EXCELLENT - Perfect match"
        elif overall_match >= 0.6:
            verdict = "âœ“ GOOD - Acceptable match"
        elif overall_match >= 0.4:
            verdict = "âš ï¸ SUBOPTIMAL - Consider switching"
        else:
            verdict = "âŒ POOR - Immediate change recommended"
        
        return overall_match, verdict
    
    def record_audio_sample(self, duration: float = 3.0) -> Optional[np.ndarray]:
        """ë§ˆì´í¬ì—ì„œ ì˜¤ë””ì˜¤ ìƒ˜í”Œ ë…¹ìŒ (ì‹¤ì‹œê°„ ë¶„ì„ìš©)"""
        if not AUDIO_AVAILABLE:
            print("âš ï¸ sounddevice not available")
            return None
        
        try:
            print(f"ğŸ¤ Recording {duration}s audio sample...")
            recording = sd.rec(
                int(duration * self.sample_rate),
                samplerate=self.sample_rate,
                channels=1,
                dtype='float32'
            )
            sd.wait()
            return recording.flatten()
            
        except Exception as e:
            print(f"âš ï¸ Recording failed: {e}")
            return None
    
    def analyze_file(self, audio_file: Path) -> Dict:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„ (í…ŒìŠ¤íŠ¸ìš©)"""
        if not AUDIO_AVAILABLE:
            return {"error": "librosa not available"}
        
        try:
            print(f"ğŸ“ Loading audio file: {audio_file.name}")
            audio_data, sr = librosa.load(audio_file, sr=self.sample_rate, duration=30)
            
            features = self.analyze_audio_buffer(audio_data)
            
            # í˜ì´ì¦ˆ ë§¤ì¹­ ê³„ì‚°
            current_phase = self.get_current_rhythm_phase() or "FOCUS"
            match_score, verdict = self.calculate_phase_match(features, current_phase)
            
            result = {
                "file": str(audio_file),
                "features": features,
                "current_phase": current_phase,
                "match_score": match_score,
                "verdict": verdict
            }
            
            return result
            
        except Exception as e:
            return {"error": str(e), "file": str(audio_file)}
    
    def run_continuous_monitoring(self, interval: int = 30):
        """ì—°ì† ëª¨ë‹ˆí„°ë§ (ë°ëª¬ ëª¨ë“œ)"""
        print("ğŸµ Starting continuous music monitoring...")
        print(f"   Interval: {interval}s")
        print("   Press Ctrl+C to stop\n")
        
        log_file = self.outputs_dir / "music_analysis_log.jsonl"
        
        try:
            while True:
                # í˜„ì¬ í˜ì´ì¦ˆ í™•ì¸
                current_phase = self.get_current_rhythm_phase()
                if not current_phase:
                    print("âš ï¸ Rhythm phase not available, waiting...")
                    time.sleep(interval)
                    continue
                
                # ì˜¤ë””ì˜¤ ìƒ˜í”Œ ë…¹ìŒ
                audio_data = self.record_audio_sample(self.buffer_duration)
                if audio_data is None:
                    time.sleep(interval)
                    continue
                
                # ë¶„ì„
                features = self.analyze_audio_buffer(audio_data)
                if "error" in features:
                    print(f"âš ï¸ Analysis error: {features['error']}")
                    time.sleep(interval)
                    continue
                
                # ë§¤ì¹­ë„ ê³„ì‚°
                match_score, verdict = self.calculate_phase_match(features, current_phase)
                
                # ê²°ê³¼ ì¶œë ¥
                print(f"\n[{datetime.now().strftime('%H:%M:%S')}] Analysis:")
                print(f"  Phase: {current_phase}")
                print(f"  Tempo: {features['tempo']:.1f} BPM")
                print(f"  Energy: {features['energy']:.3f}")
                print(f"  Match: {match_score:.1%} - {verdict}")
                
                # ë¡œê·¸ ì €ì¥
                log_entry = {
                    "timestamp": datetime.now().isoformat(),
                    "phase": current_phase,
                    "features": features,
                    "match_score": match_score,
                    "verdict": verdict
                }
                
                with open(log_file, "a", encoding="utf-8") as f:
                    f.write(json.dumps(log_entry) + "\n")
                
                # ê²½ê³  ë°œìƒ
                if match_score < 0.4:
                    print(f"\nâš ï¸ WARNING: Music not suitable for {current_phase} phase!")
                    print("   Consider switching to adaptive music player")
                
                time.sleep(interval)
                
        except KeyboardInterrupt:
            print("\n\nâœ“ Monitoring stopped")


def main():
    parser = argparse.ArgumentParser(description="Realtime Music Analyzer")
    parser.add_argument("--file", type=str, help="Analyze audio file")
    parser.add_argument("--monitor", action="store_true", help="Start continuous monitoring")
    parser.add_argument("--interval", type=int, default=30, help="Monitoring interval (seconds)")
    parser.add_argument("--workspace", type=str, default=".", help="Workspace root")
    
    args = parser.parse_args()
    
    workspace_root = Path(args.workspace).resolve()
    analyzer = RealtimeMusicAnalyzer(workspace_root)
    
    if args.file:
        # íŒŒì¼ ë¶„ì„ ëª¨ë“œ
        audio_file = Path(args.file)
        if not audio_file.exists():
            print(f"âŒ File not found: {audio_file}")
            return 1
        
        result = analyzer.analyze_file(audio_file)
        print(json.dumps(result, indent=2))
        
    elif args.monitor:
        # ì—°ì† ëª¨ë‹ˆí„°ë§ ëª¨ë“œ
        analyzer.run_continuous_monitoring(args.interval)
        
    else:
        # ê¸°ë³¸: ë‹¨ì¼ ìƒ˜í”Œ ë¶„ì„
        current_phase = analyzer.get_current_rhythm_phase() or "FOCUS"
        print(f"ğŸ“Š Current rhythm phase: {current_phase}\n")
        
        audio_data = analyzer.record_audio_sample(3.0)
        if audio_data is not None:
            features = analyzer.analyze_audio_buffer(audio_data)
            match_score, verdict = analyzer.calculate_phase_match(features, current_phase)
            
            print(f"\nğŸµ Music Analysis:")
            print(f"  Tempo: {features.get('tempo', 0):.1f} BPM")
            print(f"  Energy: {features.get('energy', 0):.3f}")
            print(f"  Brightness: {features.get('brightness', 0):.1f} Hz")
            print(f"  Complexity: {features.get('complexity', 0):.3f}")
            print(f"\nğŸ“ˆ Phase Match: {match_score:.1%}")
            print(f"  {verdict}")
    
    return 0


if __name__ == "__main__":
    exit(main())
