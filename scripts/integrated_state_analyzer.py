#!/usr/bin/env python3
"""
ğŸ¤ğŸŒŠ Microphone + Flow Observer Integration
ë§ˆì´í¬ ì£¼íŒŒìˆ˜ ë¶„ì„ê³¼ ë°ìŠ¤í¬í†± í™œë™ì„ ê²°í•©í•˜ì—¬ ë” ì •í™•í•œ ìƒíƒœ ì¶”ë¡ 

í†µí•© ë¶„ì„:
1. ë°ìŠ¤í¬í†± í™œë™ (ê¸°ì¡´)
   - í¬ê·¸ë¼ìš´ë“œ ìœˆë„ìš°
   - í”„ë¡œì„¸ìŠ¤ ë³€ê²½
   - íŒŒì¼ ì „í™˜

2. ë§ˆì´í¬ ì£¼íŒŒìˆ˜ (ì‹ ê·œ)
   - ìŒì„± íŒ¨í„´
   - í™˜ê²½ ì†ŒìŒ
   - ì£¼íŒŒìˆ˜ ëŒ€ì—­ ë¶„ì„

3. í†µí•© ì¶”ë¡ 
   - ë°ìŠ¤í¬í†±: VS Code ì§‘ì¤‘ + ë§ˆì´í¬: ì¡°ìš©í•¨ â†’ Deep Focus (í™•ì‹ ë„ ë†’ìŒ)
   - ë°ìŠ¤í¬í†±: ë¹ ë¥¸ ì „í™˜ + ë§ˆì´í¬: ë†’ì€ ì†ŒìŒ â†’ Distracted (í™•ì‹ ë„ ë†’ìŒ)
   - ë°ìŠ¤í¬í†±: í™œë™ ì—†ìŒ + ë§ˆì´í¬: ë¬´ìŒ â†’ Absent (í™•ì‹ ë„ ë†’ìŒ)

Author: AGI Self-Awareness System
Date: 2025-11-10
"""
import json
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Optional

# Import existing modules
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from fdo_agi_repo.copilot.flow_observer_integration import FlowObserver
    FLOW_AVAILABLE = True
except ImportError:
    FLOW_AVAILABLE = False
    print("âš ï¸ Flow Observer not available")

try:
    from scripts.microphone_frequency_analyzer import MicrophoneAnalyzer
    MIC_AVAILABLE = True
except ImportError:
    MIC_AVAILABLE = False
    print("âš ï¸ Microphone Analyzer not available")


class IntegratedStateAnalyzer:
    """í†µí•© ìƒíƒœ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.flow_observer = FlowObserver() if FLOW_AVAILABLE else None
        self.mic_analyzer = MicrophoneAnalyzer() if MIC_AVAILABLE else None
        
    def analyze_integrated_state(self, hours: int = 1) -> Dict:
        """
        í†µí•© ìƒíƒœ ë¶„ì„
        
        Args:
            hours: Flow Observer ë¶„ì„ ë²”ìœ„ (ì‹œê°„)
            
        Returns:
            í†µí•© ë¶„ì„ ê²°ê³¼
        """
        timestamp = datetime.now(timezone.utc).isoformat()
        
        # 1. ë°ìŠ¤í¬í†± í™œë™ ë¶„ì„
        flow_state = None
        if self.flow_observer:
            flow_state = self.flow_observer.analyze_recent_activity(hours=hours)
            print(f"ğŸ–¥ï¸ Desktop Flow: {flow_state.state} (confidence: {flow_state.confidence:.2f})")
        
        # 2. ë§ˆì´í¬ ì£¼íŒŒìˆ˜ ë¶„ì„
        mic_state = None
        if self.mic_analyzer:
            print("\nğŸ¤ Analyzing microphone (2 seconds)...")
            audio = self.mic_analyzer.capture_audio()
            spectrum = self.mic_analyzer.analyze_frequency_spectrum(audio)
            voice = self.mic_analyzer.detect_voice_activity(audio)
            mic_state = self.mic_analyzer.infer_user_state(spectrum, voice)
            print(f"ğŸ¤ Microphone State: {mic_state['state']} (confidence: {mic_state['confidence']:.2f})")
        
        # 3. í†µí•© ì¶”ë¡ 
        integrated = self._integrate_states(flow_state, mic_state)
        
        print(f"\nğŸ¯ Integrated State: {integrated['final_state']} (confidence: {integrated['final_confidence']:.2f})")
        print(f"   {integrated['reasoning']}")
        
        return {
            'timestamp': timestamp,
            'flow_state': {
                'state': flow_state.state if flow_state else None,
                'confidence': flow_state.confidence if flow_state else None,
                'context': flow_state.context if flow_state else None
            } if flow_state else None,
            'mic_state': mic_state,
            'integrated': integrated
        }
        
    def _integrate_states(self, flow_state, mic_state) -> Dict:
        """
        ë‘ ìƒíƒœë¥¼ í†µí•©í•˜ì—¬ ìµœì¢… ìƒíƒœ ì¶”ë¡ 
        
        Args:
            flow_state: Flow Observer ê²°ê³¼
            mic_state: Microphone Analyzer ê²°ê³¼
            
        Returns:
            í†µí•© ìƒíƒœ
        """
        # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ unknown
        if not flow_state and not mic_state:
            return {
                'final_state': 'unknown',
                'final_confidence': 0.0,
                'reasoning': 'No data available',
                'flow_weight': 0.0,
                'mic_weight': 0.0
            }
            
        # Flowë§Œ ìˆìœ¼ë©´ Flow ì‚¬ìš©
        if flow_state and not mic_state:
            return {
                'final_state': flow_state.state,
                'final_confidence': flow_state.confidence,
                'reasoning': 'Based on desktop activity only',
                'flow_weight': 1.0,
                'mic_weight': 0.0
            }
            
        # Micë§Œ ìˆìœ¼ë©´ Mic ì‚¬ìš©
        if mic_state and not flow_state:
            return {
                'final_state': mic_state['state'],
                'final_confidence': mic_state['confidence'],
                'reasoning': 'Based on microphone analysis only',
                'flow_weight': 0.0,
                'mic_weight': 1.0
            }
            
        # ë‘˜ ë‹¤ ìˆìœ¼ë©´ í†µí•© ì¶”ë¡ 
        flow_s = flow_state.state
        flow_c = flow_state.confidence
        mic_s = mic_state['state']
        mic_c = mic_state['confidence']
        
        # í†µí•© ë¡œì§
        final_state = 'unknown'
        final_confidence = 0.0
        reasoning = ''
        flow_weight = 0.5
        mic_weight = 0.5
        
        # Case 1: Flow ì§‘ì¤‘ + ì¡°ìš©í•¨ â†’ Deep Focus (ê°•í™”)
        if flow_s == 'flow' and mic_s in ['deep_focus', 'active_work']:
            final_state = 'deep_flow'
            final_confidence = min(0.95, (flow_c + mic_c) / 2 + 0.2)  # ë³´ë„ˆìŠ¤
            reasoning = 'Desktop focus + Quiet environment = Deep Flow (ê°•í™”ë¨)'
            flow_weight = 0.6
            mic_weight = 0.4
            
        # Case 2: Flow ì§‘ì¤‘ but ì†ŒìŒ â†’ Shallow Flow (ì•½í™”)
        elif flow_s == 'flow' and mic_s == 'noisy_environment':
            final_state = 'shallow_flow'
            final_confidence = min(flow_c, mic_c)  # ë‚®ì€ ìª½ ì„ íƒ
            reasoning = 'Desktop focus but noisy = Shallow Flow (ì•½í™”ë¨)'
            flow_weight = 0.7
            mic_weight = 0.3
            
        # Case 3: Flow ì „í™˜ + ëŒ€í™” â†’ Normal (ì¼ì¹˜)
        elif flow_s == 'transition' and mic_s == 'speaking':
            final_state = 'conversing'
            final_confidence = (flow_c + mic_c) / 2
            reasoning = 'Desktop switching + Speaking = Conversation'
            flow_weight = 0.5
            mic_weight = 0.5
            
        # Case 4: Flow ì •ì²´ + ë¬´ìŒ â†’ Absent (ì¼ì¹˜)
        elif flow_s == 'stagnation' and mic_s in ['absent', 'deep_focus']:
            if mic_s == 'absent':
                final_state = 'away'
                final_confidence = (flow_c + mic_c) / 2 + 0.1
                reasoning = 'No desktop activity + Silence = Away (í™•ì‹¤)'
            else:
                final_state = 'resting'
                final_confidence = (flow_c + mic_c) / 2
                reasoning = 'No desktop activity + Quiet = Resting/Thinking'
            flow_weight = 0.5
            mic_weight = 0.5
            
        # Case 5: ë¶ˆì¼ì¹˜ â†’ ê°€ì¤‘ í‰ê· 
        else:
            # ë” í™•ì‹ ë„ ë†’ì€ ìª½ì— ê°€ì¤‘ì¹˜
            if flow_c > mic_c:
                final_state = flow_s
                final_confidence = flow_c * 0.7 + mic_c * 0.3
                reasoning = f'Desktop ({flow_s}) more confident than Mic ({mic_s})'
                flow_weight = 0.7
                mic_weight = 0.3
            else:
                final_state = mic_s
                final_confidence = mic_c * 0.7 + flow_c * 0.3
                reasoning = f'Mic ({mic_s}) more confident than Desktop ({flow_s})'
                flow_weight = 0.3
                mic_weight = 0.7
                
        return {
            'final_state': final_state,
            'final_confidence': final_confidence,
            'reasoning': reasoning,
            'flow_weight': flow_weight,
            'mic_weight': mic_weight,
            'agreement': flow_s == mic_s  # ë‘ ì‹œìŠ¤í…œì´ ì¼ì¹˜í•˜ëŠ”ì§€
        }


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ğŸ¤ğŸŒŠ Integrated State Analyzer')
    parser.add_argument('--hours', type=int, default=1,
                       help='Hours to analyze for Flow Observer (default: 1)')
    parser.add_argument('--save', type=str, default='outputs/integrated_state_latest.json',
                       help='Save path for results')
    
    args = parser.parse_args()
    
    if not FLOW_AVAILABLE and not MIC_AVAILABLE:
        print("âŒ Neither Flow Observer nor Microphone Analyzer available!")
        print("Install dependencies:")
        print("  - Flow Observer: Already in fdo_agi_repo")
        print("  - Microphone: Run 'scripts/install_microphone_deps.ps1'")
        sys.exit(1)
    
    analyzer = IntegratedStateAnalyzer()
    result = analyzer.analyze_integrated_state(hours=args.hours)
    
    # Save
    save_path = Path(args.save)
    save_path.parent.mkdir(parents=True, exist_ok=True)
    with open(save_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ Saved to: {save_path}")
    print("\nğŸ“Š Full Result:")
    print(json.dumps(result, indent=2, ensure_ascii=False))


if __name__ == '__main__':
    main()
