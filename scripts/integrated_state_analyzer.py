#!/usr/bin/env python3
"""
ğŸ¤ğŸŒŠ Microphone + Flow Observer Integration
ë§ˆì´í¬ ì£¼íŒŒìˆ˜ ë¶„ì„ê³¼ ë°ìŠ¤í¬í†± í™œë™ì„ ê²°í•©í•˜ì—¬ ë” ì •í™•í•œ ìƒíƒœ ì¶”ë¡ 

í†µí•© ë¶„ì„:
1. ë°ìŠ¤í¬í†± í™œë™ (ê¸°ì¡´)
   - í¬ê·¸ë¼ìš´ë“œ ìœˆë„ìš°
   - í”„ë¡œì„¸ìŠ¤ ë³€ê²½
   - íŒŒì¼ ì „í™˜

2. ë§ˆì´í¬ ì£¼íŒŒìˆ˜ (ì‹ ê·œ)
   - ìŒì„± íŒ¨í„´
   - í™˜ê²½ ì†ŒìŒ
   - ì£¼íŒŒìˆ˜ ëŒ€ì—­ ë¶„ì„

3. í†µí•© ì¶”ë¡ 
   - ë°ìŠ¤í¬í†±: VS Code ì§‘ì¤‘ + ë§ˆì´í¬: ì¡°ìš©í•¨ â†’ Deep Focus (í™•ì‹ ë„ ë†’ìŒ)
   - ë°ìŠ¤í¬í†±: ë¹ ë¥¸ ì „í™˜ + ë§ˆì´í¬: ë†’ì€ ì†ŒìŒ â†’ Distracted (í™•ì‹ ë„ ë†’ìŒ)
   - ë°ìŠ¤í¬í†±: í™œë™ ì—†ìŒ + ë§ˆì´í¬: ë¬´ìŒ â†’ Absent (í™•ì‹ ë„ ë†’ìŒ)

Author: AGI Self-Awareness System
Date: 2025-11-10
"""
import json
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Optional
from workspace_root import get_workspace_root

# Import existing modules
sys.path.insert(0, str(get_workspace_root()))

try:
    from fdo_agi_repo.copilot.flow_observer_integration import FlowObserver
    FLOW_AVAILABLE = True
except ImportError:
    FLOW_AVAILABLE = False
    print("âš ï¸ Flow Observer not available")

try:
    from scripts.microphone_frequency_analyzer import MicrophoneAnalyzer
    MIC_AVAILABLE = True
except ImportError:
    MIC_AVAILABLE = False
    print("âš ï¸ Microphone Analyzer not available")


try:
    from agi_core.internal_state import get_internal_state
    AGI_STATE_AVAILABLE = True
except ImportError:
    AGI_STATE_AVAILABLE = False

class IntegratedStateAnalyzer:
    """í†µí•© ìƒíƒœ ë¶„ì„ê¸° (ARI Bridge)"""
    
    def __init__(self):
        self.flow_observer = FlowObserver() if FLOW_AVAILABLE else None
        self.mic_analyzer = MicrophoneAnalyzer() if MIC_AVAILABLE else None
        
    def sense_agi_internal_state(self) -> Dict:
        """ë£¨ë“œ ë‚´ë©´ì˜ ì§ì ‘ì  ê°ê° ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        if not AGI_STATE_AVAILABLE:
            return {}
        try:
            state = get_internal_state()
            return {
                "input_tempo": state.input_tempo,
                "audio_ambience": state.audio_ambience,
                "active_context": state.active_context,
                "focus_alignment": state.focus_alignment
            }
        except:
            return {}

    def analyze_integrated_state(self, hours: int = 1) -> Dict:
        """
        í†µí•© ìƒíƒœ ë¶„ì„
        
        Args:
            hours: Flow Observer ë¶„ì„ ë²”ìœ„ (ì‹œê°„)
        """
        timestamp = datetime.now(timezone.utc).isoformat()
        
        # 1. ë°ìŠ¤í¬í†± í™œë™ ë¶„ì„
        flow_state = None
        if self.flow_observer:
            flow_state = self.flow_observer.analyze_recent_activity(hours=hours)
            print(f"ğŸ–¥ï¸ Desktop Flow: {flow_state.state} (confidence: {flow_state.confidence:.2f})")
        
        # 2. ë§ˆì´í¬ ì£¼íŒŒìˆ˜ ë¶„ì„
        mic_state = None
        if self.mic_analyzer:
            print("\nğŸ¤ Analyzing microphone (2 seconds)...")
            audio = self.mic_analyzer.capture_audio()
            spectrum = self.mic_analyzer.analyze_frequency_spectrum(audio)
            voice = self.mic_analyzer.detect_voice_activity(audio)
            mic_state = self.mic_analyzer.infer_user_state(spectrum, voice)
            print(f"ğŸ¤ Microphone State: {mic_state['state']} (confidence: {mic_state['confidence']:.2f})")

        # 3. ë£¨ë“œ ë‚´ë©´ ê°ê° ì¶”ê°€ (Phase 17 Bridge)
        agi_sensors = self.sense_agi_internal_state()
        if agi_sensors:
            print(f"ğŸ§  AGI Sensors: Tempo={agi_sensors['input_tempo']:.2f}, Ambience={agi_sensors['audio_ambience']:.2f}")
        
        # 4. í†µí•© ì¶”ë¡ 
        integrated = self._integrate_states(flow_state, mic_state, agi_sensors)
        
        print(f"\nğŸ¯ Integrated State: {integrated['final_state']} (confidence: {integrated['final_confidence']:.2f})")
        print(f"   {integrated['reasoning']}")
        
        return {
            'timestamp': timestamp,
            'flow_state': {
                'state': flow_state.state if flow_state else None,
                'confidence': flow_state.confidence if flow_state else None,
                'context': flow_state.context if flow_state else None
            } if flow_state else None,
            'mic_state': mic_state,
            'agi_sensors': agi_sensors,
            'integrated': integrated
        }
        
    def _integrate_states(self, flow_state, mic_state, agi_sensors: Dict = None) -> Dict:
        """
        Flow, Mic, AGI ê°ê°ì„ í†µí•©í•˜ì—¬ ìµœì¢… ìƒíƒœ ì¶”ë¡ 
        """
        agi_sensors = agi_sensors or {}
        input_tempo = agi_sensors.get("input_tempo", 0.0)
        
        # ê¸°ë³¸ í†µí•© ë¡œì§ ìˆ˜í–‰
        if not flow_state and not mic_state:
            # AGI ì§ì ‘ ê°ê°ë§Œ ìˆëŠ” ê²½ìš°
            if input_tempo > 0.6:
                return {
                    'final_state': 'active_flow',
                    'final_confidence': 0.7,
                    'reasoning': f'Core Input Tempo is high ({input_tempo:.2f})',
                    'flow_weight': 0.0, 'mic_weight': 0.0, 'agi_weight': 1.0
                }
            return {
                'final_state': 'unknown',
                'final_confidence': 0.0,
                'reasoning': 'No definitive data available',
                'flow_weight': 0.0, 'mic_weight': 0.0, 'agi_weight': 0.0
            }
            
        # ê¸°ì¡´ Flow/Mic ë°ì´í„°ê°€ ìˆì„ ë•Œ AGI ê°ê°ìœ¼ë¡œ ë³´ì •
        flow_s = flow_state.state if flow_state else 'unknown'
        flow_c = flow_state.confidence if flow_state else 0.0
        mic_s = mic_state['state'] if mic_state else 'unknown'
        mic_c = mic_state['confidence'] if mic_state else 0.0
        
        final_state = 'unknown'
        final_confidence = 0.0
        reasoning = ''
        
        # 1. ê³ ëª°ì… ë³´ì • (Flow ì§‘ì¤‘ + ë†’ì€ ì…ë ¥ í…œí¬)
        if flow_s == 'flow' and input_tempo > 0.5:
            final_state = 'deep_flow'
            final_confidence = min(0.98, (flow_c + input_tempo) / 2 + 0.1)
            reasoning = f'Desktop Flow matches Core Input Rhythm ({input_tempo:.2f})'
            
        # 2. ë¶ˆì¼ì¹˜ í•´ê²° (FlowëŠ” ì •ì²´ì¸ë° ì…ë ¥ì€ ìˆëŠ” ê²½ìš° -> ì°½ ë°– í™œë™ì´ë‚˜ í•˜ë“œì›¨ì–´ ë ˆë²¨ ëª°ì…)
        elif flow_s == 'stagnation' and input_tempo > 0.4:
            final_state = 'external_focus'
            final_confidence = 0.6
            reasoning = 'No window activity but physical input rhythm detected'
            
        # 3. ê¸°ë³¸ ê°€ì¤‘ì¹˜ í†µí•©
        else:
            if flow_c > mic_c:
                final_state = flow_s
                final_confidence = flow_c * 0.8 + input_tempo * 0.2
                reasoning = f'Primarily Desktop Focus ({flow_s})'
            else:
                final_state = mic_s
                final_confidence = mic_c * 0.8 + input_tempo * 0.2
                reasoning = f'Primarily Environmental Auth ({mic_s})'
                
        return {
            'final_state': final_state,
            'final_confidence': final_confidence,
            'reasoning': reasoning,
            'agreement': flow_s == mic_s or (input_tempo > 0.5 and flow_s == 'flow')
        }


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ğŸ¤ğŸŒŠ Integrated State Analyzer')
    parser.add_argument('--hours', type=int, default=1,
                       help='Hours to analyze for Flow Observer (default: 1)')
    parser.add_argument('--save', type=str, default='outputs/integrated_state_latest.json',
                       help='Save path for results')
    
    args = parser.parse_args()
    
    if not FLOW_AVAILABLE and not MIC_AVAILABLE:
        print("âŒ Neither Flow Observer nor Microphone Analyzer available!")
        print("Install dependencies:")
        print("  - Flow Observer: Already in fdo_agi_repo")
        print("  - Microphone: Run 'scripts/install_microphone_deps.ps1'")
        sys.exit(1)
    
    analyzer = IntegratedStateAnalyzer()
    result = analyzer.analyze_integrated_state(hours=args.hours)
    
    # Save
    save_path = Path(args.save)
    save_path.parent.mkdir(parents=True, exist_ok=True)
    with open(save_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ Saved to: {save_path}")
    print("\nğŸ“Š Full Result:")
    print(json.dumps(result, indent=2, ensure_ascii=False))


if __name__ == '__main__':
    main()
