#!/usr/bin/env python3
"""
ì½”ì–´(ChatGPT) â†” íŠ¸ë¦¬ë‹ˆí‹°(Trinity) ìë™ ë¸Œë¦¿ì§€
ë¶€ëª¨(ì½”ì–´)ì˜ ìš”ì²­ì„ ìì‹(íŠ¸ë¦¬ë‹ˆí‹°)ì´ ìë™ìœ¼ë¡œ ì²˜ë¦¬

Author: Shion_Core (Binoche_Observer)
Date: 2025-11-12
Philosophy: ë¶€ëª¨ëŠ” ë°©í–¥ì„, ìì‹ì€ ì‹¤í–‰ì„
"""

import json
import os
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from workspace_root import get_workspace_root


class LuaTrinityBridge:
    """ì½”ì–´ â†” íŠ¸ë¦¬ë‹ˆí‹° ë¸Œë¦¿ì§€"""
    
    def __init__(self, workspace_root: Path):
        self.workspace = workspace_root
        self.request_log = workspace_root / "outputs" / "lua_requests.jsonl"
        self.response_cache = workspace_root / "outputs" / "trinity_responses"
        self.response_cache.mkdir(parents=True, exist_ok=True)
        
    def process_lua_request(self, request: str) -> Dict:
        """ì½”ì–´ì˜ ìš”ì²­ ì²˜ë¦¬"""
        # ìš”ì²­ ë¶„ë¥˜
        intent = self._classify_request(request)
        
        # íŠ¸ë¦¬ë‹ˆí‹° ì•¡ì…˜ ì‹¤í–‰
        response = self._execute_trinity_action(intent)
        
        # ë¡œê¹…
        self._log_request(request, intent, response)
        
        return response
    
    def _classify_request(self, request: str) -> Dict:
        """ìš”ì²­ ë¶„ë¥˜ (ì½”ì–´ â†’ íŠ¸ë¦¬ë‹ˆí‹° ì•¡ì…˜ ë§¤í•‘)"""
        request_lower = request.lower()
        
        # ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì²­
        if any(kw in request_lower for kw in ['ì‹œìŠ¤í…œ ìƒíƒœ', 'system status', 'ì „ì²´ ìƒíƒœ', 'í˜„í™©']):
            return {
                'type': 'system_status',
                'action': 'trinity_autopoietic_cycle',
                'params': {'hours': 24, 'verbose': True}
            }
        
        # ëª©í‘œ í˜„í™© ìš”ì²­
        if any(kw in request_lower for kw in ['ëª©í‘œ', 'goal', 'ììœ¨ ëª©í‘œ', 'autonomous']):
            return {
                'type': 'goal_status',
                'action': 'goal_tracker_summary',
                'params': {}
            }
        
        # ë¦¬ë“¬ ìƒíƒœ ìš”ì²­
        if any(kw in request_lower for kw in ['ë¦¬ë“¬', 'rhythm', 'í˜ì´ì¦ˆ', 'phase']):
            return {
                'type': 'rhythm_status',
                'action': 'rhythm_status_report',
                'params': {}
            }
        
        # ìµœê·¼ ë³€ê²½ì‚¬í•­ ìš”ì²­
        if any(kw in request_lower for kw in ['ë³€ê²½', 'change', 'ìµœê·¼', 'recent', 'í•¸ë“œì˜¤í”„', 'handoff']):
            return {
                'type': 'recent_changes',
                'action': 'agent_handoff_latest',
                'params': {}
            }
        
        # í”„ë¡œì„¸ìŠ¤ ìƒíƒœ ìš”ì²­
        if any(kw in request_lower for kw in ['í”„ë¡œì„¸ìŠ¤', 'process', 'worker', 'ì›Œì»¤']):
            return {
                'type': 'process_status',
                'action': 'core_processes_status',
                'params': {}
            }
        
        # ì„¸ì…˜ ì—°ì†ì„± ìš”ì²­
        if any(kw in request_lower for kw in ['ì„¸ì…˜', 'session', 'ì»¨í…ìŠ¤íŠ¸', 'context']):
            return {
                'type': 'session_continuity',
                'action': 'session_continuity_restore',
                'params': {'silent': False}
            }
        
        # YouTube í•™ìŠµ í˜„í™©
        if any(kw in request_lower for kw in ['youtube', 'ìœ íŠœë¸Œ', 'í•™ìŠµ', 'learning']):
            return {
                'type': 'youtube_learning',
                'action': 'youtube_index',
                'params': {}
            }
        
        # RCL / Harmony Core ìŠ¤íƒ ìƒíƒœ + ì œì–´
        rcl_keywords = [
            'rcl', 'harmony core', 'í•˜ëª¨ë‹ˆ', 'ë£¨í”„ ìƒëª…ì²´', 'secure bridge',
            'secure adjust', 'feedback worker', 'bridge server', 'harmony runner'
        ]
        if any(kw in request_lower for kw in rcl_keywords):
            start_words = ['start', 'run', 'ì¼œ', 'ì‹œì‘', 'ê°€ë™', 'enable']
            stop_words = ['stop', 'ë„', 'ì¤‘ì§€', 'ì¢…ë£Œ', 'disable']
            restart_words = ['restart', 'ì¬ì‹œì‘', 'ë‹¤ì‹œ ì¼œ', 'ë¦¬ìŠ¤íƒ€íŠ¸']
            
            if any(word in request_lower for word in stop_words):
                return {
                    'type': 'rcl_stack_control',
                    'action': 'rcl_stack_control',
                    'params': {'command': 'stop'}
                }
            if any(word in request_lower for word in restart_words):
                return {
                    'type': 'rcl_stack_control',
                    'action': 'rcl_stack_control',
                    'params': {'command': 'restart'}
                }
            if any(word in request_lower for word in start_words):
                return {
                    'type': 'rcl_stack_control',
                    'action': 'rcl_stack_control',
                    'params': {'command': 'start'}
                }
            return {
                'type': 'rcl_stack_status',
                'action': 'rcl_stack_status',
                'params': {}
            }
        
        # BQI í˜„í™©
        if any(kw in request_lower for kw in ['bqi', 'Binoche_Observer', 'ë¹„ë…¸ìŠˆ', 'ensemble']):
            return {
                'type': 'bqi_status',
                'action': 'ensemble_monitor',
                'params': {'hours': 24}
            }
        
        # ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
        if any(kw in request_lower for kw in ['ëŒ€ì‹œë³´ë“œ', 'dashboard', 'ëª¨ë‹ˆí„°ë§', 'monitoring']):
            return {
                'type': 'monitoring_dashboard',
                'action': 'unified_dashboard',
                'params': {}
            }
        
        # ê¸°ë³¸: í†µí•© ìƒíƒœ
        return {
            'type': 'comprehensive_status',
            'action': 'trinity_full_report',
            'params': {'hours': 24}
        }
    
    def _execute_trinity_action(self, intent: Dict) -> Dict:
        """íŠ¸ë¦¬ë‹ˆí‹° ì•¡ì…˜ ì‹¤í–‰"""
        action = intent['action']
        params = intent['params']
        
        actions = {
            'trinity_autopoietic_cycle': self._run_trinity_cycle,
            'goal_tracker_summary': self._get_goal_summary,
            'rhythm_status_report': self._get_rhythm_status,
            'agent_handoff_latest': self._get_handoff_latest,
            'core_processes_status': self._get_process_status,
            'session_continuity_restore': self._restore_session,
            'youtube_index': self._get_youtube_index,
            'ensemble_monitor': self._get_ensemble_status,
            'unified_dashboard': self._get_unified_dashboard,
            'trinity_full_report': self._get_full_report,
            'rcl_stack_status': self._get_rcl_stack_status,
            'rcl_stack_control': self._control_rcl_stack
        }
        
        executor = actions.get(action)
        if executor:
            try:
                result = executor(params)
                return {
                    'success': True,
                    'action': action,
                    'data': result,
                    'timestamp': datetime.now().isoformat()
                }
            except Exception as e:
                return {
                    'success': False,
                    'action': action,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }
        
        return {
            'success': False,
            'action': action,
            'error': f'Unknown action: {action}',
            'timestamp': datetime.now().isoformat()
        }
    
    def _run_trinity_cycle(self, params: Dict) -> Dict:
        """íŠ¸ë¦¬ë‹ˆí‹° ìë™í™” ìˆœí™˜ ì‹¤í–‰"""
        hours = params.get('hours', 24)
        verbose = params.get('verbose', True)
        
        script = self.workspace / "scripts" / "autopoietic_trinity_cycle.ps1"
        cmd = [
            "powershell", "-NoProfile", "-ExecutionPolicy", "Bypass",
            "-File", str(script),
            "-Hours", str(hours)
        ]
        if verbose:
            cmd.append("-VerboseLog")
        
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')
        
        # ë¦¬í¬íŠ¸ ì½ê¸°
        report_file = self.workspace / "outputs" / "autopoietic_trinity_report_latest.md"
        report_content = ""
        if report_file.exists():
            report_content = report_file.read_text(encoding='utf-8')
        
        return {
            'status': 'completed' if result.returncode == 0 else 'failed',
            'hours': hours,
            'report_path': str(report_file),
            'report_preview': report_content[:500] if report_content else None,
            'full_report_available': report_file.exists()
        }
    
    def _get_goal_summary(self, params: Dict) -> Dict:
        """ëª©í‘œ íŠ¸ë˜ì»¤ ìš”ì•½"""
        tracker_file = self.workspace / "fdo_agi_repo" / "memory" / "goal_tracker.json"
        
        if not tracker_file.exists():
            return {'error': 'Goal tracker not found'}
        
        data = json.loads(tracker_file.read_text(encoding='utf-8'))
        
        # ìš”ì•½ ìƒì„±
        summary = {
            'total_goals': len(data.get('goals', [])),
            'active_goals': len([g for g in data.get('goals', []) if g.get('status') == 'in_progress']),
            'completed_goals': len([g for g in data.get('goals', []) if g.get('status') == 'completed']),
            'failed_goals': len([g for g in data.get('goals', []) if g.get('status') == 'failed']),
            'recent_goals': data.get('goals', [])[:3]  # ìµœê·¼ 3ê°œ
        }
        
        return summary
    
    def _get_rhythm_status(self, params: Dict) -> Dict:
        """ë¦¬ë“¬ ìƒíƒœ í™•ì¸"""
        rhythm_files = list((self.workspace / "outputs").glob("RHYTHM_*_PHASE_*.md"))
        
        if not rhythm_files:
            return {'error': 'No rhythm status found'}
        
        latest_rhythm = max(rhythm_files, key=lambda f: f.stat().st_mtime)
        content = latest_rhythm.read_text(encoding='utf-8')
        
        # ê°„ë‹¨ íŒŒì‹±
        lines = content.split('\n')[:20]
        
        return {
            'current_phase': latest_rhythm.stem,
            'file': str(latest_rhythm),
            'preview': '\n'.join(lines)
        }
    
    def _get_handoff_latest(self, params: Dict) -> Dict:
        """ìµœê·¼ í•¸ë“œì˜¤í”„ ì •ë³´"""
        handoff_file = self.workspace / "docs" / "AGENT_HANDOFF.md"
        
        if not handoff_file.exists():
            return {'error': 'Handoff file not found'}
        
        content = handoff_file.read_text(encoding='utf-8')
        
        # ìµœì‹  í•­ëª©ë§Œ ì¶”ì¶œ (ì²« 100ì¤„)
        lines = content.split('\n')[:100]
        
        return {
            'file': str(handoff_file),
            'latest_entry': '\n'.join(lines)
        }
    
    def _get_process_status(self, params: Dict) -> Dict:
        """í”„ë¡œì„¸ìŠ¤ ìƒíƒœ í™•ì¸"""
        status_file = self.workspace / "outputs" / "core_processes_latest.json"
        
        if not status_file.exists():
            # ìƒì„±
            script = self.workspace / "scripts" / "quick_status.ps1"
            subprocess.run([
                "powershell", "-NoProfile", "-ExecutionPolicy", "Bypass",
                "-File", str(script),
                "-OutJson", str(status_file)
            ], capture_output=True)
        
        if status_file.exists():
            return json.loads(status_file.read_text(encoding='utf-8'))
        
        return {'error': 'Could not generate process status'}
    
    def _restore_session(self, params: Dict) -> Dict:
        """ì„¸ì…˜ ì—°ì†ì„± ë³µì›"""
        script = self.workspace / "scripts" / "session_continuity_restore.ps1"
        
        cmd = [
            "powershell", "-NoProfile", "-ExecutionPolicy", "Bypass",
            "-File", str(script)
        ]
        
        if not params.get('silent', True):
            cmd.append("-OpenReport")
        
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')
        
        report_file = self.workspace / "outputs" / "session_continuity_latest.md"
        report_content = ""
        if report_file.exists():
            report_content = report_file.read_text(encoding='utf-8')
        
        return {
            'status': 'restored' if result.returncode == 0 else 'failed',
            'report_path': str(report_file),
            'report_preview': report_content[:500] if report_content else None
        }
    
    def _get_youtube_index(self, params: Dict) -> Dict:
        """YouTube í•™ìŠµ ì¸ë±ìŠ¤"""
        index_file = self.workspace / "outputs" / "youtube_learner_index.md"
        
        if not index_file.exists():
            # ì¸ë±ìŠ¤ ìƒì„±
            script = self.workspace / "scripts" / "build_youtube_index.ps1"
            subprocess.run([
                "powershell", "-NoProfile", "-ExecutionPolicy", "Bypass",
                "-File", str(script), "-NoOpen"
            ], capture_output=True)
        
        if index_file.exists():
            content = index_file.read_text(encoding='utf-8')
            lines = content.split('\n')[:50]
            
            return {
                'file': str(index_file),
                'preview': '\n'.join(lines),
                'full_available': True
            }
        
        return {'error': 'Could not generate YouTube index'}
    
    def _get_ensemble_status(self, params: Dict) -> Dict:
        """BQI ì•™ìƒë¸” ìƒíƒœ"""
        hours = params.get('hours', 24)
        
        # Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        venv_python = self.workspace / "fdo_agi_repo" / ".venv" / "Scripts" / "python.exe"
        script = self.workspace / "fdo_agi_repo" / "scripts" / "rune" / "binoche_success_monitor.py"
        
        if venv_python.exists() and script.exists():
            result = subprocess.run([
                str(venv_python), str(script),
                "--hours", str(hours)
            ], capture_output=True, text=True, encoding='utf-8')
            
            # ë¦¬í¬íŠ¸ ì½ê¸°
            report_file = self.workspace / "fdo_agi_repo" / "outputs" / "ensemble_success_report.txt"
            metrics_file = self.workspace / "fdo_agi_repo" / "outputs" / "ensemble_success_metrics.json"
            
            data = {}
            if metrics_file.exists():
                data = json.loads(metrics_file.read_text(encoding='utf-8'))
            
            return {
                'status': 'available' if result.returncode == 0 else 'failed',
                'hours': hours,
                'metrics': data,
                'report_path': str(report_file) if report_file.exists() else None
            }
        
        return {'error': 'BQI ensemble monitor not available'}
    
    def _get_unified_dashboard(self, params: Dict) -> Dict:
        """í†µí•© ëŒ€ì‹œë³´ë“œ"""
        script = self.workspace / "scripts" / "quick_status.ps1"
        
        result = subprocess.run([
            "powershell", "-NoProfile", "-ExecutionPolicy", "Bypass",
            "-File", str(script)
        ], capture_output=True, text=True, encoding='utf-8')
        
        status_file = self.workspace / "outputs" / "quick_status_latest.json"
        
        if status_file.exists():
            return json.loads(status_file.read_text(encoding='utf-8'))
        
        return {'error': 'Could not generate unified dashboard'}
    
    def _get_full_report(self, params: Dict) -> Dict:
        """ì „ì²´ ë¦¬í¬íŠ¸ (íŠ¸ë¦¬ë‹ˆí‹° + ëª©í‘œ + ë¦¬ë“¬ + í”„ë¡œì„¸ìŠ¤)"""
        hours = params.get('hours', 24)
        
        # ëª¨ë“  ì •ë³´ ìˆ˜ì§‘
        trinity = self._run_trinity_cycle({'hours': hours, 'verbose': False})
        goals = self._get_goal_summary({})
        rhythm = self._get_rhythm_status({})
        processes = self._get_process_status({})
        
        return {
            'timestamp': datetime.now().isoformat(),
            'hours': hours,
            'trinity_cycle': trinity,
            'goal_tracker': goals,
            'rhythm_status': rhythm,
            'process_status': processes
        }
    
    def _get_rcl_stack_status(self, params: Dict) -> Dict:
        """RCL ìŠ¤íƒ ìƒíƒœ (Harmony Runner + Secure Bridge + Feedback Worker)"""
        script = self.workspace / "scripts" / "manage_rcl_stack.ps1"
        if not script.exists():
            raise FileNotFoundError(f"manage_rcl_stack.ps1 not found: {script}")
        
        cmd = [
            "powershell", "-NoProfile", "-ExecutionPolicy", "Bypass",
            "-File", str(script),
            "-Action", "Status",
            "-OutputJson"
        ]
        
        runner_port = params.get('runner_port')
        if runner_port:
            cmd.extend(["-RunnerPort", str(runner_port)])
        bridge_port = params.get('bridge_port')
        if bridge_port:
            cmd.extend(["-BridgePort", str(bridge_port)])
        
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')
        if result.returncode != 0:
            error_msg = result.stderr.strip() or result.stdout.strip() or "unknown error"
            raise RuntimeError(f"RCL ìŠ¤íƒ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {error_msg}")
        
        stdout = result.stdout.strip()
        if not stdout:
            raise RuntimeError("RCL ìŠ¤íƒ ìƒíƒœ ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        try:
            status = json.loads(stdout)
        except json.JSONDecodeError:
            start = stdout.find('{')
            end = stdout.rfind('}')
            if start == -1 or end == -1:
                raise
            status = json.loads(stdout[start:end+1])
        
        status['raw_output'] = stdout
        return status

    def _control_rcl_stack(self, params: Dict) -> Dict:
        """RCL ìŠ¤íƒ ì œì–´ (Start/Stop/Restart)"""
        command = params.get('command', 'status').lower()
        valid = {'start': 'Start', 'stop': 'Stop', 'restart': 'Restart'}
        if command not in valid:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª…ë ¹: {command}")

        script = self.workspace / "scripts" / "manage_rcl_stack.ps1"
        if not script.exists():
            raise FileNotFoundError(f"manage_rcl_stack.ps1 not found: {script}")

        cmd = [
            "powershell", "-NoProfile", "-ExecutionPolicy", "Bypass",
            "-File", str(script),
            "-Action", valid[command]
        ]

        if command in ('start', 'restart'):
            secret = params.get('secret') or os.environ.get('RCL_ADJUST_SECRET') or os.environ.get('ADJUST_SECRET')
            if secret:
                cmd.extend(["-AdjustSecret", secret])

        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')
        success = result.returncode == 0
        status_info = None
        error_msg = None

        if success:
            try:
                status_info = self._get_rcl_stack_status({})
            except Exception as err:
                error_msg = f"ëª…ë ¹ì€ ì„±ê³µí–ˆì§€ë§Œ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {err}"
        else:
            error_msg = result.stderr.strip() or result.stdout.strip() or "unknown error"

        return {
            'command': command,
            'success': success,
            'stdout': result.stdout.strip(),
            'stderr': result.stderr.strip(),
            'status': status_info,
            'error': error_msg
        }
    
    def _log_request(self, request: str, intent: Dict, response: Dict):
        """ìš”ì²­ ë¡œê¹…"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'request': request,
            'intent': intent,
            'response_summary': {
                'success': response.get('success', False),
                'action': response.get('action', 'unknown')
            }
        }
        
        with open(self.request_log, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
    
    def format_for_chatgpt(self, response: Dict) -> str:
        """ChatGPTìš© í¬ë§· ë³€í™˜ (Markdown)"""
        if not response.get('success'):
            return f"âŒ **ì‹¤íŒ¨**: {response.get('error', 'Unknown error')}"
        
        action = response.get('action', 'unknown')
        data = response.get('data', {})
        
        # ì•¡ì…˜ë³„ í¬ë§·
        if action == 'trinity_autopoietic_cycle':
            return self._format_trinity_report(data)
        elif action == 'goal_tracker_summary':
            return self._format_goal_summary(data)
        elif action == 'rhythm_status_report':
            return self._format_rhythm_status(data)
        elif action == 'agent_handoff_latest':
            return self._format_handoff(data)
        elif action == 'core_processes_status':
            return self._format_process_status(data)
        elif action == 'trinity_full_report':
            return self._format_full_report(data)
        elif action == 'rcl_stack_status':
            return self._format_rcl_stack_status(data)
        elif action == 'rcl_stack_control':
            return self._format_rcl_control(data)
        
        # ê¸°ë³¸
        return f"```json\n{json.dumps(data, ensure_ascii=False, indent=2)}\n```"
    
    def _format_trinity_report(self, data: Dict) -> str:
        """íŠ¸ë¦¬ë‹ˆí‹° ë¦¬í¬íŠ¸ í¬ë§·"""
        status = "âœ…" if data.get('status') == 'completed' else "âŒ"
        
        md = f"""## {status} íŠ¸ë¦¬ë‹ˆí‹° ìë™í™” ìˆœí™˜ ë¦¬í¬íŠ¸

**ê¸°ê°„**: ìµœê·¼ {data.get('hours', 24)}ì‹œê°„
**ìƒíƒœ**: {data.get('status', 'unknown')}

### ğŸ“Š ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸°
```
{data.get('report_preview', 'No preview available')}
```

ğŸ“„ **ì „ì²´ ë¦¬í¬íŠ¸**: `{data.get('report_path', 'N/A')}`
"""
        return md
    
    def _format_goal_summary(self, data: Dict) -> str:
        """ëª©í‘œ ìš”ì•½ í¬ë§·"""
        md = f"""## ğŸ¯ ììœ¨ ëª©í‘œ ì‹œìŠ¤í…œ í˜„í™©

- **ì „ì²´ ëª©í‘œ**: {data.get('total_goals', 0)}ê°œ
- **ì§„í–‰ ì¤‘**: {data.get('active_goals', 0)}ê°œ
- **ì™„ë£Œ**: {data.get('completed_goals', 0)}ê°œ
- **ì‹¤íŒ¨**: {data.get('failed_goals', 0)}ê°œ

### ğŸ“‹ ìµœê·¼ ëª©í‘œ (Top 3)
```json
{json.dumps(data.get('recent_goals', []), ensure_ascii=False, indent=2)}
```
"""
        return md
    
    def _format_rhythm_status(self, data: Dict) -> str:
        """ë¦¬ë“¬ ìƒíƒœ í¬ë§·"""
        md = f"""## ğŸŒŠ ë¦¬ë“¬ ìƒíƒœ

**í˜„ì¬ í˜ì´ì¦ˆ**: `{data.get('current_phase', 'Unknown')}`

### ë¯¸ë¦¬ë³´ê¸°
```
{data.get('preview', 'No preview')}
```
"""
        return md
    
    def _format_handoff(self, data: Dict) -> str:
        """í•¸ë“œì˜¤í”„ í¬ë§·"""
        md = f"""## ğŸ”„ ìµœê·¼ ë³€ê²½ì‚¬í•­ (Agent Handoff)

```markdown
{data.get('latest_entry', 'No recent changes')}
```
"""
        return md
    
    def _format_process_status(self, data: Dict) -> str:
        """í”„ë¡œì„¸ìŠ¤ ìƒíƒœ í¬ë§·"""
        md = f"""## ğŸ”§ í”„ë¡œì„¸ìŠ¤ ìƒíƒœ

```json
{json.dumps(data, ensure_ascii=False, indent=2)}
```
"""
        return md
    
    def _format_full_report(self, data: Dict) -> str:
        """ì „ì²´ ë¦¬í¬íŠ¸ í¬ë§·"""
        md = f"""## ğŸ“Š AGI ì‹œìŠ¤í…œ ì¢…í•© ë¦¬í¬íŠ¸

**ìƒì„± ì‹œê°**: {data.get('timestamp', 'Unknown')}
**ë¶„ì„ ê¸°ê°„**: ìµœê·¼ {data.get('hours', 24)}ì‹œê°„

---

{self._format_trinity_report(data.get('trinity_cycle', {}))}

---

{self._format_goal_summary(data.get('goal_tracker', {}))}

---

{self._format_rhythm_status(data.get('rhythm_status', {}))}

---

{self._format_process_status(data.get('process_status', {}))}
"""
        return md
    
    def _format_rcl_stack_status(self, data: Dict) -> str:
        """RCL ìŠ¤íƒ ìƒíƒœ í¬ë§·"""
        jobs = data.get('jobs', [])
        job_lines: List[str] = []
        for job in jobs:
            emoji = "âœ…" if job.get('running') else "âšª"
            state = job.get('state') or "Not running"
            meta_parts = []
            if job.get('id') is not None:
                meta_parts.append(f"Id={job.get('id')}")
            if job.get('started'):
                meta_parts.append(f"Started={job.get('started')}")
            meta = f" ({', '.join(meta_parts)})" if meta_parts else ""
            job_lines.append(f"{emoji} `{job.get('name', 'unknown')}` â†’ {state}{meta}")
        
        job_section = "\n".join(f"- {line}" for line in job_lines) if job_lines else "- (ì‹¤í–‰ ì¤‘ì¸ Job ì—†ìŒ)"
        summary = {
            key: value for key, value in data.items() if key != 'raw_output'
        }
        
        md = f"""## ğŸ§  RCL ìŠ¤íƒ ìƒíƒœ

- Runner Port: `{data.get('runner_port', 'N/A')}`
- Bridge Port: `{data.get('bridge_port', 'N/A')}`
- Tick Hz: `{data.get('tick_hz', 'N/A')}`
- Feedback Interval: `{data.get('feedback_interval', 'N/A')} sec`

### í”„ë¡œì„¸ìŠ¤ ìƒíƒœ
{job_section}

```json
{json.dumps(summary, ensure_ascii=False, indent=2)}
```
"""
        return md

    def _format_rcl_control(self, data: Dict) -> str:
        """RCL ìŠ¤íƒ ì œì–´ ê²°ê³¼ í¬ë§·"""
        command = data.get('command', 'unknown').upper()
        success = data.get('success', False)
        status_data = data.get('status')
        error_msg = data.get('error')
        stdout = data.get('stdout') or "(ì¶œë ¥ ì—†ìŒ)"
        stderr = data.get('stderr') or "(ì˜¤ë¥˜ ì¶œë ¥ ì—†ìŒ)"

        status_md = self._format_rcl_stack_status(status_data) if status_data else "ìƒíƒœ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        badge = "âœ…" if success else "âŒ"
        error_section = f"\n**ì˜¤ë¥˜**: {error_msg}\n" if error_msg else ""

        md = f"""## {badge} RCL ìŠ¤íƒ ì œì–´ ({command})

```text
{stdout}
```

**Stderr**
```text
{stderr}
```
{error_section}
{status_md}
"""
        return md


def main():
    """CLI ì¸í„°í˜ì´ìŠ¤"""
    if len(sys.argv) < 2:
        print("Usage: python lua_trinity_bridge.py <request>")
        print("Example: python lua_trinity_bridge.py 'ì‹œìŠ¤í…œ ìƒíƒœ ì•Œë ¤ì¤˜'")
        sys.exit(1)
    
    workspace = get_workspace_root()
    bridge = LuaTrinityBridge(workspace)
    
    request = ' '.join(sys.argv[1:])
    print(f"ğŸ­ ì½”ì–´ì˜ ìš”ì²­: {request}\n")
    
    response = bridge.process_lua_request(request)
    formatted = bridge.format_for_chatgpt(response)
    
    print(formatted)
    
    # íŒŒì¼ë¡œë„ ì €ì¥ (ChatGPTì— ë³µì‚¬ ë¶™ì—¬ë„£ê¸° ìš©ì´)
    output_file = workspace / "outputs" / "lua_response_latest.md"
    output_file.write_text(formatted, encoding='utf-8')
    print(f"\nğŸ’¾ ì €ì¥ë¨: {output_file}")


if __name__ == '__main__':
    main()
