#!/usr/bin/env python3
"""
Resonance Ledger Backfill: í•„ë“œëª… ì •ê·œí™” ì†Œê¸‰ ì ìš©

ê¸°ì¡´ 34,314ê°œ ì´ë²¤íŠ¸ì— ì •ê·œí™”ëœ quality/latency_ms í•„ë“œ ì¶”ê°€

ë£¨ë©˜(åˆ) ê¶Œì¥: ì‹œê°„ íˆ¬ì ëŒ€ë¹„ íš¨ê³¼ ê·¹ëŒ€í™” (10ë¶„ â†’ 10%+ ì»¤ë²„ë¦¬ì§€)

Usage:
    python scripts/backfill_ledger_metrics.py [--dry-run] [--recent-days 7]

Options:
    --dry-run: ì‹¤ì œ ì“°ê¸° ì—†ì´ ì‹œë®¬ë ˆì´ì…˜
    --recent-days: ìµœê·¼ Nì¼ ì´ë²¤íŠ¸ë§Œ ì²˜ë¦¬ (ê¸°ë³¸: ì „ì²´)
    --backup: Ledger ë°±ì—… ìƒì„± (ê¸°ë³¸: True)
"""

import argparse
import json
import shutil
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Dict, Any, List

# Repo root detection
REPO_ROOT = Path(__file__).parent.parent
LEDGER_PATH = REPO_ROOT / "fdo_agi_repo" / "memory" / "resonance_ledger.jsonl"


# Field normalization rules (event_emitter.pyì™€ ë™ì¼)
FIELD_ALIASES = {
    'agi_quality': 'quality',
    'lumen_latency_ms': 'latency_ms',
    'duration_sec': 'latency_ms',  # ë³€í™˜ í•„ìš” (ì´ˆ â†’ ë°€ë¦¬ì´ˆ)
}


def normalize_event(event: Dict[str, Any]) -> Dict[str, Any]:
    """
    ì´ë²¤íŠ¸ì— ì •ê·œí™”ëœ í•„ë“œ ì¶”ê°€
    
    Args:
        event: ì›ë³¸ ì´ë²¤íŠ¸
    
    Returns:
        ì •ê·œí™”ëœ ì´ë²¤íŠ¸ (ì›ë³¸ í•„ë“œ ìœ ì§€)
    """
    normalized = event.copy()
    
    for old_name, new_name in FIELD_ALIASES.items():
        # ì´ë¯¸ ì •ê·œí™”ëœ í•„ë“œê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
        if new_name in normalized:
            continue
        
        # ë ˆê±°ì‹œ í•„ë“œê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if old_name not in normalized:
            continue
        
        value = normalized[old_name]
        
        # duration_sec â†’ latency_ms ë³€í™˜ (ì´ˆ â†’ ë°€ë¦¬ì´ˆ)
        if old_name == 'duration_sec' and new_name == 'latency_ms':
            value = float(value) * 1000
        
        normalized[new_name] = value
    
    return normalized


def should_process_event(event: Dict[str, Any], recent_days: int = None) -> bool:
    """
    ì´ë²¤íŠ¸ ì²˜ë¦¬ ì—¬ë¶€ ê²°ì •
    
    Args:
        event: ì´ë²¤íŠ¸
        recent_days: ìµœê·¼ Nì¼ ì´ë²¤íŠ¸ë§Œ ì²˜ë¦¬ (None: ì „ì²´)
    
    Returns:
        ì²˜ë¦¬ ì—¬ë¶€
    """
    # recent_days ì§€ì • ì•ˆ ë¨: ëª¨ë‘ ì²˜ë¦¬
    if recent_days is None:
        return True
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ ì—†ìŒ: ìŠ¤í‚µ
    if 'timestamp' not in event:
        return False
    
    # Unix timestamp ê¸°ë°˜ í•„í„°ë§
    cutoff = datetime.now(timezone.utc) - timedelta(days=recent_days)
    event_time = datetime.fromtimestamp(event['timestamp'], tz=timezone.utc)
    
    return event_time >= cutoff


def backfill_metrics(
    dry_run: bool = False,
    recent_days: int = None,
    backup: bool = True
) -> Dict[str, Any]:
    """
    Ledger ë©”íŠ¸ë¦­ ì†Œê¸‰ ì ìš©
    
    Args:
        dry_run: Trueë©´ ì‹œë®¬ë ˆì´ì…˜ë§Œ
        recent_days: ìµœê·¼ Nì¼ë§Œ ì²˜ë¦¬ (None: ì „ì²´)
        backup: Trueë©´ ë°±ì—… ìƒì„±
    
    Returns:
        ì²˜ë¦¬ í†µê³„
    """
    stats = {
        'total_events': 0,
        'processed_events': 0,
        'quality_added': 0,
        'latency_added': 0,
        'skipped_events': 0,
    }
    
    # Ledger ì½ê¸°
    print(f"ğŸ“– Reading Ledger: {LEDGER_PATH}")
    events = []
    
    with open(LEDGER_PATH, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, start=1):
            line = line.strip()
            if not line:
                continue
            
            try:
                event = json.loads(line)
                events.append(event)
            except json.JSONDecodeError as e:
                print(f"âš ï¸ Line {line_num}: Invalid JSON - {e}")
                continue
    
    stats['total_events'] = len(events)
    print(f"âœ… Loaded {len(events):,} events")
    
    # ì´ë²¤íŠ¸ ì •ê·œí™”
    print(f"\nğŸ”„ Normalizing events...")
    normalized_events = []
    
    for event in events:
        # ìµœê·¼ Nì¼ í•„í„°ë§
        if not should_process_event(event, recent_days):
            stats['skipped_events'] += 1
            normalized_events.append(event)  # ì›ë³¸ ìœ ì§€
            continue
        
        # ì •ê·œí™” ì „ ìƒíƒœ
        had_quality = 'quality' in event
        had_latency = 'latency_ms' in event
        
        # ì •ê·œí™” ì‹¤í–‰
        normalized = normalize_event(event)
        normalized_events.append(normalized)
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        stats['processed_events'] += 1
        
        if not had_quality and 'quality' in normalized:
            stats['quality_added'] += 1
        
        if not had_latency and 'latency_ms' in normalized:
            stats['latency_added'] += 1
    
    # í†µê³„ ì¶œë ¥
    print(f"\nğŸ“Š Backfill Statistics:")
    print(f"   Total Events: {stats['total_events']:,}")
    print(f"   Processed: {stats['processed_events']:,}")
    print(f"   Skipped (too old): {stats['skipped_events']:,}")
    print(f"   Quality Added: {stats['quality_added']:,}")
    print(f"   Latency Added: {stats['latency_added']:,}")
    
    if recent_days:
        print(f"   Filter: Recent {recent_days} days")
    
    # ì˜ˆìƒ ì»¤ë²„ë¦¬ì§€
    if stats['total_events'] > 0:
        quality_coverage = ((stats['quality_added'] + 123) / stats['total_events']) * 100
        latency_coverage = ((stats['latency_added'] + 85) / stats['total_events']) * 100
        
        print(f"\nğŸ¯ Expected Coverage:")
        print(f"   Quality: 0.4% â†’ {quality_coverage:.1f}%")
        print(f"   Latency: 0.2% â†’ {latency_coverage:.1f}%")
    
    # Dry-run ì¢…ë£Œ
    if dry_run:
        print(f"\nâš ï¸ DRY-RUN MODE - No changes written")
        return stats
    
    # ë°±ì—… ìƒì„±
    if backup:
        backup_path = LEDGER_PATH.with_suffix('.jsonl.backup')
        print(f"\nğŸ’¾ Creating backup: {backup_path}")
        shutil.copy2(LEDGER_PATH, backup_path)
        print(f"âœ… Backup saved")
    
    # Ledger ì“°ê¸°
    print(f"\nğŸ’¾ Writing normalized Ledger...")
    
    with open(LEDGER_PATH, 'w', encoding='utf-8') as f:
        for event in normalized_events:
            f.write(json.dumps(event, ensure_ascii=False) + '\n')
    
    print(f"âœ… Ledger updated: {LEDGER_PATH}")
    
    return stats


def main():
    parser = argparse.ArgumentParser(
        description="Backfill Resonance Ledger with normalized metrics"
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Simulate without writing changes'
    )
    parser.add_argument(
        '--recent-days',
        type=int,
        default=None,
        help='Only process events from last N days (default: all)'
    )
    parser.add_argument(
        '--no-backup',
        action='store_true',
        help='Skip backup creation (not recommended)'
    )
    
    args = parser.parse_args()
    
    print("ğŸš€ Resonance Ledger Backfill\n")
    print("=" * 60)
    
    stats = backfill_metrics(
        dry_run=args.dry_run,
        recent_days=args.recent_days,
        backup=not args.no_backup
    )
    
    print("\n" + "=" * 60)
    print("ğŸ‰ Backfill Complete!")
    
    if args.dry_run:
        print("\nğŸ’¡ Run without --dry-run to apply changes")


if __name__ == '__main__':
    main()
