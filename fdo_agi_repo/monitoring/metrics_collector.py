"""
ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
- RPA ì‘ì—… ì„±ê³µë¥ , ì‘ë‹µì‹œê°„, ì—ëŸ¬ìœ¨ ë“± ìˆ˜ì§‘
- ì‹œê³„ì—´ ë°ì´í„°ë¡œ ì €ì¥í•˜ì—¬ íŠ¸ë Œë“œ ë¶„ì„ ê°€ëŠ¥
"""
import time
import json
from pathlib import Path
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, asdict
from datetime import datetime
from collections import deque
from threading import Lock


@dataclass
class MetricSnapshot:
    """ë©”íŠ¸ë¦­ ìŠ¤ëƒ…ìƒ·"""
    timestamp: float
    total_tasks: int
    successful_tasks: int
    failed_tasks: int
    avg_response_time_ms: float
    error_rate: float
    active_workers: int
    queue_size: int
    memory_usage_mb: float
    cpu_usage_percent: float
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return asdict(self)
    
    @property
    def success_rate(self) -> float:
        """ì„±ê³µë¥  (%)"""
        if self.total_tasks == 0:
            return 0.0
        return (self.successful_tasks / self.total_tasks) * 100


class MetricsCollector:
    """ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, history_size: int = 100, persist_path: Optional[Path] = None):
        """
        Args:
            history_size: ë©”ëª¨ë¦¬ì— ë³´ê´€í•  ìµœëŒ€ ìŠ¤ëƒ…ìƒ· ê°œìˆ˜
            persist_path: ë©”íŠ¸ë¦­ì„ ì €ì¥í•  íŒŒì¼ ê²½ë¡œ (JSONL)
        """
        self.history_size = history_size
        self.persist_path = persist_path
        
        # ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ (deque for O(1) append/pop)
        self._snapshots: deque[MetricSnapshot] = deque(maxlen=history_size)
        self._lock = Lock()
        
        # ëˆ„ì  í†µê³„
        self._total_tasks = 0
        self._successful_tasks = 0
        self._failed_tasks = 0
        self._response_times: deque[float] = deque(maxlen=1000)  # ìµœê·¼ 1000ê°œ
        
        # í˜„ì¬ ìƒíƒœ
        self._active_workers = 0
        self._queue_size = 0
    
    def record_task(self, success: bool, response_time_ms: float):
        """ì‘ì—… ì‹¤í–‰ ê²°ê³¼ ê¸°ë¡"""
        with self._lock:
            self._total_tasks += 1
            if success:
                self._successful_tasks += 1
            else:
                self._failed_tasks += 1
            
            self._response_times.append(response_time_ms)
    
    def update_worker_count(self, count: int):
        """í™œì„± Worker ìˆ˜ ì—…ë°ì´íŠ¸"""
        with self._lock:
            self._active_workers = count
    
    def update_queue_size(self, size: int):
        """Queue í¬ê¸° ì—…ë°ì´íŠ¸"""
        with self._lock:
            self._queue_size = size
    
    def take_snapshot(self, memory_mb: float = 0.0, cpu_percent: float = 0.0) -> MetricSnapshot:
        """í˜„ì¬ ìƒíƒœì˜ ìŠ¤ëƒ…ìƒ· ìƒì„±"""
        with self._lock:
            # í‰ê·  ì‘ë‹µ ì‹œê°„ ê³„ì‚°
            avg_response = sum(self._response_times) / len(self._response_times) if self._response_times else 0.0
            
            # ì—ëŸ¬ìœ¨ ê³„ì‚°
            error_rate = (self._failed_tasks / max(self._total_tasks, 1)) * 100
            
            snapshot = MetricSnapshot(
                timestamp=time.time(),
                total_tasks=self._total_tasks,
                successful_tasks=self._successful_tasks,
                failed_tasks=self._failed_tasks,
                avg_response_time_ms=avg_response,
                error_rate=error_rate,
                active_workers=self._active_workers,
                queue_size=self._queue_size,
                memory_usage_mb=memory_mb,
                cpu_usage_percent=cpu_percent,
            )
            
            # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self._snapshots.append(snapshot)
            
            # íŒŒì¼ì— ì €ì¥ (ì˜µì…˜)
            if self.persist_path:
                self._persist_snapshot(snapshot)
            
            return snapshot
    
    def _persist_snapshot(self, snapshot: MetricSnapshot):
        """ìŠ¤ëƒ…ìƒ·ì„ JSONL íŒŒì¼ì— ì €ì¥"""
        try:
            self.persist_path.parent.mkdir(parents=True, exist_ok=True)
            with open(self.persist_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(snapshot.to_dict()) + "\n")
        except Exception as e:
            print(f"Failed to persist snapshot: {e}")
    
    def get_recent_snapshots(self, count: int = 10) -> List[MetricSnapshot]:
        """ìµœê·¼ Nê°œì˜ ìŠ¤ëƒ…ìƒ· ì¡°íšŒ"""
        with self._lock:
            # dequeëŠ” FIFOì´ë¯€ë¡œ ë§ˆì§€ë§‰ Nê°œê°€ ìµœì‹ 
            return list(self._snapshots)[-count:]
    
    def get_statistics(self, window_seconds: Optional[float] = None) -> Dict[str, Any]:
        """í†µê³„ ì¡°íšŒ
        
        Args:
            window_seconds: ì§€ì • ì‹œ í•´ë‹¹ ì‹œê°„ ë‚´ì˜ ìŠ¤ëƒ…ìƒ·ë§Œ ì‚¬ìš©
        """
        with self._lock:
            if window_seconds:
                cutoff = time.time() - window_seconds
                snapshots = [s for s in self._snapshots if s.timestamp >= cutoff]
            else:
                snapshots = list(self._snapshots)
            
            if not snapshots:
                return {
                    "count": 0,
                    "avg_success_rate": 0.0,
                    "avg_error_rate": 0.0,
                    "avg_response_time_ms": 0.0,
                    "max_response_time_ms": 0.0,
                    "min_response_time_ms": 0.0,
                }
            
            success_rates = [s.success_rate for s in snapshots]
            error_rates = [s.error_rate for s in snapshots]
            response_times = [s.avg_response_time_ms for s in snapshots]
            
            return {
                "count": len(snapshots),
                "window_seconds": window_seconds,
                "avg_success_rate": sum(success_rates) / len(success_rates),
                "avg_error_rate": sum(error_rates) / len(error_rates),
                "avg_response_time_ms": sum(response_times) / len(response_times),
                "max_response_time_ms": max(response_times),
                "min_response_time_ms": min(response_times),
                "total_tasks": snapshots[-1].total_tasks if snapshots else 0,
                "successful_tasks": snapshots[-1].successful_tasks if snapshots else 0,
                "failed_tasks": snapshots[-1].failed_tasks if snapshots else 0,
            }
    
    def reset(self):
        """ëª¨ë“  ë©”íŠ¸ë¦­ ì´ˆê¸°í™”"""
        with self._lock:
            self._total_tasks = 0
            self._successful_tasks = 0
            self._failed_tasks = 0
            self._response_times.clear()
            self._snapshots.clear()
            self._active_workers = 0
            self._queue_size = 0


class DashboardRenderer:
    """ì½˜ì†” ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ ë Œë”ëŸ¬"""
    
    @staticmethod
    def render(snapshot: MetricSnapshot, stats: Dict[str, Any]) -> str:
        """ìŠ¤ëƒ…ìƒ·ê³¼ í†µê³„ë¥¼ ì½˜ì†” ì¹œí™”ì ìœ¼ë¡œ ë Œë”ë§"""
        timestamp_str = datetime.fromtimestamp(snapshot.timestamp).strftime("%Y-%m-%d %H:%M:%S")
        
        # ì„±ê³µë¥ ì— ë”°ë¥¸ ìƒ‰ìƒ (í„°ë¯¸ë„ ANSI ì½”ë“œ)
        success_rate = snapshot.success_rate
        if success_rate >= 95:
            status_icon = "âœ…"
            status_color = "\033[92m"  # Green
        elif success_rate >= 80:
            status_icon = "âš ï¸"
            status_color = "\033[93m"  # Yellow
        else:
            status_icon = "âŒ"
            status_color = "\033[91m"  # Red
        
        reset_color = "\033[0m"
        
        lines = [
            "=" * 70,
            f"ğŸ” RPA Monitoring Dashboard - {timestamp_str}",
            "=" * 70,
            "",
            f"{status_icon} System Status: {status_color}{success_rate:.1f}% Success Rate{reset_color}",
            "",
            "ğŸ“Š Current Metrics:",
            f"  Total Tasks:     {snapshot.total_tasks}",
            f"  Successful:      {snapshot.successful_tasks} âœ…",
            f"  Failed:          {snapshot.failed_tasks} âŒ",
            f"  Success Rate:    {success_rate:.1f}%",
            f"  Error Rate:      {snapshot.error_rate:.1f}%",
            f"  Avg Response:    {snapshot.avg_response_time_ms:.2f}ms",
            "",
            "ğŸ”§ Infrastructure:",
            f"  Active Workers:  {snapshot.active_workers}",
            f"  Queue Size:      {snapshot.queue_size}",
            f"  Memory Usage:    {snapshot.memory_usage_mb:.1f}MB",
            f"  CPU Usage:       {snapshot.cpu_usage_percent:.1f}%",
            "",
            "ğŸ“ˆ Statistics (Recent Window):",
            f"  Snapshots:       {stats['count']}",
            f"  Avg Success:     {stats['avg_success_rate']:.1f}%",
            f"  Avg Error:       {stats['avg_error_rate']:.1f}%",
            f"  Avg Response:    {stats['avg_response_time_ms']:.2f}ms",
            f"  Max Response:    {stats['max_response_time_ms']:.2f}ms",
            f"  Min Response:    {stats['min_response_time_ms']:.2f}ms",
            "=" * 70,
        ]
        
        return "\n".join(lines)
    
    @staticmethod
    def render_compact(snapshot: MetricSnapshot) -> str:
        """ì»´íŒ©íŠ¸í•œ í•œ ì¤„ ìš”ì•½"""
        timestamp_str = datetime.fromtimestamp(snapshot.timestamp).strftime("%H:%M:%S")
        return (
            f"[{timestamp_str}] "
            f"Tasks: {snapshot.total_tasks} "
            f"| Success: {snapshot.success_rate:.1f}% "
            f"| Errors: {snapshot.error_rate:.1f}% "
            f"| Response: {snapshot.avg_response_time_ms:.0f}ms "
            f"| Workers: {snapshot.active_workers} "
            f"| Queue: {snapshot.queue_size}"
        )


def demo_metrics_collector():
    """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ë°ëª¨"""
    import random
    
    print("ğŸ” Metrics Collector Demo\n")
    
    # ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    output_dir = Path(__file__).parent.parent / "outputs"
    collector = MetricsCollector(
        history_size=50,
        persist_path=output_dir / "metrics_demo.jsonl"
    )
    
    # ì‹œë®¬ë ˆì´ì…˜: 10ì´ˆê°„ ì‘ì—… ì‹¤í–‰
    print("Simulating RPA tasks for 10 seconds...\n")
    
    for i in range(20):
        # ì‘ì—… ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜
        num_tasks = random.randint(1, 5)
        for _ in range(num_tasks):
            success = random.random() > 0.1  # 90% ì„±ê³µë¥ 
            response_time = random.uniform(50, 500)  # 50-500ms
            collector.record_task(success, response_time)
        
        # ì¸í”„ë¼ ìƒíƒœ ì—…ë°ì´íŠ¸
        collector.update_worker_count(random.randint(1, 3))
        collector.update_queue_size(random.randint(0, 10))
        
        # ìŠ¤ëƒ…ìƒ· ìƒì„±
        memory = random.uniform(50, 150)
        cpu = random.uniform(20, 80)
        snapshot = collector.take_snapshot(memory, cpu)
        
        # í†µê³„ ì¡°íšŒ
        stats = collector.get_statistics(window_seconds=60)
        
        # ëŒ€ì‹œë³´ë“œ ë Œë”ë§ (5ì´ˆë§ˆë‹¤ ìƒì„¸, ë‚˜ë¨¸ì§€ëŠ” ì»´íŒ©íŠ¸)
        if i % 5 == 0:
            print(DashboardRenderer.render(snapshot, stats))
        else:
            print(DashboardRenderer.render_compact(snapshot))
        
        time.sleep(0.5)
    
    # ìµœì¢… í†µê³„
    print("\n" + "=" * 70)
    print("ğŸ“Š Final Statistics")
    print("=" * 70)
    
    final_stats = collector.get_statistics()
    for key, value in final_stats.items():
        if isinstance(value, float):
            print(f"  {key}: {value:.2f}")
        else:
            print(f"  {key}: {value}")
    
    print(f"\nMetrics saved to: {collector.persist_path}")
    print(f"Total snapshots collected: {len(collector.get_recent_snapshots(100))}")


if __name__ == "__main__":
    demo_metrics_collector()
