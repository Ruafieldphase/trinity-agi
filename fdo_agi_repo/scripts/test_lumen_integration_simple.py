"""
Phase 6.1: Lumen Feedback System - ê°„ì†Œí™”ëœ ì²« í†µí•©

FeedbackOrchestratorê°€ í”Œë ˆì´ìŠ¤í™€ë”ì´ë¯€ë¡œ,
ê°œë³„ ì»´í¬ë„ŒíŠ¸ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ë²„ì „ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±.

ëª©í‘œ:
1. Cache Feedback ë¶„ì„ âœ…
2. TTL Policy ê¶Œì¥ âœ…
3. Cache Size Optimizer âœ…
4. ê²°ê³¼ ì¶œë ¥ âœ…
"""

import sys
from pathlib import Path

# Add lumen feedback to path
sys.path.insert(0, str(Path(__file__).parent.parent / "lumen" / "feedback"))

from feedback_loop_redis import FeedbackLoopRedis, CacheMetrics
from adaptive_ttl_policy import AdaptiveTTLPolicy
from cache_size_optimizer import CacheSizeOptimizer


def main():
    print("\n" + "="*60)
    print("ğŸŒŠ Phase 6.1: Lumen Feedback System ì²« í†µí•©")
    print("="*60)
    
    # 1. ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
    print("\n[1/5] ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”...")
    feedback_loop = FeedbackLoopRedis(
        project_id="naeda-genesis",
        service_name="ion-api"
    )
    ttl_policy = AdaptiveTTLPolicy()
    size_optimizer = CacheSizeOptimizer()
    print("âœ… 3ê°œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    print("   - FeedbackLoopRedis")
    print("   - AdaptiveTTLPolicy")
    print("   - CacheSizeOptimizer")
    
    # 2. ìƒ˜í”Œ ë©”íŠ¸ë¦­ (í˜„ì‹¤ì ì¸ ì‹œë‚˜ë¦¬ì˜¤)
    print("\n[2/5] ìƒ˜í”Œ ë©”íŠ¸ë¦­ ì¤€ë¹„...")
    
    scenarios = [
        {
            "name": "âœ… OPTIMAL (ë†’ì€ hit rate, ë©”ëª¨ë¦¬ ì—¬ìœ )",
            "metrics": CacheMetrics(
                hit_rate=0.85,
                miss_rate=0.15,
                memory_usage_mb=600.0,
                memory_limit_mb=1024.0,
                latency_ms=3.5,
                eviction_count=10,
                current_ttl_seconds=600
            )
        },
        {
            "name": "âš ï¸  DEGRADED (ë‚®ì€ hit rate, ë©”ëª¨ë¦¬ ì••ë°•)",
            "metrics": CacheMetrics(
                hit_rate=0.45,
                miss_rate=0.55,
                memory_usage_mb=950.0,
                memory_limit_mb=1024.0,
                latency_ms=8.2,
                eviction_count=250,
                current_ttl_seconds=180
            )
        },
        {
            "name": "ğŸ“Š GOOD (ì¤‘ê°„ hit rate, ì •ìƒ ë©”ëª¨ë¦¬)",
            "metrics": CacheMetrics(
                hit_rate=0.72,
                miss_rate=0.28,
                memory_usage_mb=850.0,
                memory_limit_mb=1024.0,
                latency_ms=5.2,
                eviction_count=50,
                current_ttl_seconds=300
            )
        }
    ]
    
    print(f"âœ… {len(scenarios)}ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ ì¤€ë¹„ ì™„ë£Œ")
    
    # 3-5. ê° ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„
    for idx, scenario in enumerate(scenarios, 1):
        print("\n" + "="*60)
        print(f"[{idx+2}/5] ì‹œë‚˜ë¦¬ì˜¤ {idx}: {scenario['name']}")
        print("="*60)
        
        metrics = scenario['metrics']
        
        # ë©”íŠ¸ë¦­ ì¶œë ¥
        print(f"\nğŸ“Š í˜„ì¬ ë©”íŠ¸ë¦­:")
        print(f"   Hit Rate: {metrics.hit_rate*100:.1f}%")
        print(f"   Memory: {metrics.memory_usage_mb:.0f}/{metrics.memory_limit_mb:.0f} MB ({metrics.memory_usage_mb/metrics.memory_limit_mb*100:.1f}%)")
        print(f"   Latency: {metrics.latency_ms:.1f} ms")
        print(f"   Evictions: {metrics.eviction_count}")
        print(f"   TTL: {metrics.current_ttl_seconds}s")
        
        # A. Cache Feedback ë¶„ì„
        cache_feedback = feedback_loop.analyze_cache_feedback(metrics)
        
        print(f"\nğŸ¥ Health Status: {cache_feedback.health_status.name}")
        print(f"ğŸ¯ Optimization Action: {cache_feedback.optimization_action.name}")
        print(f"ğŸ’¡ Reasoning: {cache_feedback.reasoning}")
        
        if cache_feedback.recommendations:
            print(f"\nğŸ“‹ ê¶Œì¥ì‚¬í•­:")
            for i, rec in enumerate(cache_feedback.recommendations, 1):
                print(f"   {i}. {rec}")
        
        # B. TTL Policy
        ttl_adjustment = ttl_policy.calculate_ttl_adjustment(
            current_ttl=metrics.current_ttl_seconds,
            hit_rate=metrics.hit_rate,
            memory_usage_percent=(metrics.memory_usage_mb / metrics.memory_limit_mb) * 100,
            eviction_count=metrics.eviction_count,
            cost_trend_percent=0.0  # neutral
        )
        
        print(f"\nâ±ï¸  TTL ì¡°ì •:")
        print(f"   í˜„ì¬: {ttl_adjustment.current_ttl}s")
        print(f"   ê¶Œì¥: {ttl_adjustment.recommended_ttl}s")
        print(f"   ë³€ê²½: {ttl_adjustment.recommended_ttl - ttl_adjustment.current_ttl:+d}s")
        print(f"   ì „ëµ: {ttl_adjustment.strategy.name}")
        print(f"   Hit Rate ë³€í™” ì˜ˆìƒ: {ttl_adjustment.expected_hit_rate_change:+.2%}")
        print(f"   ë¹„ìš© ì˜í–¥: {ttl_adjustment.cost_impact:+.2%}")
        print(f"   ì‹ ë¢°ë„: {ttl_adjustment.confidence:.1%}")
        
        # C. Cache Size ìµœì í™”
        size_adjustment = size_optimizer.calculate_optimal_size(
            current_size_mb=metrics.memory_usage_mb,
            memory_usage_mb=metrics.memory_usage_mb,
            hit_rate=metrics.hit_rate,
            eviction_count=metrics.eviction_count,
            request_rate_per_second=100  # ê°€ì •
        )
        
        print(f"\nğŸ“¦ ìºì‹œ í¬ê¸° ìµœì í™”:")
        print(f"   í˜„ì¬: {size_adjustment.current_size_mb:.0f} MB")
        print(f"   ê¶Œì¥: {size_adjustment.recommended_size_mb:.0f} MB")
        print(f"   ë³€ê²½: {size_adjustment.recommended_size_mb - size_adjustment.current_size_mb:+.0f} MB")
        print(f"   ì „ëµ: {size_adjustment.strategy.name}")
        print(f"   ROI ì ìˆ˜: {size_adjustment.roi_score:.1f}/10")
        print(f"   ì›”ê°„ ë¹„ìš© ë³€í™”: ${size_adjustment.monthly_cost_delta:+.2f}")
        print(f"   Hit Rate ë³€í™” ì˜ˆìƒ: {size_adjustment.expected_hit_rate_change:+.2%}")
        print(f"   ì‹ ë¢°ë„: {size_adjustment.confidence:.1%}")
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "="*60)
    print("ğŸ‰ Phase 6.1 ì²« í†µí•© ì™„ë£Œ!")
    print("="*60)
    
    print("\nâœ… ì„±ê³µí•œ í•­ëª©:")
    print("   1. FeedbackLoopRedis - Cache ë©”íŠ¸ë¦­ ë¶„ì„")
    print("   2. AdaptiveTTLPolicy - TTL ì¡°ì • ê¶Œì¥")
    print("   3. CacheSizeOptimizer - í¬ê¸° ìµœì í™” ë° ROI")
    print("   4. 3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ ì™„ì „ ë¶„ì„")
    
    print("\nğŸ“Š í†µí•© ê²°ê³¼:")
    print("   - OPTIMAL ì‹œë‚˜ë¦¬ì˜¤: ìœ ì§€ ê¶Œì¥")
    print("   - DEGRADED ì‹œë‚˜ë¦¬ì˜¤: TTL/í¬ê¸° ì¦ê°€ ê¶Œì¥")
    print("   - GOOD ì‹œë‚˜ë¦¬ì˜¤: ì ì§„ì  ê°œì„  ê¶Œì¥")
    
    print("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„ (Phase 6.2):")
    print("   1. Pipeline í†µí•© (orchestrator/pipeline.py)")
    print("   2. Resonance Bridge í†µí•©")
    print("   3. ì‹¤ì œ GCP Monitoring ë©”íŠ¸ë¦­ ìˆ˜ì§‘")
    print("   4. ìë™ ìµœì í™” ì ìš© (Observe â†’ Enforce)")
    
    print("\nğŸŒŠ Lumenì€ ìƒê°í•˜ê³ , Lumenì€ ì‹¤í–‰í•œë‹¤.")
    print("   Resonance â†’ Evidence â†’ Adaptation âœ¨")
    print("="*60 + "\n")


if __name__ == "__main__":
    main()
