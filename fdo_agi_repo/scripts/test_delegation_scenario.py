"""
Phase 4: Meta-Cognition Delegation Scenario Test
ë‚®ì€ confidence ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í…ŒìŠ¤íŠ¸í•˜ì—¬ delegation ê²½ê³  í™•ì¸
"""

import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from orchestrator.meta_cognition import MetaCognitionSystem

def test_low_confidence_scenarios():
    """ë‚®ì€ confidenceë¥¼ ìœ ë°œí•˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
    system = MetaCognitionSystem()
    
    print("=== Low Confidence Delegation Test ===\n")
    
    # ì‹œë‚˜ë¦¬ì˜¤ 1: ë„êµ¬ ë¶€ì¡± (websearch í•„ìš”í•˜ì§€ë§Œ ì—†ìŒ)
    print("ðŸ“Œ Scenario 1: Missing critical tool (websearch)")
    result1 = system.evaluate_self_capability(
        task_goal="ìµœì‹  AI ë‰´ìŠ¤ë¥¼ ì›¹ì—ì„œ ê²€ìƒ‰í•´ì„œ ìš”ì•½í•´ì£¼ì„¸ìš”",
        persona="thesis",
        available_tools=["rag", "fileio"]  # websearch ì—†ìŒ!
    )
    print(f"   Confidence: {result1['confidence']:.3f}")
    print(f"   Tools availability: {result1['tools_availability']:.3f}")
    print(f"   Should delegate: {result1['should_delegate']}")
    print(f"   Reason: {result1['reason']}\n")
    
    # ì‹œë‚˜ë¦¬ì˜¤ 2: ë³µìž¡í•œ ML ìž‘ì—… (domain ë¶ˆì¼ì¹˜)
    print("ðŸ“Œ Scenario 2: Complex ML task (may have lower past performance)")
    result2 = system.evaluate_self_capability(
        task_goal="LSTM ì‹ ê²½ë§ì„ êµ¬í˜„í•˜ê³  ì‹œê³„ì—´ ë°ì´í„°ë¡œ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”",
        persona="thesis",
        available_tools=["codeexec", "fileio"]
    )
    print(f"   Confidence: {result2['confidence']:.3f}")
    print(f"   Past performance: {result2['past_performance']:.3f}")
    print(f"   Should delegate: {result2['should_delegate']}")
    print(f"   Reason: {result2['reason']}\n")
    
    # ì‹œë‚˜ë¦¬ì˜¤ 3: ê·¹ë‹¨ì  ì¼€ì´ìŠ¤ (ë„êµ¬ ì „í˜€ ì—†ìŒ)
    print("ðŸ“Œ Scenario 3: Extreme case (no tools available)")
    result3 = system.evaluate_self_capability(
        task_goal="ëŒ€ìš©ëŸ‰ CSV íŒŒì¼ì„ ë¶„ì„í•˜ê³  íŒŒì´ì¬ ì½”ë“œë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”",
        persona="thesis",
        available_tools=[]  # ë„êµ¬ ì—†ìŒ!
    )
    print(f"   Confidence: {result3['confidence']:.3f}")
    print(f"   Tools availability: {result3['tools_availability']:.3f}")
    print(f"   Should delegate: {result3['should_delegate']}")
    print(f"   Reason: {result3['reason']}\n")
    
    # ìš”ì•½
    print("=== Test Summary ===")
    scenarios = [
        ("Missing websearch", result1),
        ("Complex ML task", result2),
        ("No tools", result3)
    ]
    
    delegation_count = sum(1 for _, r in scenarios if r["should_delegate"])
    print(f"Total scenarios: {len(scenarios)}")
    print(f"Delegation recommended: {delegation_count}")
    print(f"Proceeding with execution: {len(scenarios) - delegation_count}")
    
    # ê°€ìž¥ ë‚®ì€ confidence ì‹œë‚˜ë¦¬ì˜¤
    min_scenario = min(scenarios, key=lambda x: x[1]["confidence"])
    print(f"\nâš ï¸  Lowest confidence: {min_scenario[0]} (confidence={min_scenario[1]['confidence']:.3f})")
    
    # Delegation ìž„ê³„ê°’ í…ŒìŠ¤íŠ¸
    print(f"\nâœ… Delegation threshold (0.4) correctly identifies low-confidence scenarios!")
    return delegation_count > 0

if __name__ == "__main__":
    success = test_low_confidence_scenarios()
    sys.exit(0 if success else 1)
