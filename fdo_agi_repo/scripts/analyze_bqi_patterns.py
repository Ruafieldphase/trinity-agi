"""
BQI Training Data ì‹¬ì¸µ ë¶„ì„

ëª©ì :
1. ê°ì • í‚¤ì›Œë“œ ê°œì„  ë°©ì•ˆ ë„ì¶œ (í˜„ì¬ 0.1% ì¸ì‹ë¥ )
2. ê³ ë¹ˆë„ ì§ˆë¬¸ íŒ¨í„´ ë¶„ì„
3. Rhythm Phase ì „í™˜ íŒ¨í„´ íŒŒì•…
4. ì‚¬ìš©ì ëŒ€í™” ìŠ¤íƒ€ì¼ í”„ë¡œíŒŒì¼ë§

Author: GitHub Copilot
Created: 2025-10-28
"""

import json
import sys
from pathlib import Path
from collections import Counter, defaultdict
from typing import Dict, List, Any
import re

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "scripts"))

# UTF-8 ì¸ì½”ë”© ê°•ì œ ì„¤ì • (í•œê¸€ ê¹¨ì§ ë°©ì§€)
import encoding_setup


class BQIDataAnalyzer:
    """BQI Training Data ë¶„ì„ê¸°"""
    
    def __init__(self, data_file: str = "memory/bqi_training_dataset.jsonl"):
        self.data_file = Path(__file__).parent.parent / data_file
        self.data: List[Dict[str, Any]] = []
        self.load_data()
    
    def load_data(self):
        """Training data ë¡œë“œ"""
        if not self.data_file.exists():
            raise FileNotFoundError(f"Training data not found: {self.data_file}")
        
        with open(self.data_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    self.data.append(json.loads(line))
        
        print(f"ğŸ“‚ Loaded {len(self.data)} training examples\n")
    
    def analyze_emotion_failures(self, sample_size: int = 50):
        """
        ê°ì •ì´ 'neutral'ë¡œ ë¶„ë¥˜ëœ ì§ˆë¬¸ë“¤ì„ ìƒ˜í”Œë§í•˜ì—¬ ì‹¤ì œ ê°ì • ë¶„ì„
        
        ëª©í‘œ: ë†“ì¹œ ê°ì • í‚¤ì›Œë“œ ë°œê²¬
        """
        print("=" * 70)
        print("1. ê°ì • ì¸ì‹ ì‹¤íŒ¨ ë¶„ì„ (Neutralë¡œ ë¶„ë¥˜ëœ ì§ˆë¬¸ë“¤)")
        print("=" * 70)
        
        neutral_questions = [
            d for d in self.data
            if d['bqi']['emotion']['keywords'] == ['neutral']
        ]
        
        print(f"Neutral ë¶„ë¥˜: {len(neutral_questions)} / {len(self.data)} ({len(neutral_questions)/len(self.data)*100:.1f}%)\n")
        
        # í•œê¸€ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
        korean_words = Counter()
        emotion_patterns = {
            'hope': ['ê¸°ëŒ€', 'í¬ë§', 'ê°€ëŠ¥', 'ë ê¹Œ', 'í•´ë³´', 'ì¢‹ì„', 'ë°œì „', 'ì„±ì¥'],
            'concern': ['ê±±ì •', 'ë¶ˆì•ˆ', 'ë¬¸ì œ', 'ìœ„í—˜', 'ì‹¤íŒ¨', 'ì–´ë ¤', 'í˜ë“¤', 'ìš°ë ¤'],
            'focus': ['ì§€ê¸ˆ', 'í˜„ì¬', 'ë‹¹ì¥', 'ì¦‰ì‹œ', 'ë°”ë¡œ', 'ë¨¼ì €'],
            'integration': ['í†µí•©', 'í•©ì¹˜', 'ì—°ê²°', 'ì¡°í•©', 'ë¬¶', 'í†µì¼']
        }
        
        # ìƒ˜í”Œ ì§ˆë¬¸ì—ì„œ ê°ì • í‚¤ì›Œë“œ í›„ë³´ ì°¾ê¸°
        print(f"ë¬´ì‘ìœ„ ìƒ˜í”Œ {sample_size}ê°œ ë¶„ì„:\n")
        
        import random
        samples = random.sample(neutral_questions, min(sample_size, len(neutral_questions)))
        
        found_emotions = defaultdict(list)
        
        for i, sample in enumerate(samples[:20], 1):  # ì²˜ìŒ 20ê°œë§Œ ì¶œë ¥
            q = sample['question']
            q_lower = q.lower()
            
            # ê° ê°ì • íŒ¨í„´ ë§¤ì¹­
            detected = []
            for emotion, keywords in emotion_patterns.items():
                if any(kw in q for kw in keywords):
                    detected.append(emotion)
                    found_emotions[emotion].append(q)
            
            if detected:
                print(f"[{i}] {emotion.upper()} ê°ì§€: {q[:60]}...")
                print(f"    ë§¤ì¹­: {', '.join(detected)}\n")
        
        # ê°ì •ë³„ í†µê³„
        print("\nê°ì • í‚¤ì›Œë“œ ë°œê²¬ í†µê³„:")
        for emotion, questions in found_emotions.items():
            print(f"  {emotion}: {len(questions)}ê°œ ì§ˆë¬¸ì—ì„œ ë°œê²¬")
        
        return found_emotions
    
    def analyze_question_patterns(self):
        """ì§ˆë¬¸ ìœ í˜• íŒ¨í„´ ë¶„ì„"""
        print("\n" + "=" * 70)
        print("2. ì§ˆë¬¸ ìœ í˜• íŒ¨í„´ ë¶„ì„")
        print("=" * 70)
        
        # ì§ˆë¬¸ ì‹œì‘ íŒ¨í„´
        start_patterns = Counter()
        question_types = Counter()
        
        for d in self.data:
            q = d['question'].strip()
            
            # ì²« ë‹¨ì–´ ì¶”ì¶œ
            first_words = q.split()[:2]
            if first_words:
                start_patterns[' '.join(first_words)] += 1
            
            # ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜
            if '?' in q or '?' in q:
                question_types['interrogative'] += 1
            elif any(word in q for word in ['í•´ì¤˜', 'ì•Œë ¤', 'ì„¤ëª…', 'ë³´ì—¬ì¤˜']):
                question_types['request'] += 1
            elif any(word in q for word in ['ì–´ë•Œ', 'ì–´ë–»ê²Œ', 'ë­ì•¼', 'ë­˜ê¹Œ']):
                question_types['inquiry'] += 1
            else:
                question_types['statement'] += 1
        
        print("\nì§ˆë¬¸ ì‹œì‘ íŒ¨í„´ (Top 20):")
        for pattern, count in start_patterns.most_common(20):
            print(f"  '{pattern}': {count}íšŒ")
        
        print("\nì§ˆë¬¸ ìœ í˜• ë¶„í¬:")
        total = sum(question_types.values())
        for qtype, count in question_types.most_common():
            print(f"  {qtype}: {count}ê°œ ({count/total*100:.1f}%)")
    
    def analyze_rhythm_transitions(self):
        """Rhythm Phase ì „í™˜ íŒ¨í„´ ë¶„ì„"""
        print("\n" + "=" * 70)
        print("3. Rhythm Phase ì „í™˜ íŒ¨í„´")
        print("=" * 70)
        
        # ëŒ€í™”ë³„ ê·¸ë£¹í•‘ (conversation_id ê¸°ì¤€)
        by_conversation = defaultdict(list)
        for d in self.data:
            conv_id = d['metadata']['conversation_id']
            by_conversation[conv_id].append(d)
        
        # ê° ëŒ€í™”ì—ì„œ rhythm ì „í™˜ ì¶”ì 
        transitions = Counter()
        
        for conv_id, turns in by_conversation.items():
            if len(turns) < 2:
                continue
            
            # ì‹œê°„ìˆœ ì •ë ¬
            turns_sorted = sorted(turns, key=lambda x: x['metadata']['date'])
            
            for i in range(len(turns_sorted) - 1):
                curr_rhythm = turns_sorted[i]['bqi']['rhythm_phase']
                next_rhythm = turns_sorted[i + 1]['bqi']['rhythm_phase']
                
                if curr_rhythm != next_rhythm:
                    transitions[f"{curr_rhythm} â†’ {next_rhythm}"] += 1
        
        print("\nRhythm Phase ì „í™˜ (Top 10):")
        for transition, count in transitions.most_common(10):
            print(f"  {transition}: {count}íšŒ")
        
        # Rhythmë³„ í‰ê·  ì§ˆë¬¸ ê¸¸ì´
        rhythm_lengths = defaultdict(list)
        for d in self.data:
            rhythm = d['bqi']['rhythm_phase']
            q_len = len(d['question'])
            rhythm_lengths[rhythm].append(q_len)
        
        print("\nRhythm Phaseë³„ í‰ê·  ì§ˆë¬¸ ê¸¸ì´:")
        for rhythm, lengths in sorted(rhythm_lengths.items()):
            avg_len = sum(lengths) / len(lengths)
            print(f"  {rhythm}: {avg_len:.1f}ì (ìƒ˜í”Œ {len(lengths)}ê°œ)")
    
    def suggest_emotion_keywords(self):
        """ê°œì„ ëœ ê°ì • í‚¤ì›Œë“œ ì œì•ˆ"""
        print("\n" + "=" * 70)
        print("4. ê°œì„ ëœ ê°ì • í‚¤ì›Œë“œ ì œì•ˆ")
        print("=" * 70)
        
        # ì‹¤ì œ ì§ˆë¬¸ì—ì„œ ìì£¼ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ ì¶”ì¶œ
        word_freq = Counter()
        
        for d in self.data:
            q = d['question']
            # í•œê¸€ ë‹¨ì–´ë§Œ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
            words = re.findall(r'[ê°€-í£]{2,}', q)
            word_freq.update(words)
        
        print("\nê³ ë¹ˆë„ í•œê¸€ ë‹¨ì–´ (Top 30):")
        for word, count in word_freq.most_common(30):
            print(f"  {word}: {count}íšŒ", end="  ")
            if count % 5 == 0:
                print()  # 5ê°œë§ˆë‹¤ ì¤„ë°”ê¿ˆ
        
        print("\n\nì œì•ˆí•˜ëŠ” ìƒˆ ê°ì • í‚¤ì›Œë“œ:")
        print("""
        _EMOTION_KEYWORDS = {
            "hope": [
                "hope", "growth", "expand", 
                "ê¸°ëŒ€", "í¬ë§", "ê°€ëŠ¥", "ë ê¹Œ", "ì¢‹ì„", "ë°œì „", "ì„±ì¥", "í•´ë³´"
            ],
            "concern": [
                "risk", "concern", "worry", 
                "ë¶ˆì•ˆ", "ìš°ë ¤", "ê±±ì •", "ë¬¸ì œ", "ìœ„í—˜", "ì‹¤íŒ¨", "ì–´ë ¤", "í˜ë“¤"
            ],
            "focus": [
                "now", "focus", 
                "ì§€ê¸ˆ", "í˜„ì¬", "ë‹¹ì¥", "ì¦‰ì‹œ", "ë°”ë¡œ", "ë¨¼ì €", "ìš°ì„ "
            ],
            "integration": [
                "integrate", 
                "í•©ì¹˜", "í†µí•©", "ì¡°ìœ¨", "ì—°ê²°", "ì¡°í•©", "ë¬¶", "í†µì¼", "í•©ì³"
            ],
            "curiosity": [  # ìƒˆ ê°ì • ì¶”ê°€
                "ê¶ê¸ˆ", "ì•Œê³ ", "ë­ì•¼", "ë­˜ê¹Œ", "ì–´ë–»ê²Œ", "ì™œ"
            ],
            "gratitude": [  # ìƒˆ ê°ì • ì¶”ê°€
                "ê³ ë§ˆ", "ê°ì‚¬", "ì¢‹ì•„", "ë©‹ì§€", "í›Œë¥­"
            ]
        }
        """)
    
    def analyze_priority_distribution(self):
        """Priority ë¶„í¬ ë¶„ì„"""
        print("\n" + "=" * 70)
        print("5. Priority ë¶„í¬ ë¶„ì„")
        print("=" * 70)
        
        priority_counts = Counter()
        priority_questions = defaultdict(list)
        
        for d in self.data:
            priority = d['bqi']['priority']
            priority_counts[priority] += 1
            priority_questions[priority].append(d['question'])
        
        print("\nPriority ë¶„í¬:")
        total = sum(priority_counts.values())
        for priority in sorted(priority_counts.keys(), reverse=True):
            count = priority_counts[priority]
            print(f"  Priority {priority}: {count}ê°œ ({count/total*100:.1f}%)")
        
        # ê° priority ìƒ˜í”Œ ì¶œë ¥
        print("\nPriorityë³„ ìƒ˜í”Œ ì§ˆë¬¸:")
        for priority in sorted(priority_counts.keys(), reverse=True):
            samples = priority_questions[priority][:3]
            print(f"\n  Priority {priority}:")
            for i, q in enumerate(samples, 1):
                print(f"    {i}. {q[:70]}...")
    
    def generate_report(self):
        """ì „ì²´ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n" + "=" * 70)
        print("BQI Training Data ì‹¬ì¸µ ë¶„ì„ ë¦¬í¬íŠ¸")
        print("=" * 70)
        print(f"ë¶„ì„ ì‹œê°„: 2025-10-28")
        print(f"ë°ì´í„° í¬ê¸°: {len(self.data)} ì§ˆë¬¸")
        print("=" * 70 + "\n")
        
        # 1. ê°ì • ì‹¤íŒ¨ ë¶„ì„
        found_emotions = self.analyze_emotion_failures(sample_size=100)
        
        # 2. ì§ˆë¬¸ íŒ¨í„´
        self.analyze_question_patterns()
        
        # 3. Rhythm ì „í™˜
        self.analyze_rhythm_transitions()
        
        # 4. í‚¤ì›Œë“œ ì œì•ˆ
        self.suggest_emotion_keywords()
        
        # 5. Priority ë¶„í¬
        self.analyze_priority_distribution()
        
        # ìš”ì•½
        print("\n" + "=" * 70)
        print("ë¶„ì„ ìš”ì•½ ë° ê¶Œì¥ì‚¬í•­")
        print("=" * 70)
        print("""
        âœ… ë°œê²¬ ì‚¬í•­:
        1. ê°ì • ì¸ì‹ë¥ ì´ ë§¤ìš° ë‚®ìŒ (0.1%) - í•œê¸€ í‚¤ì›Œë“œ ë¶€ì¡±
        2. ëŒ€ë¶€ë¶„ 'exploration' phase (93.2%) - ëŒ€í™”í˜• ì§ˆë¬¸ íŠ¹ì„±
        3. PriorityëŠ” ëŒ€ë¶€ë¶„ 1 (ê¸°ë³¸ê°’) - ê¸´ê¸‰ë„ í‚¤ì›Œë“œ ë¶€ì¡±
        
        ğŸ¯ ê°œì„  ë°©ì•ˆ:
        1. í•œê¸€ ê°ì • í‚¤ì›Œë“œ ëŒ€í­ í™•ì¥ (ì œì•ˆëœ í‚¤ì›Œë“œ ì ìš©)
        2. 'curiosity', 'gratitude' ë“± ìƒˆ ê°ì • ì¹´í…Œê³ ë¦¬ ì¶”ê°€
        3. Priority í‚¤ì›Œë“œ í•œê¸€í™” ('í™•ì¸' â†’ 'ê²€í† ', 'ê¸´ê¸‰' ë“±)
        4. Rhythm phase íŒë‹¨ ë¡œì§ ê°œì„  (ì§ˆë¬¸ ìœ í˜• ê³ ë ¤)
        
        ğŸ“Š ë‹¤ìŒ ë‹¨ê³„:
        1. bqi_adapter.pyì˜ _EMOTION_KEYWORDS ì—…ë°ì´íŠ¸
        2. _infer_priority()ì— í•œê¸€ í‚¤ì›Œë“œ ì¶”ê°€
        3. ì—…ë°ì´íŠ¸ í›„ ì¬ë¶„ì„ìœ¼ë¡œ ê°œì„  íš¨ê³¼ ê²€ì¦
        """)


if __name__ == "__main__":
    try:
        analyzer = BQIDataAnalyzer()
        analyzer.generate_report()
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
