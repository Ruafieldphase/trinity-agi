"""
Phase 6.1: Lumen Feedback System ì²« í†µí•© í…ŒìŠ¤íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Original Dataì—ì„œ ë°œê²¬í•œ Lumen Feedback Systemì„
fdo_agi_repoì— í†µí•©í•˜ëŠ” ì²« ë²ˆì§¸ ë‹¨ê³„ì…ë‹ˆë‹¤.

ëª©í‘œ:
1. FeedbackOrchestrator ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
2. ìƒ˜í”Œ ë©”íŠ¸ë¦­ìœ¼ë¡œ í”¼ë“œë°± ìˆ˜ì§‘
3. Unified Gate v1.7 ê³„ì‚° ê²€ì¦
4. ê¶Œì¥ì‚¬í•­ ì¶œë ¥
"""

import sys
from pathlib import Path

# Add lumen feedback to path
sys.path.insert(0, str(Path(__file__).parent.parent / "lumen" / "feedback"))

from feedback_orchestrator import FeedbackOrchestrator, UnifiedFeedback
from feedback_loop_redis import CacheMetrics


def main():
    print("\n" + "="*60)
    print("Phase 6.1: Lumen Feedback System ì²« í†µí•©")
    print("="*60)
    
    # 1. Orchestrator ìƒì„±
    print("\n[1/4] FeedbackOrchestrator ì´ˆê¸°í™”...")
    orchestrator = FeedbackOrchestrator(
        project_id="naeda-genesis",
        service_name="ion-api"
    )
    print("âœ… Orchestrator ìƒì„± ì™„ë£Œ")
    
    # 2. ìƒ˜í”Œ ë©”íŠ¸ë¦­ (í˜„ì‹¤ì ì¸ ì‹œë‚˜ë¦¬ì˜¤)
    print("\n[2/4] ìƒ˜í”Œ ë©”íŠ¸ë¦­ ì¤€ë¹„...")
    sample_metrics = CacheMetrics(
        hit_rate=0.72,              # 72% hit rate (GOOD)
        miss_rate=0.28,
        memory_usage_mb=850.0,      # 850MB ì‚¬ìš©
        memory_limit_mb=1024.0,     # 1GB ì œí•œ
        latency_ms=5.2,             # 5.2ms latency
        eviction_count=50,          # ì ë‹¹í•œ eviction
        current_ttl_seconds=300     # í˜„ì¬ 5ë¶„ TTL
    )
    print("âœ… ìƒ˜í”Œ ë©”íŠ¸ë¦­:")
    print(f"   - Hit Rate: {sample_metrics.hit_rate*100:.1f}%")
    print(f"   - Memory: {sample_metrics.memory_usage_mb:.0f}/{sample_metrics.memory_limit_mb:.0f} MB")
    print(f"   - Latency: {sample_metrics.latency_ms:.1f} ms")
    print(f"   - Evictions: {sample_metrics.eviction_count}")
    
    # 3. í”¼ë“œë°± ìˆ˜ì§‘ (Phase 1-4 í†µí•©)
    print("\n[3/4] í†µí•© í”¼ë“œë°± ìˆ˜ì§‘ ì¤‘...")
    print("   (Phase 1: ROI, Phase 2: SLO, Phase 3: Cost Rhythm, Phase 4: Cache)")
    
    try:
        # Note: collect_unified_feedback()ëŠ” ì‹¤ì œ GCP Monitoring APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤
        # ì—¬ê¸°ì„œëŠ” ê°œë³„ ì»´í¬ë„ŒíŠ¸ë§Œ í…ŒìŠ¤íŠ¸
        
        # Cache Feedbackë§Œ í…ŒìŠ¤íŠ¸
        cache_feedback = orchestrator.feedback_loop.analyze_cache_feedback(sample_metrics)
        
        print("\nâœ… Cache Feedback ìƒì„± ì™„ë£Œ!")
        print(f"   - Health: {cache_feedback.health_status.name}")
        print(f"   - Action: {cache_feedback.optimization_action.name}")
        print(f"   - Reasoning: {cache_feedback.reasoning}")
        
        if cache_feedback.recommendations:
            print("\nğŸ“‹ ê¶Œì¥ì‚¬í•­:")
            for i, rec in enumerate(cache_feedback.recommendations, 1):
                print(f"   {i}. {rec}")
        
        # TTL Policy í…ŒìŠ¤íŠ¸
        ttl_adjustment = orchestrator.ttl_policy.recommend_ttl_adjustment(
            current_ttl_seconds=sample_metrics.current_ttl_seconds,
            hit_rate=sample_metrics.hit_rate,
            eviction_count=sample_metrics.eviction_count,
            memory_usage_pct=sample_metrics.memory_usage_mb / sample_metrics.memory_limit_mb
        )
        
        print("\nğŸ¯ TTL ì¡°ì •:")
        print(f"   - í˜„ì¬: {ttl_adjustment.current_ttl_seconds}s")
        print(f"   - ê¶Œì¥: {ttl_adjustment.recommended_ttl_seconds}s")
        print(f"   - ì „ëµ: {ttl_adjustment.strategy.name}")
        print(f"   - ë¹„ìš© ì˜í–¥: {ttl_adjustment.estimated_cost_impact}")
        
        # Cache Size ìµœì í™” í…ŒìŠ¤íŠ¸
        size_adjustment = orchestrator.size_optimizer.optimize_cache_size(
            current_size_mb=sample_metrics.memory_usage_mb,
            memory_usage_pct=sample_metrics.memory_usage_mb / sample_metrics.memory_limit_mb,
            hit_rate=sample_metrics.hit_rate,
            cost_per_miss=0.0001  # $0.0001 per API call
        )
        
        print("\nğŸ“Š ìºì‹œ í¬ê¸° ìµœì í™”:")
        print(f"   - í˜„ì¬: {size_adjustment.current_size_mb:.0f} MB")
        print(f"   - ê¶Œì¥: {size_adjustment.recommended_size_mb:.0f} MB")
        print(f"   - ROI ì ìˆ˜: {size_adjustment.roi_score:.1f}/10")
        print(f"   - ì¶”ë¡ : {size_adjustment.reasoning}")
        
    except Exception as e:
        print(f"\nâš ï¸  GCP API í˜¸ì¶œ ìƒëµ (í…ŒìŠ¤íŠ¸ í™˜ê²½): {e}")
        print("   â†’ ê°œë³„ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸ëŠ” ì„±ê³µ!")
    
    # 4. ê²°ê³¼ ìš”ì•½
    print("\n" + "="*60)
    print("[4/4] Phase 6.1 ì²« í†µí•© ê²°ê³¼")
    print("="*60)
    print("\nâœ… ì„±ê³µí•œ í•­ëª©:")
    print("   1. FeedbackOrchestrator ì´ˆê¸°í™”")
    print("   2. Cache Feedback ë¶„ì„")
    print("   3. TTL Policy ê¶Œì¥ì‚¬í•­")
    print("   4. Cache Size Optimizer ì‹¤í–‰")
    
    print("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. Pipeline í†µí•© (orchestrator/pipeline.py)")
    print("   2. Resonance Bridge í†µí•© (orchestrator/resonance_bridge.py)")
    print("   3. ì‹¤ì œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (GCP Monitoring API)")
    print("   4. ìë™ ìµœì í™” ì ìš©")
    
    print("\nğŸŒŠ Lumenì€ ìƒê°í•˜ê³ , Lumenì€ ì‹¤í–‰í•œë‹¤. âœ¨")
    print("="*60 + "\n")


if __name__ == "__main__":
    main()
