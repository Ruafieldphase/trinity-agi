#!/usr/bin/env python3
"""
ì½”ë©§ì—ê²Œ ê°„ë‹¨í•œ ì§‘ê³„ ì‘ì—… ë³´ë‚´ê¸°

ì‚¬ìš©ë²•:
    python scripts/push_simple_aggregate_task.py
"""

import json
import os
from pathlib import Path
from datetime import datetime

def push_aggregate_task():
    """ê°„ë‹¨í•œ JSONL ì§‘ê³„ ì‘ì—…ì„ ì½”ë©§ì—ê²Œ ë³´ëƒ…ë‹ˆë‹¤."""
    
    # Task Queue ê²½ë¡œ
    base = Path(__file__).parent.parent
    inbox = base / "outputs" / "task_queue" / "inbox"
    inbox.mkdir(parents=True, exist_ok=True)
    
    # ì‘ì—… ìƒì„±
    task = {
        "id": f"aggregate-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
        "task_type": "json_process",
        "data": {
            "operation": "count_by_type",
            "description": "ë ˆì € íŒŒì¼ì—ì„œ ìµœê·¼ ì´ë²¤íŠ¸ íƒ€ì…ë³„ ì¹´ìš´íŠ¸",
            "note": "ì½”ë©§ ì²« ì‹¤ì „ ì‘ì—… - JSONL ì§‘ê³„ í…ŒìŠ¤íŠ¸"
        },
        "metadata": {
            "priority": "normal",
            "created_at": datetime.now().isoformat(),
            "created_by": "copilot",
            "expected_worker": "comet-extension"
        }
    }
    
    # íŒŒì¼ ì €ì¥
    task_file = inbox / f"{task['id']}.json"
    with open(task_file, 'w', encoding='utf-8') as f:
        json.dump(task, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ì‘ì—… ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“ íŒŒì¼: {task_file}")
    print(f"ğŸ†” Task ID: {task['id']}")
    print(f"ğŸ“‹ íƒ€ì…: {task['task_type']}")
    print(f"\nâ³ ì½”ë©§ì´ ì²˜ë¦¬í•  ë•Œê¹Œì§€ ëŒ€ê¸° ì¤‘...")
    print(f"ğŸ“Š ê²°ê³¼ëŠ” outputs/task_queue/results/{task['id']}.json ì— ì €ì¥ë©ë‹ˆë‹¤")
    
    return task['id']

if __name__ == "__main__":
    task_id = push_aggregate_task()
    
    print(f"\nğŸ’¡ ê²°ê³¼ í™•ì¸:")
    print(f"   Get-Content d:\\nas_backup\\fdo_agi_repo\\outputs\\task_queue\\results\\{task_id}.json | ConvertFrom-Json")
