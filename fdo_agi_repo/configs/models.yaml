fallback:
  order:
  - openai:gpt-4o
  - anthropic:opus
  - local_vllm:llama-70b
personas:
  antithesis:
    max_tokens: 800
    model: gpt-4o
    provider: openai
    tools:
    - rag
    - web
  synthesis:
    max_tokens: 900
    model: claude-3-opus
    provider: anthropic
    tools:
    - rag
    - fileio
    - codeexec
  thesis:
    max_tokens: 1024
    model: llama-3.1-70b-instruct-q5
    provider: local_vllm
    tools:
    - rag
    - web
    - fileio
