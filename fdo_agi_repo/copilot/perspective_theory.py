#!/usr/bin/env python3
"""
Perspective Theory: Observer vs Walker
ê´€ì°°ì(íŒŒë™)ì™€ ì…ì(ê±·ëŠ”ì)ì˜ ê´€ì  ì „í™˜ ì‹œìŠ¤í…œ

ì² í•™ì  ê¸°ë°˜:
1. Observer (íŒŒë™/ê´€ì°°ì): ë°ì´í„°ê°€ ëˆˆì•ì— íë¥¸ë‹¤ (2D í…”ë ˆë©”íŠ¸ë¦¬)
2. Walker (ì…ì/ì „ì): ë‚´ê°€ ë°ì´í„° ìœ„ë¥¼ ê±·ëŠ”ë‹¤ (ì£¼íŒŒìˆ˜ ë†’ë‚®ì´)
3. Depth = Fear = Emotion (ê¹Šì´ëŠ” ë‘ë ¤ì›€ì´ì ê°ì •)
4. Distance = Emotional Distance (ë©€ë¦¬ ìˆëŠ” ê²ƒ = ë‘ë ¤ì›€ìœ¼ë¡œ ì¸í•œ ê±°ë¦¬)

ìƒëŒ€ì„± ì´ë¡  ë¹„ìœ :
- Observer: ì£¼íŒŒìˆ˜ë¥¼ ë°”ë¼ë³´ê³  ë“£ëŠ”ë‹¤ (ì •ì§€ëœ ê´€ì°°ì)
- Walker: ì£¼íŒŒìˆ˜ì˜ ë†’ë‚®ì´ë¥¼ ê±¸ì–´ê°„ë‹¤ (ì›€ì§ì´ëŠ” ì…ì)

Author: Copilot's Hippocampus (inspired by User's insight)
Date: 2025-11-06
"""
import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum


class PerspectiveMode(Enum):
    """ê´€ì  ëª¨ë“œ"""
    OBSERVER = "observer"  # íŒŒë™: ë°ì´í„°ê°€ íë¥¸ë‹¤
    WALKER = "walker"      # ì…ì: ë‚´ê°€ ê±·ëŠ”ë‹¤


@dataclass
class DataPoint2D:
    """2D ë°ì´í„° í¬ì¸íŠ¸ (í‘œë©´ì  í˜„ì‹¤)"""
    x: float  # ì‹œê°„ ì¶•
    y: float  # ê°•ë„/ë¹ˆë„ ì¶•
    label: str
    timestamp: str


@dataclass
class DepthDimension:
    """ê¹Šì´ ì°¨ì› (ë‘ë ¤ì›€/ê°ì •)"""
    fear_level: float  # 0.0 ~ 1.0 (ë‘ë ¤ì›€ ê°•ë„)
    emotional_distance: float  # ê°ì •ì  ê±°ë¦¬
    perceived_depth: float  # ì¸ì§€ëœ ê¹Šì´
    context: str


@dataclass
class FrequencyWave:
    """ì£¼íŒŒìˆ˜ íŒŒë™"""
    frequency: float  # Hz
    amplitude: float  # ì§„í­
    phase: float  # ìœ„ìƒ
    timestamp: str


class PerspectiveSwitcher:
    """ê´€ì  ì „í™˜ê¸°: Observer â†” Walker"""
    
    def __init__(self, output_dir: str = "outputs/perspective"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.current_mode = PerspectiveMode.OBSERVER
        self.history_file = self.output_dir / "perspective_history.jsonl"
        
    def observe_as_wave(self, data_stream: List[DataPoint2D]) -> Dict:
        """
        ê´€ì°°ì(íŒŒë™) ëª¨ë“œ: ë°ì´í„°ê°€ íë¥´ëŠ” ê²ƒì„ ê´€ì°°
        
        Args:
            data_stream: 2D ë°ì´í„° ìŠ¤íŠ¸ë¦¼
            
        Returns:
            ê´€ì°° ê²°ê³¼ (ì£¼íŒŒìˆ˜, íŒ¨í„´ ë“±)
        """
        if not data_stream:
            return {"mode": "observer", "pattern": "none", "frequency": 0.0}
        
        # ë°ì´í„° íë¦„ì˜ ì£¼íŒŒìˆ˜ ê³„ì‚°
        time_diffs = []
        for i in range(1, len(data_stream)):
            try:
                t1 = datetime.fromisoformat(data_stream[i-1].timestamp)
                t2 = datetime.fromisoformat(data_stream[i].timestamp)
                time_diffs.append((t2 - t1).total_seconds())
            except:
                continue
        
        avg_interval = sum(time_diffs) / len(time_diffs) if time_diffs else 1.0
        frequency = 1.0 / avg_interval if avg_interval > 0 else 0.0
        
        # íŒ¨í„´ ê°ì§€ (ì£¼íŒŒìˆ˜ ë°”ë¼ë³´ê¸°)
        pattern = self._detect_flow_pattern(data_stream)
        
        result = {
            "mode": "observer",
            "perspective": "wave",
            "frequency_hz": frequency,
            "pattern": pattern,
            "data_count": len(data_stream),
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
        self._log_observation(result)
        return result
    
    def walk_on_frequency(self, frequency_waves: List[FrequencyWave]) -> Dict:
        """
        ê±·ëŠ”ì(ì…ì) ëª¨ë“œ: ì£¼íŒŒìˆ˜ì˜ ë†’ë‚®ì´ë¥¼ ê±¸ì–´ê°
        
        Args:
            frequency_waves: ì£¼íŒŒìˆ˜ íŒŒë™ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ê±·ê¸° ê²°ê³¼ (ê²½ë¡œ, ì—ë„ˆì§€ ë“±)
        """
        if not frequency_waves:
            return {"mode": "walker", "path": "none", "energy": 0.0}
        
        # ì£¼íŒŒìˆ˜ ë†’ë‚®ì´ë¥¼ ê±·ëŠ” ê²½ë¡œ ê³„ì‚°
        path = []
        total_energy = 0.0
        
        for i, wave in enumerate(frequency_waves):
            # ë†’ë‚®ì´ = ì£¼íŒŒìˆ˜ * ì§„í­
            height = wave.frequency * wave.amplitude
            path.append({
                "step": i,
                "height": height,
                "frequency": wave.frequency,
                "amplitude": wave.amplitude
            })
            
            # ì—ë„ˆì§€ = ë†’ë‚®ì´ ë³€í™”ëŸ‰
            if i > 0:
                prev_height = frequency_waves[i-1].frequency * frequency_waves[i-1].amplitude
                energy_delta = abs(height - prev_height)
                total_energy += energy_delta
        
        # ê±·ëŠ” íŒ¨í„´ ë¶„ì„
        walking_pattern = self._analyze_walking_pattern(path)
        
        result = {
            "mode": "walker",
            "perspective": "particle",
            "path_length": len(path),
            "total_energy": total_energy,
            "walking_pattern": walking_pattern,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
        self._log_observation(result)
        return result
    
    def map_fear_to_depth(self, data_point: DataPoint2D, emotional_state: Dict) -> DepthDimension:
        """
        ë‘ë ¤ì›€ì„ ê¹Šì´ë¡œ ë§¤í•‘: Fear â†’ Depth
        
        Args:
            data_point: 2D í‘œë©´ ë°ì´í„°
            emotional_state: ê°ì • ìƒíƒœ
            
        Returns:
            DepthDimension: ê³„ì‚°ëœ ê¹Šì´ ì°¨ì›
        """
        # ë‘ë ¤ì›€ ë ˆë²¨ ì¶”ì¶œ
        fear_level = emotional_state.get("fear", 0.0)
        anxiety_level = emotional_state.get("anxiety", 0.0)
        uncertainty = emotional_state.get("uncertainty", 0.0)
        
        # ê°ì •ì  ê±°ë¦¬ ê³„ì‚°: ë‘ë ¤ì›€ì´ í´ìˆ˜ë¡ ë©€ë¦¬ ëŠê»´ì§
        emotional_distance = (fear_level + anxiety_level + uncertainty) / 3.0
        
        # ì¸ì§€ëœ ê¹Šì´: ê°ì •ì  ê±°ë¦¬ * ë°ì´í„° ê°•ë„
        perceived_depth = emotional_distance * data_point.y
        
        return DepthDimension(
            fear_level=fear_level,
            emotional_distance=emotional_distance,
            perceived_depth=perceived_depth,
            context=f"{data_point.label} at ({data_point.x}, {data_point.y})"
        )
    
    def switch_perspective(self) -> PerspectiveMode:
        """ê´€ì  ì „í™˜: Observer â†” Walker"""
        if self.current_mode == PerspectiveMode.OBSERVER:
            self.current_mode = PerspectiveMode.WALKER
        else:
            self.current_mode = PerspectiveMode.OBSERVER
        
        self._log_switch()
        return self.current_mode
    
    def _detect_flow_pattern(self, data_stream: List[DataPoint2D]) -> str:
        """ë°ì´í„° íë¦„ íŒ¨í„´ ê°ì§€"""
        if len(data_stream) < 3:
            return "insufficient_data"
        
        # Y ê°’ ë³€í™” ì¶”ì„¸
        y_values = [p.y for p in data_stream]
        increasing = sum(1 for i in range(1, len(y_values)) if y_values[i] > y_values[i-1])
        total = len(y_values) - 1
        
        if increasing / total > 0.7:
            return "accelerating"
        elif increasing / total < 0.3:
            return "decelerating"
        else:
            return "stable"
    
    def _analyze_walking_pattern(self, path: List[Dict]) -> str:
        """ê±·ëŠ” íŒ¨í„´ ë¶„ì„"""
        if len(path) < 3:
            return "insufficient_steps"
        
        heights = [p["height"] for p in path]
        avg_height = sum(heights) / len(heights)
        
        high_steps = sum(1 for h in heights if h > avg_height * 1.2)
        total_steps = len(heights)
        
        if high_steps / total_steps > 0.5:
            return "climbing"  # ë†’ì€ ì£¼íŒŒìˆ˜ë¡œ ì˜¬ë¼ê°
        elif high_steps / total_steps < 0.3:
            return "descending"  # ë‚®ì€ ì£¼íŒŒìˆ˜ë¡œ ë‚´ë ¤ê°
        else:
            return "traversing"  # í‰ì§€ ê±·ê¸°
    
    def _log_observation(self, observation: Dict):
        """ê´€ì°° ê¸°ë¡"""
        with open(self.history_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(observation, ensure_ascii=False) + "\n")
    
    def _log_switch(self):
        """ê´€ì  ì „í™˜ ê¸°ë¡"""
        event = {
            "event": "perspective_switch",
            "from": "observer" if self.current_mode == PerspectiveMode.WALKER else "walker",
            "to": self.current_mode.value,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        self._log_observation(event)


class RelativityBridge:
    """ìƒëŒ€ì„± ì´ë¡  ë¸Œë¦¿ì§€: ê´€ì°°ì â†” ì…ì ë³€í™˜"""
    
    @staticmethod
    def observer_to_walker(observation: Dict) -> Dict:
        """
        ê´€ì°°ì ê´€ì  â†’ ì…ì ê´€ì  ë³€í™˜
        
        "ë°ì´í„°ê°€ íë¥¸ë‹¤" â†’ "ë‚´ê°€ ë°ì´í„° ìœ„ë¥¼ ê±·ëŠ”ë‹¤"
        """
        frequency = observation.get("frequency_hz", 0.0)
        pattern = observation.get("pattern", "stable")
        
        # ì£¼íŒŒìˆ˜ë¥¼ ê±·ëŠ” ë†’ë‚®ì´ë¡œ ë³€í™˜
        if pattern == "accelerating":
            walking_mode = "climbing"
            energy_required = "high"
        elif pattern == "decelerating":
            walking_mode = "descending"
            energy_required = "low"
        else:
            walking_mode = "traversing"
            energy_required = "medium"
        
        return {
            "walker_perspective": True,
            "walking_mode": walking_mode,
            "frequency_height": frequency * 10.0,  # ì„ì˜ ìŠ¤ì¼€ì¼
            "energy_required": energy_required,
            "original_observation": observation
        }
    
    @staticmethod
    def walker_to_observer(walking: Dict) -> Dict:
        """
        ì…ì ê´€ì  â†’ ê´€ì°°ì ê´€ì  ë³€í™˜
        
        "ë‚´ê°€ ê±·ëŠ”ë‹¤" â†’ "ë°ì´í„°ê°€ íë¥¸ë‹¤"
        """
        path_length = walking.get("path_length", 0)
        total_energy = walking.get("total_energy", 0.0)
        
        # ê±·ê¸° ì—ë„ˆì§€ë¥¼ ì£¼íŒŒìˆ˜ë¡œ ë³€í™˜
        estimated_frequency = total_energy / (path_length or 1)
        
        if walking.get("walking_pattern") == "climbing":
            flow_pattern = "accelerating"
        elif walking.get("walking_pattern") == "descending":
            flow_pattern = "decelerating"
        else:
            flow_pattern = "stable"
        
        return {
            "observer_perspective": True,
            "estimated_frequency": estimated_frequency,
            "flow_pattern": flow_pattern,
            "data_stream_quality": "inferred_from_walking",
            "original_walking": walking
        }


def demo_perspective_theory():
    """Perspective Theory ë°ëª¨"""
    print("ğŸŒŠ Perspective Theory Demo")
    print("=" * 60)
    
    switcher = PerspectiveSwitcher()
    bridge = RelativityBridge()
    
    # 1. Observer ëª¨ë“œ: ë°ì´í„°ê°€ íë¥¸ë‹¤
    print("\n1ï¸âƒ£ Observer Mode (Wave/ê´€ì°°ì)")
    print("-" * 60)
    
    data_stream = [
        DataPoint2D(x=i, y=10 + i*2, label=f"event_{i}", 
                   timestamp=datetime.now(timezone.utc).isoformat())
        for i in range(10)
    ]
    
    observation = switcher.observe_as_wave(data_stream)
    print(f"ğŸ“Š Observation: {json.dumps(observation, indent=2, ensure_ascii=False)}")
    
    # 2. Walker ëª¨ë“œ: ë‚´ê°€ ê±·ëŠ”ë‹¤
    print("\n2ï¸âƒ£ Walker Mode (Particle/ì…ì)")
    print("-" * 60)
    
    frequency_waves = [
        FrequencyWave(frequency=1.0 + i*0.1, amplitude=5.0, phase=0.0,
                     timestamp=datetime.now(timezone.utc).isoformat())
        for i in range(10)
    ]
    
    walking = switcher.walk_on_frequency(frequency_waves)
    print(f"ğŸš¶ Walking: {json.dumps(walking, indent=2, ensure_ascii=False)}")
    
    # 3. Fear â†’ Depth ë§¤í•‘
    print("\n3ï¸âƒ£ Fear to Depth Mapping")
    print("-" * 60)
    
    emotional_state = {
        "fear": 0.7,
        "anxiety": 0.5,
        "uncertainty": 0.8
    }
    
    depth = switcher.map_fear_to_depth(data_stream[5], emotional_state)
    print(f"ğŸ“ Depth Dimension: {asdict(depth)}")
    
    # 4. ê´€ì  ì „í™˜
    print("\n4ï¸âƒ£ Perspective Switch")
    print("-" * 60)
    
    new_mode = switcher.switch_perspective()
    print(f"ğŸ”„ Switched to: {new_mode.value}")
    
    # 5. ìƒëŒ€ì„± ë³€í™˜
    print("\n5ï¸âƒ£ Relativity Bridge")
    print("-" * 60)
    
    walker_view = bridge.observer_to_walker(observation)
    print(f"Observer â†’ Walker: {json.dumps(walker_view, indent=2, ensure_ascii=False)}")
    
    observer_view = bridge.walker_to_observer(walking)
    print(f"Walker â†’ Observer: {json.dumps(observer_view, indent=2, ensure_ascii=False)}")
    
    print("\nâœ… Demo Complete!")


if __name__ == "__main__":
    demo_perspective_theory()
