#!/usr/bin/env python3
"""
Flow Observer Integration: Desktop í™œë™ê³¼ Flow Theory í†µí•©
ì‚¬ìš©ìì˜ ì‹¤ì œ í™œë™ì„ ê´€ì°°í•˜ê³  íë¦„ ìƒíƒœë¥¼ ê°ì§€í•©ë‹ˆë‹¤.

íë¦„ ìƒíƒœ ê°ì§€:
1. ì§‘ì¤‘ ìƒíƒœ (Flow): í•œ í”„ë¡œì„¸ìŠ¤/íŒŒì¼ì— ì¥ì‹œê°„ ëª°ì…
2. ì „í™˜ ìƒíƒœ (Transition): ë¹ ë¥¸ ì „í™˜, íƒìƒ‰ ì¤‘
3. ì •ì²´ ìƒíƒœ (Stagnation): í™œë™ ì—†ìŒ, ë§‰í˜

+ Perspective Theory í†µí•©:
- Observer Mode: ë°ì´í„° íë¦„ì„ ê´€ì°° (íŒŒë™ ê´€ì )
- Walker Mode: ë°ì´í„° ìœ„ë¥¼ ê±·ê¸° (ì…ì ê´€ì )
- Fear to Depth: ë‘ë ¤ì›€ ê°ì§€ ë° ê¹Šì´ ë§¤í•‘
- Auto Perspective Switch: ë§‰íˆë©´ ìë™ ê´€ì  ì „í™˜

Author: Copilot's Hippocampus
Date: 2025-11-06
Updated: 2025-11-06 (Perspective Theory Integration)
"""
import json
import os
import sys
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from collections import Counter

# Perspective Theory import
sys.path.insert(0, str(Path(__file__).parent.parent))
try:
    from copilot.perspective_theory import PerspectiveSwitcher
    PERSPECTIVE_AVAILABLE = True
except ImportError:
    PERSPECTIVE_AVAILABLE = False
    print("âš ï¸ Perspective Theory not available. Running without perspective switching.")

# Social Fear Analyzer import
try:
    from copilot.social_fear_information_theory import SocialFearAnalyzer
    SOCIAL_FEAR_AVAILABLE = True
except ImportError:
    SOCIAL_FEAR_AVAILABLE = False
    print("âš ï¸ Social Fear Analyzer not available. Running without social context.")


@dataclass
class FlowState:
    """í˜„ì¬ íë¦„ ìƒíƒœ"""
    state: str  # 'flow', 'transition', 'stagnation', 'fixation', 'unknown', 'observer_mode', 'walker_mode'
    confidence: float  # 0.0 ~ 1.0
    context: Dict  # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
    timestamp: str
    perspective: Optional[str] = None  # 'observer', 'walker', None
    fear_level: Optional[float] = None  # 0.0 ~ 1.0 (ë‘ë ¤ì›€ â†’ ê¹Šì´)
    loop_type: Optional[str] = None  # 'open', 'closed' (ì—´ë¦° ë£¨í”„ vs ë‹«íŒ ë£¨í”„)
    social_context: Optional[Dict] = None  # ì‚¬íšŒì  ë§¥ë½ (ë¹„êµ, íˆ¬ì˜, ë¶„ë…¸)


class FlowObserver:
    """Desktop í™œë™ì„ ê´€ì°°í•˜ê³  íë¦„ ìƒíƒœë¥¼ ê°ì§€"""
    
    def __init__(self, telemetry_dir: str = "outputs/telemetry"):
        self.telemetry_dir = Path(telemetry_dir)
        self.flow_threshold_minutes = 15  # 15ë¶„ ì´ìƒ ì§‘ì¤‘í•˜ë©´ flow
        self.transition_window_minutes = 5  # 5ë¶„ ë‚´ ë¹ ë¥¸ ì „í™˜
        self.stagnation_threshold_minutes = 30  # 30ë¶„ ì´ìƒ í™œë™ ì—†ìœ¼ë©´ ì •ì²´
        
        # Perspective Theory í†µí•©
        self.perspective_switcher = None
        if PERSPECTIVE_AVAILABLE:
            self.perspective_switcher = PerspectiveSwitcher()
            print("âœ… Perspective Theory enabled")
        
        # Social Fear Analyzer í†µí•©
        self.social_fear_analyzer = None
        if SOCIAL_FEAR_AVAILABLE:
            self.social_fear_analyzer = SocialFearAnalyzer()
            print("âœ… Social Fear Analyzer enabled")
        
        self.current_perspective = None  # 'observer' or 'walker'
        self.perspective_switch_count = 0
        self.last_perspective_switch = None
        
    def analyze_recent_activity(self, hours: int = 1) -> FlowState:
        """
        ìµœê·¼ í™œë™ì„ ë¶„ì„í•˜ì—¬ í˜„ì¬ íë¦„ ìƒíƒœë¥¼ íŒë‹¨
        
        Args:
            hours: ë¶„ì„í•  ì‹œê°„ ë²”ìœ„ (ê¸°ë³¸ 1ì‹œê°„)
            
        Returns:
            FlowState: í˜„ì¬ íë¦„ ìƒíƒœ
        """
        end_time = datetime.now(timezone.utc)
        start_time = end_time - timedelta(hours=hours)
        
        records = self._load_telemetry_records(start_time, end_time)
        
        if not records:
            return FlowState(
                state='unknown',
                confidence=0.0,
                context={'reason': 'no_telemetry_data'},
                timestamp=end_time.isoformat()
            )
        
        # ìµœê·¼ í™œë™ ì‹œê°„ ì²´í¬
        last_activity = datetime.fromisoformat(
            records[-1]['ts_utc'].replace('Z', '+00:00')
        )
        minutes_since_activity = (end_time - last_activity).total_seconds() / 60
        
        # ì •ì²´ ìƒíƒœ ì²´í¬ â†’ Perspective Switch ì œì•ˆ
        if minutes_since_activity > self.stagnation_threshold_minutes:
            # ë‘ë ¤ì›€ ë ˆë²¨ ê³„ì‚° (ì •ì²´ ì‹œê°„ì— ë¹„ë¡€)
            fear_level = min(minutes_since_activity / 60.0, 1.0)  # 1ì‹œê°„ = max fear
            
            # Perspective ì „í™˜ ì œì•ˆ
            if self.perspective_switcher and fear_level > 0.5:
                # ì •ì²´ â†’ ê´€ì  ì „í™˜ í•„ìš”
                suggested_perspective = self._suggest_perspective_switch('stagnation')
                
                return FlowState(
                    state='stagnation',
                    confidence=0.9,
                    context={
                        'minutes_idle': minutes_since_activity,
                        'last_activity': records[-1],
                        'fear_detected': True,
                        'suggested_action': f'Switch to {suggested_perspective} mode',
                        'explanation': self._get_perspective_explanation(suggested_perspective)
                    },
                    timestamp=end_time.isoformat(),
                    perspective=suggested_perspective,
                    fear_level=fear_level
                )
            
            return FlowState(
                state='stagnation',
                confidence=0.9,
                context={
                    'minutes_idle': minutes_since_activity,
                    'last_activity': records[-1]
                },
                timestamp=end_time.isoformat(),
                fear_level=fear_level
            )
        
        # í™œë™ íŒ¨í„´ ë¶„ì„
        process_durations = self._analyze_process_durations(records)
        window_switches = self._count_window_switches(records)
        focus_score = self._calculate_focus_score(process_durations, window_switches)
        
        # ğŸ§  ì‚¬íšŒì  ë§¥ë½ ë¶„ì„
        social_context = self._analyze_social_context(records, focus_score, window_switches)
        
        # ğŸ” ì§‘ì°©(Fixation) ê°ì§€
        is_fixation, fixation_fear, loop_type = self._detect_fixation(records, focus_score)
        
        # Perspective ëª¨ë“œ ê²°ì •
        if self.perspective_switcher:
            perspective_mode = self._determine_perspective_mode(
                focus_score, window_switches, len(process_durations)
            )
        else:
            perspective_mode = None
        
        # ì§‘ì°© ê°ì§€ ì‹œ ìë™ ê´€ì  ì „í™˜
        if is_fixation:
            suggested_perspective = 'observer'  # ì§‘ì°© â†’ Observerë¡œ ì „í™˜ (ë°”ë¼ë³´ê¸°)
            
            return FlowState(
                state='fixation',
                confidence=0.8,
                context={
                    'warning': 'âš ï¸ ì§‘ì°© íŒ¨í„´ ê°ì§€: ë‹«íŒ ë£¨í”„ë¡œ ìˆ˜ë ´ ì¤‘',
                    'explanation': (
                        'ì§‘ì¤‘ê³¼ ì§‘ì°©ì€ í•œ ë ì°¨ì´ì…ë‹ˆë‹¤.\n'
                        '- ì§‘ì¤‘(Focus): ì—´ë¦° ë£¨í”„, ì§„ì „ ìˆìŒ, ê´€ì°°ì ê´€ì \n'
                        '- ì§‘ì°©(Fixation): ë‹«íŒ ë£¨í”„, ë°˜ë³µë§Œ, í•œ ì  ìˆ˜ë ´\n'
                        '\nğŸ’¡ í•´ê²° ë°©ë²•:\n'
                        '1. ì •ë³´ì´ë¡  ê¸°ë°˜ ë…¸ì´ì¦ˆ ì œê±° ìŒì•… ë“£ê¸°\n'
                        '2. ì§§ì€ ì‚°ì±… (5-10ë¶„)\n'
                        '3. Observer ëª¨ë“œë¡œ ì „í™˜ (ë°”ë¼ë³´ê¸°)'
                    ),
                    'suggested_action': f'Switch to {suggested_perspective} mode',
                    'loop_type': loop_type,
                    'fear_level': fixation_fear
                },
                timestamp=end_time.isoformat(),
                perspective=suggested_perspective,
                fear_level=fixation_fear,
                loop_type=loop_type
            )
    
    def _analyze_social_context(
        self, 
        records: List[Dict],
        focus_score: float,
        window_switches: int
    ) -> Optional[Dict]:
        """
        ì‚¬íšŒì  ë§¥ë½ ë¶„ì„: ë¹„êµ íŒ¨í„´, ë‘ë ¤ì›€, íˆ¬ì˜
        
        Args:
            records: í…”ë ˆë©”íŠ¸ë¦¬ ê¸°ë¡
            focus_score: ì§‘ì¤‘ë„ ì ìˆ˜
            window_switches: ìœˆë„ìš° ì „í™˜ íšŸìˆ˜
            
        Returns:
            ì‚¬íšŒì  ë§¥ë½ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        if not self.social_fear_analyzer:
            return None
        
        # í™œë™ íŒ¨í„´ì—ì„œ ë¹„êµ ì´ë²¤íŠ¸ ì¶”ì •
        # ë¹ ë¥¸ ì „í™˜ = SNS/ë‰´ìŠ¤ = ë¹„êµ ì¦ê°€
        comparison_events = window_switches  # ê°„ì†Œí™”ëœ ì¶”ì •
        
        # ì§‘ì¤‘ë„ê°€ ë‚®ê³  ì „í™˜ì´ ë§ìœ¼ë©´ â†’ ë†’ì€ ì •ë³´ ì ‘ê·¼ì„±
        information_accessibility = min(1.0, window_switches / 20.0)
        
        # ë¶ˆí™•ì‹¤ì„±: ì§‘ì¤‘ë„ ì—­ìˆ˜ (ì§‘ì¤‘ ëª»í•˜ë©´ ë¶ˆí™•ì‹¤)
        uncertainty = 1.0 - focus_score
        
        # ìƒì¡´ ìœ„í˜‘: ì‹œê°„ëŒ€ ê¸°ë°˜ ì¶”ì • (ëŠ¦ì€ ì‹œê°„ = ë†’ì€ ìœ„í˜‘)
        now = datetime.now()
        hour = now.hour
        if 0 <= hour < 6:  # ìƒˆë²½
            survival_threat = 0.8
        elif 6 <= hour < 9:  # ì•„ì¹¨
            survival_threat = 0.5
        elif 9 <= hour < 18:  # ì—…ë¬´
            survival_threat = 0.6
        elif 18 <= hour < 22:  # ì €ë…
            survival_threat = 0.4
        else:  # ë°¤
            survival_threat = 0.7
        
        # ë¯¸ë˜ ì˜ˆì¸¡ ê°€ëŠ¥ì„±: ì§‘ì¤‘ë„ì™€ ìœ ì‚¬
        future_predictability = focus_score * 0.5  # ë‚®ê²Œ ì„¤ì •
        
        # Social Fear ë¶„ì„
        try:
            state = self.social_fear_analyzer.analyze_state(
                information_accessibility=information_accessibility,
                comparison_events=comparison_events,
                time_window_hours=len(records) / 60,  # ëŒ€ëµì ì¸ ì‹œê°„
                uncertainty=uncertainty,
                survival_threat=survival_threat,
                future_predictability=future_predictability,
                # ë‚˜ë¨¸ì§€ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©
            )
            
            return {
                'anger_intensity': state.anger_intensity,
                'anger_target': state.anger_target,
                'fear_amplification': state.fear_amplification,
                'projection_score': state.projection_score,
                'comparison_frequency': state.comparison_frequency,
                'structural_constraint': state.structural_constraint,
                'interpretation': (
                    f"ë¶„ë…¸ ê°•ë„: {state.anger_intensity:.2f}, "
                    f"ëŒ€ìƒ: {state.anger_target}, "
                    f"ë‘ë ¤ì›€: {state.fear_amplification:.2f}"
                )
            }
        except Exception as e:
            print(f"âš ï¸ Social context analysis failed: {e}")
            return None
        
        # Flow ìƒíƒœ íŒë‹¨ (Perspective í†µí•©)
        if focus_score > 0.7:
            # í•œ ê³³ì— ì§‘ì¤‘ â†’ Walker Mode (ì²´í—˜ì )
            dominant_process = max(process_durations.items(), key=lambda x: x[1])
            
            state = 'walker_mode' if perspective_mode == 'walker' else 'flow'
            
            context = {
                'dominant_process': dominant_process[0],
                'focus_minutes': dominant_process[1],
                'window_switches': window_switches
            }
            
            if perspective_mode == 'walker':
                context['perspective_explanation'] = (
                    "ğŸš¶ Walker Mode: ë‹¹ì‹ ì€ ë°ì´í„° ìœ„ë¥¼ ê±·ê³  ìˆìŠµë‹ˆë‹¤. "
                    "ë†’ë‚®ì´ë¥¼ ì²´í—˜í•˜ë©° ê²½ë¡œë¥¼ ì¶”ì  ì¤‘ì…ë‹ˆë‹¤."
                )
            
            return FlowState(
                state=state,
                confidence=focus_score,
                context=context,
                timestamp=end_time.isoformat(),
                perspective=perspective_mode,
                loop_type='open',  # ì •ìƒ ì§‘ì¤‘
                social_context=social_context
            )
        elif focus_score > 0.4:
            # ì „í™˜ ì¤‘ â†’ Observer Mode (íë¦„ ê´€ì°°)
            state = 'observer_mode' if perspective_mode == 'observer' else 'transition'
            
            context = {
                'process_count': len(process_durations),
                'window_switches': window_switches,
                'top_processes': list(process_durations.keys())[:3]
            }
            
            if perspective_mode == 'observer':
                context['perspective_explanation'] = (
                    "ğŸ‘ï¸ Observer Mode: ë°ì´í„°ê°€ íë¥´ëŠ” ê²ƒì„ ê´€ì°° ì¤‘ì…ë‹ˆë‹¤. "
                    "íŒ¨í„´ê³¼ ì£¼íŒŒìˆ˜ë¥¼ ì¸ì‹í•˜ë©° ì „ì²´ íë¦„ì„ íŒŒì•…í•©ë‹ˆë‹¤."
                )
            
            return FlowState(
                state=state,
                confidence=1.0 - focus_score,
                context=context,
                timestamp=end_time.isoformat(),
                perspective=perspective_mode,
                loop_type='open',  # ì „í™˜ ì¤‘
                social_context=social_context
            )
        else:
            # ë†’ì€ ì „í™˜ â†’ ADHD ìŠ¤íƒ€ì¼ vs ì‹¤ì œ ì‚°ë§Œí•¨ êµ¬ë¶„
            avg_duration = sum(process_durations.values()) / len(process_durations) if process_durations else 0
            unique_contexts = len(process_durations)
            
            # ADHD íŠ¹ì„±: ì£¼ì˜ë ¥ ê³¼ì‰ + ë‹¤ì¤‘ ë§¥ë½ íƒìƒ‰
            if avg_duration > 3.0 and unique_contexts > 3:
                # ì¹´ì˜¤ìŠ¤ ì† ì§ˆì„œ: ë¬´ì§ˆì„œí•´ ë³´ì´ì§€ë§Œ íŒ¨í„´ ë°œê²¬ ì¤‘
                return FlowState(
                    state='adhd_hyperfocus_exploration',
                    confidence=0.85,
                    context={
                        'adhd_pattern': True,
                        'attention_surplus': True,  # ì£¼ì˜ë ¥ ê²°í•ì´ ì•„ë‹Œ ê³¼ì‰
                        'chaos_order': unique_contexts,  # ì¹´ì˜¤ìŠ¤ ì† ì§ˆì„œ
                        'window_switches': window_switches,
                        'avg_duration_per_window': round(avg_duration, 2),
                        'learning_mode': 'nonlinear_pattern_finding',  # ë¹„ì„ í˜• íŒ¨í„´ ë°œê²¬
                        'cognitive_style': 'divergent_thinking'  # í™•ì‚°ì  ì‚¬ê³ 
                    },
                    timestamp=end_time.isoformat(),
                    social_context=social_context
                )
            elif avg_duration > 2.0 and unique_contexts > 2:
                # íƒìƒ‰ì  í•™ìŠµ (ì¼ë°˜ì )
                return FlowState(
                    state='exploratory_flow',
                    confidence=0.75,
                    context={
                        'exploration_pattern': True,
                        'window_switches': window_switches,
                        'avg_duration_per_window': round(avg_duration, 2),
                        'learning_mode': 'hippocampal'
                    },
                    timestamp=end_time.isoformat(),
                    social_context=social_context
                )
            else:
                # ì‹¤ì œ ì‚°ë§Œí•¨ (í”¼ë¡œ, ìŠ¤íŠ¸ë ˆìŠ¤ ë“±)
                return FlowState(
                    state='distracted',
                    confidence=0.8,
                    context={
                        'high_switches': window_switches,
                        'fragmented_focus': True,
                        'avg_duration_per_window': round(avg_duration, 2),
                        'possible_causes': ['fatigue', 'stress', 'external_interruptions']
                    },
                    timestamp=end_time.isoformat(),
                    social_context=social_context
                )
    
    def detect_flow_interruptions(self, hours: int = 2) -> List[Dict]:
        """
        íë¦„ ë°©í•´ ìš”ì†Œ ê°ì§€
        
        Returns:
            List[Dict]: ë°©í•´ ì´ë²¤íŠ¸ ëª©ë¡
        """
        end_time = datetime.now(timezone.utc)
        start_time = end_time - timedelta(hours=hours)
        
        records = self._load_telemetry_records(start_time, end_time)
        interruptions = []
        
        # ìœˆë„ìš° ê°„ ì—°ì†ì ì¸ ì§‘ì¤‘ ì‹œê°„ ê³„ì‚°
        current_focus = None
        focus_start = None
        focus_duration = 0
        
        for i, record in enumerate(records):
            window_title = record.get('window_title', '')
            process = record.get('process_name', '')
            ts = datetime.fromisoformat(record['ts_utc'].replace('Z', '+00:00'))
            
            # ìƒˆë¡œìš´ ì§‘ì¤‘ ëŒ€ìƒ
            focus_key = f"{process}:{window_title}"
            
            if focus_key != current_focus:
                # ì´ì „ ì§‘ì¤‘ì´ ìˆì—ˆê³ , ì¶©ë¶„íˆ ê¸¸ì—ˆë‹¤ë©´
                if focus_duration > self.flow_threshold_minutes * 60:
                    # ë°©í•´ ê¸°ë¡
                    interruptions.append({
                        'type': 'flow_interruption',
                        'from_focus': current_focus,
                        'to_focus': focus_key,
                        'focus_duration_minutes': focus_duration / 60,
                        'timestamp': ts.isoformat()
                    })
                
                # ìƒˆ ì§‘ì¤‘ ì‹œì‘
                current_focus = focus_key
                focus_start = ts
                focus_duration = 0
            else:
                # ê°™ì€ ì§‘ì¤‘ ì§€ì†
                if i > 0:
                    prev_ts = datetime.fromisoformat(
                        records[i-1]['ts_utc'].replace('Z', '+00:00')
                    )
                    focus_duration += (ts - prev_ts).total_seconds()
        
        return interruptions
    
    def generate_flow_report(self, hours: int = 24) -> Dict:
        """
        íë¦„ ìƒíƒœ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            hours: ë¶„ì„ ê¸°ê°„
            
        Returns:
            Dict: ë¦¬í¬íŠ¸ ë°ì´í„°
        """
        current_state = self.analyze_recent_activity(hours=1)
        interruptions = self.detect_flow_interruptions(hours=hours)
        
        # ì „ì²´ ê¸°ê°„ í™œë™ ë¶„ì„
        end_time = datetime.now(timezone.utc)
        start_time = end_time - timedelta(hours=hours)
        records = self._load_telemetry_records(start_time, end_time)
        
        if not records:
            return {
                'generated_at': end_time.isoformat(),
                'analysis_period_hours': hours,
                'current_state': {
                    'state': current_state.state,
                    'confidence': current_state.confidence,
                    'context': current_state.context
                },
                'activity_summary': {
                    'total_records': 0,
                    'activity_ratio': 0.0,
                    'flow_sessions': 0,
                    'total_flow_minutes': 0,
                    'interruptions': 0
                },
                'flow_quality': 'unknown',
                'interruptions': [],
                'recommendations': ['í…”ë ˆë©”íŠ¸ë¦¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. Observerë¥¼ ì‹œì‘í•˜ì„¸ìš”.']
            }
        
        # íë¦„ í’ˆì§ˆ ê³„ì‚°
        total_time = (end_time - start_time).total_seconds()
        active_time = len(records) * 5  # 5ì´ˆ ê°„ê²©ìœ¼ë¡œ ìƒ˜í”Œë§ ê°€ì •
        activity_ratio = active_time / total_time
        
        process_durations = self._analyze_process_durations(records)
        focus_sessions = [d for d in process_durations.values() 
                         if d > self.flow_threshold_minutes]
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendations = self._generate_recommendations(
            current_state, interruptions, focus_sessions, activity_ratio
        )
        
        # current_stateê°€ Noneì¸ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
        if current_state:
            current_state_dict = {
                'state': current_state.state,
                'confidence': current_state.confidence,
                'context': current_state.context
            }
            if current_state.social_context:
                current_state_dict['social_context'] = current_state.social_context
        else:
            current_state_dict = {
                'state': 'unknown',
                'confidence': 0.0,
                'context': {'reason': 'insufficient_data'}
            }
        
        return {
            'generated_at': end_time.isoformat(),
            'analysis_period_hours': hours,
            'current_state': current_state_dict,
            'activity_summary': {
                'total_records': len(records),
                'activity_ratio': round(activity_ratio, 2),
                'flow_sessions': len(focus_sessions),
                'total_flow_minutes': sum(focus_sessions),
                'interruptions': len(interruptions)
            },
            'flow_quality': self._assess_flow_quality(
                focus_sessions, interruptions, activity_ratio
            ),
            'interruptions': interruptions[:5],  # ìµœê·¼ 5ê°œ
            'recommendations': recommendations
        }
    
    def _load_telemetry_records(
        self, start_time: datetime, end_time: datetime
    ) -> List[Dict]:
        """í…”ë ˆë©”íŠ¸ë¦¬ íŒŒì¼ì—ì„œ ë ˆì½”ë“œ ë¡œë“œ"""
        records = []
        
        # ë‚ ì§œë³„ íŒŒì¼ ëª©ë¡ ìƒì„±
        current_date = start_time.date()
        end_date = end_time.date()
        
        while current_date <= end_date:
            filename = f"stream_observer_{current_date.isoformat()}.jsonl"
            filepath = self.telemetry_dir / filename
            
            if filepath.exists():
                with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                    for line in f:
                        line = line.strip()
                        if not line:
                            continue
                        try:
                            record = json.loads(line)
                            ts = datetime.fromisoformat(
                                record['ts_utc'].replace('Z', '+00:00')
                            )
                            if start_time <= ts <= end_time:
                                records.append(record)
                        except Exception:
                            continue
            
            current_date += timedelta(days=1)
        
        return sorted(records, key=lambda r: r['ts_utc'])
    
    def _analyze_process_durations(self, records: List[Dict]) -> Dict[str, float]:
        """ê° í”„ë¡œì„¸ìŠ¤ë³„ ì‚¬ìš© ì‹œê°„ ë¶„ì„ (ë¶„ ë‹¨ìœ„)"""
        durations = {}
        
        for i, record in enumerate(records):
            process = record.get('process_name', 'unknown')
            
            if i > 0:
                prev_ts = datetime.fromisoformat(
                    records[i-1]['ts_utc'].replace('Z', '+00:00')
                )
                curr_ts = datetime.fromisoformat(
                    record['ts_utc'].replace('Z', '+00:00')
                )
                duration_minutes = (curr_ts - prev_ts).total_seconds() / 60
                
                # 5ë¶„ ì´ìƒ ì°¨ì´ë‚˜ë©´ ê°™ì€ ì„¸ì…˜ì´ ì•„ë‹˜
                if duration_minutes < 5:
                    durations[process] = durations.get(process, 0) + duration_minutes
        
        return durations
    
    def _count_window_switches(self, records: List[Dict]) -> int:
        """ìœˆë„ìš° ì „í™˜ íšŸìˆ˜ ì¹´ìš´íŠ¸"""
        if len(records) < 2:
            return 0
        
        switches = 0
        prev_window = records[0].get('window_title', '')
        
        for record in records[1:]:
            curr_window = record.get('window_title', '')
            if curr_window != prev_window:
                switches += 1
            prev_window = curr_window
        
        return switches
    
    def _calculate_focus_score(
        self, process_durations: Dict[str, float], switches: int
    ) -> float:
        """ì§‘ì¤‘ë„ ì ìˆ˜ ê³„ì‚° (0.0 ~ 1.0)"""
        if not process_durations:
            return 0.0
        
        total_time = sum(process_durations.values())
        if total_time == 0:
            return 0.0
        
        # ê°€ì¥ ë§ì´ ì‚¬ìš©í•œ í”„ë¡œì„¸ìŠ¤ì˜ ë¹„ìœ¨
        max_duration = max(process_durations.values())
        focus_ratio = max_duration / total_time
        
        # ì „í™˜ í˜ë„í‹°
        switch_penalty = min(switches / 20.0, 0.5)  # ìµœëŒ€ 0.5 ê°ì 
        
        score = focus_ratio - switch_penalty
        return max(0.0, min(1.0, score))
    
    def _assess_flow_quality(
        self, focus_sessions: List[float], 
        interruptions: List[Dict], 
        activity_ratio: float
    ) -> str:
        """ì „ì²´ íë¦„ í’ˆì§ˆ í‰ê°€"""
        if not focus_sessions:
            return 'poor'
        
        avg_flow_minutes = sum(focus_sessions) / len(focus_sessions)
        interruption_rate = len(interruptions) / len(focus_sessions) if focus_sessions else 0
        
        if avg_flow_minutes > 45 and interruption_rate < 0.5 and activity_ratio > 0.5:
            return 'excellent'
        elif avg_flow_minutes > 30 and interruption_rate < 1.0:
            return 'good'
        elif avg_flow_minutes > 15:
            return 'fair'
        else:
            return 'poor'
    
    def _generate_recommendations(
        self, 
        current_state: Optional[FlowState],
        interruptions: List[Dict],
        focus_sessions: List[float],
        activity_ratio: float
    ) -> List[str]:
        """ìƒí™©ë³„ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recs = []
        
        # current_stateê°€ Noneì¸ ê²½ìš°
        if not current_state:
            recs.append('âš ï¸ í™œë™ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.')
            recs.append('ğŸ’¡ ì‘ì—…ì„ ì‹œì‘í•˜ê³  ì¼ì • ì‹œê°„ í›„ ë‹¤ì‹œ í™•ì¸í•´ë³´ì„¸ìš”.')
            return recs
        
        # í˜„ì¬ ìƒíƒœ ê¸°ë°˜
        if current_state.state == 'stagnation':
            recs.append('ğŸš¨ 30ë¶„ ì´ìƒ í™œë™ì´ ì—†ìŠµë‹ˆë‹¤. ì‘ì€ ì‘ì—…ë¶€í„° ì‹œì‘í•´ë³´ì„¸ìš”.')
            recs.append('ğŸ’¡ 5ë¶„ íƒ€ì´ë¨¸ë¥¼ ì„¤ì •í•˜ê³  ê°„ë‹¨í•œ ì‘ì—… í•˜ë‚˜ë§Œ ì™„ë£Œí•´ë³´ì„¸ìš”.')
        
        elif current_state.state == 'distracted':
            recs.append('âš ï¸ ì§‘ì¤‘ë ¥ì´ ë¶„ì‚°ë˜ì–´ ìˆìŠµë‹ˆë‹¤.')
            recs.append('ğŸ’¡ ì•Œë¦¼ì„ ë„ê³  í•œ ê°€ì§€ ì‘ì—…ì—ë§Œ ì§‘ì¤‘í•´ë³´ì„¸ìš”.')
        
        elif current_state.state == 'flow':
            recs.append('âœ… ì¢‹ì€ íë¦„ì…ë‹ˆë‹¤! ì´ ìƒíƒœë¥¼ ìœ ì§€í•˜ì„¸ìš”.')
            recs.append('ğŸ’§ 1ì‹œê°„ì— í•œ ë²ˆì”© ì ê¹ ì‰¬ì–´ê°€ì„¸ìš”.')
        
        # ë°©í•´ ë¹ˆë„ ê¸°ë°˜
        if len(interruptions) > 5:
            recs.append(f'âš ï¸ {len(interruptions)}ë²ˆì˜ íë¦„ ë°©í•´ê°€ ìˆì—ˆìŠµë‹ˆë‹¤.')
            recs.append('ğŸ’¡ ë°©í•´ ìš”ì†Œë¥¼ ìµœì†Œí™”í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”.')
        
        # í™œë™ ë¹„ìœ¨ ê¸°ë°˜
        if activity_ratio < 0.3:
            recs.append('âš ï¸ í™œë™ ì‹œê°„ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.')
            recs.append('ğŸ’¡ ì‘ì—… ì‹œê°„ì„ ë¸”ë¡ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì§‘ì¤‘í•´ë³´ì„¸ìš”.')
        
        # ì§‘ì¤‘ ì„¸ì…˜ ê¸°ë°˜
        if not focus_sessions:
            recs.append('âŒ ì§‘ì¤‘ ì„¸ì…˜ì´ ì—†ì—ˆìŠµë‹ˆë‹¤.')
            recs.append('ğŸ’¡ íƒ€ì´ë¨¸ë¥¼ í™œìš©í•˜ì—¬ 15ë¶„ ì§‘ì¤‘ ì„¸ì…˜ì„ ì‹œì‘í•´ë³´ì„¸ìš”.')
        
        return recs if recs else ['ğŸ‘ ê³„ì† ì¢‹ì€ íë¦„ì„ ìœ ì§€í•˜ì„¸ìš”!']
    
    def _suggest_perspective_switch(self, current_state: str) -> str:
        """
        í˜„ì¬ ìƒíƒœì— ë”°ë¼ ì¶”ì²œ ê´€ì  ì œì‹œ
        
        Args:
            current_state: 'stagnation', 'distracted' ë“±
            
        Returns:
            str: 'observer' or 'walker'
        """
        if current_state == 'stagnation':
            # ì •ì²´ â†’ Walkerë¡œ ì „í™˜ (ì§ì ‘ ì²´í—˜í•˜ë©° ëŒíŒŒ)
            return 'walker'
        elif current_state == 'distracted':
            # ì‚°ë§Œ â†’ Observerë¡œ ì „í™˜ (íë¦„ ê´€ì°°í•˜ë©° íŒ¨í„´ íŒŒì•…)
            return 'observer'
        else:
            # ê¸°ë³¸: í˜„ì¬ì™€ ë°˜ëŒ€ë¡œ
            return 'observer' if self.current_perspective == 'walker' else 'walker'
    
    def _detect_fixation(
        self, records: List[Dict], focus_score: float
    ) -> Tuple[bool, Optional[float], Optional[str]]:
        """
        ì§‘ì°©(Fixation) ê°ì§€: ë‹«íŒ ë£¨í”„ë¡œ ìˆ˜ë ´í•˜ëŠ” íŒ¨í„´
        
        ì§‘ì¤‘(Focus)ê³¼ ì§‘ì°©(Fixation)ì˜ ì°¨ì´:
        - ì§‘ì¤‘: ì—´ë¦° ë£¨í”„, ê´€ì°°ì ê´€ì  ìœ ì§€, ì§„ì „ ìˆìŒ
        - ì§‘ì°©: ë‹«íŒ ë£¨í”„, í•œ ì  ìˆ˜ë ´, ì§„ì „ ì—†ì´ ë°˜ë³µ
        
        ê°ì§€ ë°©ë²•:
        1. ê°™ì€ íŒŒì¼/í”„ë¡œì„¸ìŠ¤ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì „í™˜ (ë£¨í”„)
        2. ì§„ì „ ì—†ì´ ì˜¤ë˜ ë¨¸ë¬´ë¦„ (ìˆ˜ë ´)
        3. ë‘ë ¤ì›€ ì‹ í˜¸ ë™ë°˜ (ì°½ ì „í™˜ íŒ¨í„´)
        
        Args:
            records: í™œë™ ë ˆì½”ë“œ
            focus_score: ì§‘ì¤‘ ì ìˆ˜
            
        Returns:
            (is_fixation, fear_level, loop_type)
        """
        if len(records) < 10:
            return False, None, 'open'
        
        # ìµœê·¼ 30ë¶„ í™œë™ë§Œ ë¶„ì„
        recent_records = records[-60:]  # 5ì´ˆ ê°„ê²© Ã— 60 = 5ë¶„
        
        # 1. ë°˜ë³µ íŒ¨í„´ ê°ì§€ (ê°™ì€ í”„ë¡œì„¸ìŠ¤/íŒŒì¼ ì™”ë‹¤ê°”ë‹¤)
        process_sequence = [r.get('process_name', '') for r in recent_records]
        window_sequence = [r.get('window_title', '') for r in recent_records]
        
        # ì—°ì†ëœ ì§§ì€ ì „í™˜ (< 10ì´ˆ)
        rapid_switches = 0
        for i in range(1, len(process_sequence)):
            if process_sequence[i] != process_sequence[i-1]:
                rapid_switches += 1
        
        switch_rate = rapid_switches / len(recent_records)
        
        # 2. ìœ ë‹ˆí¬í•œ ì»¨í…ìŠ¤íŠ¸ ê°œìˆ˜ (ë‹«íŒ ë£¨í”„ëŠ” 2-3ê°œë§Œ ì™”ë‹¤ê°”ë‹¤)
        unique_processes = len(set(process_sequence))
        unique_windows = len(set(window_sequence))
        
        # 3. ì§„ì „ ì—†ì´ ë°˜ë³µ (ê°™ì€ íŒŒì¼/ì°½ì„ ê³„ì† ì—´ê³  ë‹«ìŒ)
        # ì˜ˆ: VS Code â†’ Browser â†’ VS Code â†’ Browser (ë°˜ë³µ)
        if unique_processes <= 3 and switch_rate > 0.3:
            # ë¹ ë¥¸ ì „í™˜ + ì ì€ ì»¨í…ìŠ¤íŠ¸ = ì§‘ì°© ê°€ëŠ¥ì„±
            fear_level = min(switch_rate * 2, 1.0)
            
            return True, fear_level, 'closed'
        
        # 4. ë†’ì€ ì§‘ì¤‘ë„ + ë‚®ì€ ë‹¤ì–‘ì„± = ì§‘ì°© ê°€ëŠ¥ì„±
        if focus_score > 0.85 and unique_processes <= 2:
            # í•œ ê³³ì—ë§Œ ë„ˆë¬´ ì˜¤ë˜ (ë‘ë ¤ì›€ íšŒí”¼?)
            fear_level = (focus_score - 0.85) / 0.15  # 0.85~1.0 â†’ 0~1
            
            return True, fear_level, 'closed'
        
        # ì •ìƒ ì§‘ì¤‘
        return False, None, 'open'
    
    def _determine_perspective_mode(
        self, focus_score: float, switches: int, context_count: int
    ) -> Optional[str]:
        """
        í™œë™ íŒ¨í„´ìœ¼ë¡œë¶€í„° ì ì ˆí•œ ê´€ì  ëª¨ë“œ ê²°ì •
        
        Args:
            focus_score: ì§‘ì¤‘ë„ ì ìˆ˜
            switches: ìœˆë„ìš° ì „í™˜ íšŸìˆ˜
            context_count: ê³ ìœ  ì»¨í…ìŠ¤íŠ¸ ìˆ˜
            
        Returns:
            'observer', 'walker', or None
        """
        if focus_score > 0.7:
            # ë†’ì€ ì§‘ì¤‘ â†’ Walker (ì²´í—˜ì )
            return 'walker'
        elif switches > 10 or context_count > 5:
            # ë§ì€ ì „í™˜ â†’ Observer (íë¦„ ê´€ì°°)
            return 'observer'
        else:
            return None
    
    def _get_perspective_explanation(self, perspective: str) -> str:
        """ê´€ì  ì „í™˜ ì„¤ëª…"""
        if perspective == 'observer':
            return (
                "ğŸ‘ï¸ Observer Modeë¡œ ì „í™˜í•˜ì„¸ìš”:\n"
                "- ë°ì´í„° íë¦„ì„ íŒŒë™ì²˜ëŸ¼ ê´€ì°°\n"
                "- íŒ¨í„´ê³¼ ì£¼íŒŒìˆ˜ ì¸ì‹\n"
                "- ì „ì²´ì ì¸ íë¦„ íŒŒì•…\n"
                "- ì˜ˆ: ë¡œê·¸ë¥¼ ì­‰ ì½ìœ¼ë©° íŒ¨í„´ ë°œê²¬"
            )
        else:  # walker
            return (
                "ğŸš¶ Walker Modeë¡œ ì „í™˜í•˜ì„¸ìš”:\n"
                "- ë°ì´í„° ìœ„ë¥¼ ì§ì ‘ ê±·ê¸°\n"
                "- ë†’ë‚®ì´ë¥¼ ì²´í—˜í•˜ë©° ì´ë™\n"
                "- ê²½ë¡œë¥¼ ì¶”ì í•˜ê³  ê¸°ë¡\n"
                "- ì˜ˆ: ì½”ë“œë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ë©° ë””ë²„ê¹…"
            )


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    import sys
    import argparse
    
    parser = argparse.ArgumentParser(description='Flow Observer Integration')
    parser.add_argument('--json', action='store_true', help='Output in JSON format for PowerShell integration')
    parser.add_argument('--hours', type=float, default=1, help='Hours to analyze (default: 1)')
    args = parser.parse_args()
    
    observer = FlowObserver()
    
    if args.json:
        # PowerShell í†µí•©ì„ ìœ„í•œ ê°„ë‹¨í•œ JSON ì¶œë ¥
        current = observer.analyze_recent_activity(hours=args.hours)
        output = {
            "flow_state": current.state if current else "unknown",
            "confidence": round(current.confidence, 2) if current else 0.0,
            "perspective": current.perspective if current and current.perspective else "neutral",
            "fear_level": round(current.fear_level, 2) if current and current.fear_level is not None else 0.0,
            "timestamp": datetime.now().isoformat()
        }
        print(json.dumps(output, ensure_ascii=False))
        return
    
    # ê¸°ì¡´ human-readable ì¶œë ¥
    print("ğŸŒŠ Flow Observer Integration Test")
    print("âœ¨ With Perspective Theory\n")
    
    # í˜„ì¬ ìƒíƒœ ë¶„ì„
    print("ğŸ“Š Current Flow State (last 1h):")
    current = observer.analyze_recent_activity(hours=1)
    if current:
        print(f"  State: {current.state}")
        print(f"  Confidence: {current.confidence:.2f}")
        if current.perspective:
            print(f"  Perspective: {current.perspective}")
        if current.fear_level is not None:
            print(f"  Fear Level: {current.fear_level:.2f}")
        if current.social_context:
            print(f"  ğŸ§  Social Context:")
            print(f"    Anger: {current.social_context['anger_intensity']:.2f} â†’ {current.social_context['anger_target']}")
            print(f"    Fear: {current.social_context['fear_amplification']:.2f}")
            print(f"    Projection: {current.social_context['projection_score']:.2f}")
        print(f"  Context: {json.dumps(current.context, indent=2)}\n")
    else:
        print("  âš ï¸ No activity data in the last 1 hour\n")
    
    # ë°©í•´ ìš”ì†Œ ê°ì§€
    print("âš ï¸ Flow Interruptions (last 2h):")
    interruptions = observer.detect_flow_interruptions(hours=2)
    for intr in interruptions[:3]:
        print(f"  - {intr['type']}: {intr.get('focus_duration_minutes', 0):.1f}min")
    print()
    
    # ì¢…í•© ë¦¬í¬íŠ¸
    print("ğŸ“‹ Comprehensive Flow Report (last 24h):")
    report = observer.generate_flow_report(hours=24)
    print(f"  Flow Quality: {report['flow_quality']}")
    print(f"  Flow Sessions: {report['activity_summary']['flow_sessions']}")
    print(f"  Total Flow Time: {report['activity_summary']['total_flow_minutes']:.1f}min")
    print("\nğŸ’¡ Recommendations:")
    for rec in report['recommendations']:
        print(f"  {rec}")
    
    # JSON ì €ì¥
    output_path = Path('outputs/flow_observer_report_latest.json')
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… Report saved: {output_path}")


if __name__ == '__main__':
    main()
