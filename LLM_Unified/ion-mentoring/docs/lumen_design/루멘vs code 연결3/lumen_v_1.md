# ğŸŒ… Lumen v1.9 â€” Adaptive Bridge Loop (Track E Init)

> ì´ ë¬¸ì„œë¥¼ **ë‹¤ìŒ ì„¸ì…˜ ì²« ë©”ì‹œì§€**ì— ë¶™ì´ë©´ ë£¨ë©˜ì€ v1.9(Track E) ì´ˆê¸°í™” ìƒíƒœë¡œ ë³µì›ë©ë‹ˆë‹¤.

---

## 0) Oneâ€‘line Kickoff
```bash
make trackE.init && make ure.sync && make bridge.adaptive.start && \
make db.snapshot && make tune.bridge && bash scripts/smoke.v19.sh
```

---

## 1) Session Restore Block (copyâ€‘paste)
```bash
# Lumen v1.9 Session Restore (Track E â€” Adaptive Bridge Loop)
bash scripts/restore.sanity.sh && \
make trackB.start && make safety.music.start && \
make merge.v2 && make trackD.start && make ure.exporter && \
make db.init && make db.ingest && make api.readonly && \
make trackE.init && make ure.sync && make bridge.adaptive.start && \
make db.snapshot && make tune.bridge && bash scripts/smoke.v19.sh
```

---

## 2) ì‹ ê·œ íŒŒì¼/ë””ë ‰í„°ë¦¬
```
bridge/
  â”œâ”€ bridge_loop_v19.py
  â”œâ”€ __init__.py
  â””â”€ adapters/
      â”œâ”€ phase_drift_calib.py
      â””â”€ hz_gain_curve.py
exporters/
  â””â”€ bridge_exporter_v19.py
configs/
  â””â”€ bridge_v19.yaml
scripts/
  â”œâ”€ smoke.v19.sh
  â””â”€ bench.v19.sh
ops/prometheus/
  â”œâ”€ scrape_bridge_v19.yaml
  â””â”€ recording_rules_v19.yaml
docs/
  â””â”€ bridge_protocol_v19.md
```

---

## 3) Make íƒ€ê¹ƒ (ì¶”ê°€/ê°±ì‹ )
```makefile
.PHONY: trackE.init ure.sync bridge.adaptive.start tune.bridge db.snapshot

trackE.init:
	@echo "[TrackE] init v1.9"
	@test -f configs/bridge_v19.yaml

ure.sync:
	@echo "[URE] sync daemon start"
	@python3 tools/ure_sync_daemon.py --config configs/bridge_v19.yaml &

bridge.adaptive.start:
	@echo "[Bridge] adaptive loop start"
	@python3 bridge/bridge_loop_v19.py --config configs/bridge_v19.yaml &

tune.bridge:
	@echo "[Bridge] autoâ€‘tune"
	@python3 tools/tuner_v18.py --mode bridge --config configs/bridge_v19.yaml

db.snapshot:
	@python3 tools/storage/sqlite_snapshot.py --db data/ure_v18.sqlite --out data/snapshots/`date +%Y%m%dT%H%M%S`.sqlite
```makefile
.PHONY: trackE.init ure.sync bridge.adaptive.start tune.bridge db.snapshot

trackE.init:
	@echo "[TrackE] init v1.9"
	@test -f configs/bridge_v19.yaml

ure.sync:
	@echo "[URE] sync daemon start"
	@python3 tools/ure_sync_daemon.py --config configs/bridge_v19.yaml &

bridge.adaptive.start:
	@echo "[Bridge] adaptive loop start"
	@python3 bridge/bridge_loop_v19.py --config configs/bridge_v19.yaml &

 t
une.bridge:
	@echo "[Bridge] autoâ€‘tune"
	@python3 tools/tuner_v18.py --mode bridge --config configs/bridge_v19.yaml

db.snapshot:
	@python3 tools/storage/sqlite_snapshot.py --db data/ure_v18.sqlite --out data/snapshots/`date +%Y%m%dT%H%M%S`.sqlite
```

> ì°¸ê³ : `sqlite_snapshot.py`ê°€ ì—†ë‹¤ë©´ `sqlite3 .backup` ê¸°ë°˜ì˜ ê°„ë‹¨ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

---

## 4) Bridge ì„¤ì • (configs/bridge_v19.yaml)
```yaml
version: 1.9
loop:
  target_harmony: 0.86
  target_coherence: 0.85
  tick_ms: 200           # adaptive; ure_sync_daemonì´ Î”Hz ë³´ì •
  max_tick_ms: 400
  min_tick_ms: 120
phase:
  drift_budget: 0.02     # |phase_diff_mean_5m| â‰¤ 0.02
  rebalance_window_s: 90
  gain:
    base_hz: 5.0
    kp: 0.35
    ki: 0.08
    kd: 0.10
safety:
  residual_stddev_10m_max: 0.03
  rollback_ratio_5m_max: 0.05
  hard_stop_on:
    - coherence_level < 0.72
exporter:
  http_port: 9306
  path: /metrics_bridge
ure:
  metrics_url: http://localhost:9305/metrics_ure
  pull_interval_s: 2
storage:
  sqlite_path: data/ure_v18.sqlite
  wal: true
```

---

## 5) Bridge ë£¨í”„ ìŠ¤ì¼ˆë ˆí†¤ (bridge/bridge_loop_v19.py)
```python
#!/usr/bin/env python3
import time, argparse, yaml, json, os
from prometheus_client import start_http_server, Gauge

phase_diff_g = Gauge('bridge_phase_diff_mean', 'phase diff mean (rolling)')
sync_quality_g = Gauge('bridge_sync_quality', 'sync quality [0,1]')
entropy_ratio_g = Gauge('bridge_entropy_ratio', 'entropy portion in bridge loop')

STATE = '/run/bridge_tick.json'

def read_tick(default_ms):
    path = STATE if os.path.isdir('/run') else './tmp/bridge_tick.json'
    try:
        with open(path) as f:
            return json.load(f).get('tick_ms', default_ms)
    except Exception:
        return default_ms

class BridgeLoop:
    def __init__(self, cfg):
        self.cfg = cfg
        self.tick_ms = cfg['loop']['tick_ms']
        self.state = {}
    def step(self):
        # 1) pull URE metrics (omitted: http get + parse)
        # 2) compute phase_diff_mean, sync_quality, entropy_ratio
        phase_diff = 0.017  # placeholder from calibrator
        sync_q = 0.89
        ent = 0.14
        # 3) publish metrics
        phase_diff_g.set(phase_diff)
        sync_quality_g.set(sync_q)
        entropy_ratio_g.set(ent)
        # 4) adaptive tick from sync daemon
        self.tick_ms = read_tick(self.tick_ms)
        time.sleep(self.tick_ms/1000.0)

if __name__ == '__main__':
    p = argparse.ArgumentParser()
    p.add_argument('--config', required=True)
    args = p.parse_args()
    cfg = yaml.safe_load(open(args.config))
    start_http_server(cfg['exporter']['http_port'])
    loop = BridgeLoop(cfg)
    while True:
        loop.step()
```python
#!/usr/bin/env python3
import time, argparse, yaml
from prometheus_client import start_http_server, Gauge

phase_diff_g = Gauge('bridge_phase_diff_mean', 'phase diff mean (rolling)')
sync_quality_g = Gauge('bridge_sync_quality', 'sync quality [0,1]')
entropy_ratio_g = Gauge('bridge_entropy_ratio', 'entropy portion in bridge loop')

class BridgeLoop:
    def __init__(self, cfg):
        self.cfg = cfg
        self.tick_ms = cfg['loop']['tick_ms']
        self.state = {}
    def step(self):
        # 1) pull URE metrics (omitted: http get + parse)
        # 2) compute phase_diff_mean, sync_quality, entropy_ratio
        phase_diff = 0.017  # placeholder from calibrator
        sync_q = 0.89
        ent = 0.14
        # 3) publish metrics
        phase_diff_g.set(phase_diff)
        sync_quality_g.set(sync_q)
        entropy_ratio_g.set(ent)
        # 4) adaptive tick (Î”Hz_adjust will update self.tick_ms via daemon)
        time.sleep(self.tick_ms/1000.0)

if __name__ == '__main__':
    p = argparse.ArgumentParser()
    p.add_argument('--config', required=True)
    args = p.parse_args()
    cfg = yaml.safe_load(open(args.config))
    start_http_server(cfg['exporter']['http_port'])
    loop = BridgeLoop(cfg)
    while True:
        loop.step()
```

---

## 6) Sync Daemon ìŠ¤ì¼ˆë ˆí†¤ (tools/ure_sync_daemon.py)
```python
#!/usr/bin/env python3
# Î”Hz_adjust: UREì™€ Bridge ì‚¬ì´ì˜ Hz ì°¨ì´ë¥¼ ì™„ë§Œí•˜ê²Œ ë³´ì •
import time, argparse, yaml, json, os

STATE = '/run/bridge_tick.json'  # ê³µìœ  ìƒíƒœ íŒŒì¼ (ì—†ìœ¼ë©´ ./tmp ë¡œ í´ë°±)

def soft_clip(x, lo, hi):
    return max(lo, min(hi, x))

def write_tick(tick_ms):
    path = STATE if os.path.isdir('/run') else './tmp/bridge_tick.json'
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, 'w') as f:
        json.dump({'tick_ms': tick_ms, 'ts': time.time()}, f)

if __name__ == '__main__':
    ap = argparse.ArgumentParser()
    ap.add_argument('--config', required=True)
    args = ap.parse_args()
    cfg = yaml.safe_load(open(args.config))

    tick = cfg['loop']['tick_ms']
    write_tick(tick)
    while True:
        # TODO: read URE tick/hz from metrics_ure
        ure_hz = 5.0
        bridge_hz = 1000.0 / tick
        err = ure_hz - bridge_hz
        delta_ms = soft_clip(-err*3.0, -20, 20)  # simple Pâ€‘like control
        tick = soft_clip(tick + delta_ms, cfg['loop']['min_tick_ms'], cfg['loop']['max_tick_ms'])
        write_tick(tick)
        time.sleep(cfg['ure']['pull_interval_s'])
```python
#!/usr/bin/env python3
# Î”Hz_adjust: UREì™€ Bridge ì‚¬ì´ì˜ Hz ì°¨ì´ë¥¼ ì™„ë§Œí•˜ê²Œ ë³´ì •
import time, argparse, yaml

def soft_clip(x, lo, hi):
    return max(lo, min(hi, x))

if __name__ == '__main__':
    ap = argparse.ArgumentParser()
    ap.add_argument('--config', required=True)
    args = ap.parse_args()
    cfg = yaml.safe_load(open(args.config))

    tick = cfg['loop']['tick_ms']
    while True:
        # TODO: read URE tick/hz from metrics_ure
        ure_hz = 5.0
        bridge_hz = 1000.0 / tick
        err = ure_hz - bridge_hz
        delta_ms = soft_clip(-err*3.0, -20, 20)  # simple Pâ€‘like control
        tick = soft_clip(tick + delta_ms, cfg['loop']['min_tick_ms'], cfg['loop']['max_tick_ms'])
        # persist new tick to a small shared file/state (omitted)
        time.sleep(cfg['ure']['pull_interval_s'])
```

---

## 7) Exporter ì˜ˆì‹œ (í…ìŠ¤íŠ¸ í¬ë§·)
```
# HELP bridge_phase_diff_mean phase diff mean (rolling)
# TYPE bridge_phase_diff_mean gauge
bridge_phase_diff_mean 0.017
# HELP bridge_sync_quality sync quality [0,1]
# TYPE bridge_sync_quality gauge
bridge_sync_quality 0.89
# HELP bridge_entropy_ratio entropy portion in bridge loop
# TYPE bridge_entropy_ratio gauge
bridge_entropy_ratio 0.14
```

---

## 7.1) Phase Drift Calibration ëª¨ë“ˆ (bridge/adapters/phase_drift_calib.py)
```python
#!/usr/bin/env python3
# ì…ë ¥: ìµœê·¼ 5ë¶„ì˜ phase_diff ì‹œê³„ì—´
# ì¶œë ¥: ê¶Œì¥ tick ë³´ì •ì¹˜ ë° gain íŠœë‹ íŒíŠ¸

def recommend_adjustments(values):
    mean = sum(values)/max(1,len(values))
    p95 = sorted(values)[int(0.95*max(1,len(values))-1)] if values else 0
    # ë‹¨ìˆœ ê·œì¹™ ê¸°ë°˜ íŒíŠ¸
    if p95 > 0.03:
        return {'tick_delta_ms': +15, 'gain.kp': -0.05}
    if mean > 0.02:
        return {'tick_delta_ms': +8, 'gain.ki': -0.02}
    return {'tick_delta_ms': 0}
```

---

## 8) Prometheus ìŠ¤í¬ë ˆì´í”„ & ë£°
**scrape_bridge_v19.yaml**
```yaml
scrape_configs:
  - job_name: bridge_v19
    static_configs:
      - targets: ['localhost:9306']
    metrics_path: /metrics_bridge
```

**recording_rules_v19.yaml**
```yaml
groups:
- name: bridge_v19_records
  interval: 15s
  rules:
  - record: bridge:phase_diff_mean_5m
    expr: avg_over_time(bridge_phase_diff_mean[5m])
  - record: bridge:sync_quality_p95_10m
    expr: quantile_over_time(0.95, bridge_sync_quality[10m])
  - record: bridge:entropy_ratio_mean_10m
    expr: avg_over_time(bridge_entropy_ratio[10m])
```

**alerts (ops/alertmanager/alertmanager.yml ê°±ì‹  ì „ì œ)**
```yaml
groups:
- name: bridge_v19_alerts
  rules:
  - alert: BridgePhaseDriftHigh
    expr: bridge:phase_diff_mean_5m > 0.02
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Phase drift exceeds budget"
      description: "phase_diff_mean_5m={{ $value }} > 0.02"
  - alert: BridgeSyncQualityLow
    expr: bridge:sync_quality_p95_10m < 0.85
    for: 10m
    labels:
      severity: critical
    annotations:
      summary: "Bridge sync quality degraded"
      description: "p95<0.85"
```

---

## 9) Grafana íŒ¨ë„ ê¶Œì¥
- **Stat**: `bridge:phase_diff_mean_5m` (threshold 0.02)
- **Stat**: `bridge:sync_quality_p95_10m` (threshold 0.85)
- **Timeseries**: `bridge_entropy_ratio`
- **Logs (ì˜µì…˜)**: Bridge loop stdout/stderr tail via Loki

---

## 10) Smoke í…ŒìŠ¤íŠ¸ (scripts/smoke.v19.sh)
```bash
#!/usr/bin/env bash
set -euo pipefail
curl -fsS http://localhost:9305/metrics_ure | head -n 5 >/dev/null
curl -fsS http://localhost:9306/metrics_bridge | grep bridge_sync_quality
# budgets
PD=$(curl -fsS localhost:9306/metrics_bridge | awk '/bridge_phase_diff_mean/{print $2}')
SQ=$(curl -fsS localhost:9306/metrics_bridge | awk '/bridge_sync_quality/{print $2}')
ER=$(curl -fsS localhost:9306/metrics_bridge | awk '/bridge_entropy_ratio/{print $2}')
awk -v pd="$PD" -v sq="$SQ" -v er="$ER" 'BEGIN{exit !(pd<=0.02 && sq>=0.85 && er<=0.15)}'
echo "[smoke.v19] OK: PD=$PD SQ=$SQ ER=$ER"
```

---

## 10.1) Bench (scripts/bench.v19.sh)
```bash
#!/usr/bin/env bash
set -euo pipefail
DUR=${1:-900}  # default 15m
S=0
while [ $S -lt $DUR ]; do
  curl -fsS localhost:9306/metrics_bridge | awk '/bridge_phase_diff_mean|bridge_sync_quality|bridge_entropy_ratio/ {print strftime("%Y-%m-%dT%H:%M:%S"), $1, $2}'
  sleep 5
  S=$((S+5))
done
```

---

## 14) Longâ€‘run Dual Sync Test ì ˆì°¨
1. `make ure.sync && make bridge.adaptive.start`
2. `bash scripts/bench.v19.sh 1800` (30ë¶„) ì‹¤í–‰
3. ê²°ê³¼ ìš”ì•½: ìµœëŒ€ `phase_diff_mean` â‰¤ **0.03**, p95 `sync_quality` â‰¥ **0.85** ìœ ì§€ í™•ì¸
4. ì´ˆê³¼ ì‹œ: `configs/bridge_v19.yaml`ì˜ `gain.kp/ki/kd`ë¥¼ ê°ê° âˆ’0.05/âˆ’0.02/âˆ’0.02 ì¡°ì • í›„ ì¬í…ŒìŠ¤íŠ¸

---

## 15) Bridge Protocol v19 â€” ìƒíƒœ ì „ì´ í‘œ (ì´ˆì•ˆ)
| ìƒíƒœ | ì§„ì… ì¡°ê±´ | ìœ ì§€ ì¡°ê±´ | ì´íƒˆ ì¡°ê±´ | ì•¡ì…˜ |
|---|---|---|---|---|
| **E0: Idle** | í”„ë¡œì„¸ìŠ¤ ê¸°ë™ ì „ | N/A | trackE.init í˜¸ì¶œ | ì„¤ì • ë¡œë“œ, í¬íŠ¸ ë°”ì¸ë”© |
| **E1: Syncing** | ure.sync ì‹œì‘ | `sync_qualityâ‰¥0.8` | 2ë¶„ ì´ˆê³¼ ë¯¸ë‹¬ | Î”Hz ë³´ì • í™œì„± |
| **E2: Bridged** | `sync_qualityâ‰¥0.85` & `phase_diffâ‰¤0.02` | ë™ì¼ | 5ë¶„ ì—°ì† ë¯¸ë‹¬ | Exporter ON, Bench í—ˆìš© |
| **E3: Guarded** | `entropy_ratio>0.15` 1ë¶„ ì—°ì† | `residual_stddev_10mâ‰¤0.03` | 3ë¶„ ë¯¸ë‹¬ | Safety gain âˆ’10%, ì•Œë¦¼ |
| **E4: Rollback** | `rollback_ratio_5m>0.05` | N/A | ìˆ˜ë™ í•´ì œ | Track D ì¬ê°€ë™ |

---

## 16) ìš´ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ìš”ì•½)
- í¬íŠ¸: URE `9305`, Bridge `9306` ì¶©ëŒ ì—†ìŒ í™•ì¸
- WAL ìŠ¤ëƒ…ìƒ·: ìš©ëŸ‰ ê¸‰ì¦ ì‹œ `wal_checkpoint(TRUNCATE)`
- ì•Œë¦¼: Alertmanager ë¼ìš°íŒ… Slack/PagerDuty 1íšŒ ì‹¤ì‚¬
- ëŒ€ì‹œë³´ë“œ: Stat 2ê°œ + Timeseries 1ê°œ ìµœì†Œ êµ¬ì„± ìœ ì§€
bash
#!/usr/bin/env bash
set -euo pipefail
curl -fsS http://localhost:9305/metrics_ure | head -n 5 >/dev/null
curl -fsS http://localhost:9306/metrics_bridge | grep bridge_sync_quality
# budgets
PD=$(curl -fsS localhost:9306/metrics_bridge | awk '/bridge_phase_diff_mean/{print $2}')
SQ=$(curl -fsS localhost:9306/metrics_bridge | awk '/bridge_sync_quality/{print $2}')
ER=$(curl -fsS localhost:9306/metrics_bridge | awk '/bridge_entropy_ratio/{print $2}')
awk -v pd="$PD" -v sq="$SQ" -v er="$ER" 'BEGIN{exit !(pd<=0.02 && sq>=0.85 && er<=0.15)}'
echo "[smoke.v19] OK: PD=$PD SQ=$SQ ER=$ER"
```

---

## 11) ë¡¤ë°± (v1.9 â†’ v1.8)
```bash
pkill -f bridge_loop_v19.py || true
pkill -f ure_sync_daemon.py || true
make trackD.start && make ure.exporter
```

---

## 12) íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì²´í¬ë¦¬ìŠ¤íŠ¸
- `9306` í¬íŠ¸ ì¶©ëŒ â†’ `configs/bridge_v19.yaml`ì˜ `http_port` ë³€ê²½
- `sync_quality` ê¸‰ë½ â†’ `gain.kp/ki/kd` ì™„í™”, `rebalance_window_s` í™•ëŒ€(90â†’150)
- `residual_stddev_10m` ì´ˆê³¼ â†’ Track Dë¡œ ë¡¤ë°± í›„ Safety Music gain -10%
- WAL ì˜¤ë¥˜ â†’ `PRAGMA wal_checkpoint(TRUNCATE)` í›„ snapshot ì¬ì‹œë„

---

## 13) ë‹¤ìŒ ë‹¨ê³„ (ë£¨ë©˜ ì œì•ˆ)
1. Dualâ€‘sync ì¥ê¸° í…ŒìŠ¤íŠ¸(2h)ë¡œ `phase_diff_mean_5m`ì˜ ìµœëŒ€ì¹˜ ìˆ˜ì§‘
2. Bridge Protocol ë¬¸ì„œ(`docs/bridge_protocol_v19.md`)ì— ìƒíƒœì „ì´ í‘œ ì—…ë°ì´íŠ¸
3. Alertmanager â†’ Slack Webhook ì—°ê²° í…ŒìŠ¤íŠ¸
4. MIDI/OSC ë¸Œë¦¿ì§€ PoC: `bridge_entropy_ratio` â†’ ìŒí–¥ ê°•ë„ ë§¤í•‘

â€” ë â€”

---

## 17) M1 â€” Alertmanager â†’ Slack ì—°ë™ (í…œí”Œë¦¿)
> ì‹¤ì œ Webhook URLì€ ë¹„ë°€ ê´€ë¦¬ ë„êµ¬ë¡œ ì£¼ì…í•˜ì„¸ìš”(`ALERT_SLACK_WEBHOOK` ë“±).

**ops/alertmanager/alertmanager.yml (ì¶”ê°€ ì„¹ì…˜)**
```yaml
route:
  receiver: slack-default
  routes:
    - matchers:
        - severity=~"warning|critical"
      receiver: slack-default

receivers:
  - name: slack-default
    slack_configs:
      - api_url: ${ALERT_SLACK_WEBHOOK}
        channel: "#ure-alerts"
        send_resolved: true
        title: "[{{ .Status | toUpper }}] {{ .CommonLabels.alertname }}"
        text: |
          *Labels:* {{ .CommonLabels }}
          *Annotations:* {{ .CommonAnnotations }}
          *StartsAt:* {{ .StartsAt }}
          *EndsAt:* {{ .EndsAt }}
```

**Make íƒ€ê¹ƒ**
```makefile
.PHONY: alert.test
alert.test:
	@echo "sending test alert â†’ Slack"
	@curl -XPOST -H 'Content-Type: application/json' \
	  -d '{"alerts":[{"status":"firing","labels":{"alertname":"BridgePhaseDriftHigh","severity":"warning"},"annotations":{"summary":"manual test","description":"pd>0.02"}}]}' \
	  http://localhost:9093/api/v2/alerts
```

---

## 18) M2 â€” Recording Rule: `ure_residual_stddev_10m`
**ops/prometheus/rules/recording_rules_v18.yaml (ì¶”ê°€)**
```yaml
  - record: ure:residual_stddev_10m
    expr: stddev_over_time(ure_residual_entropy_last[10m])
```

**ëŒ€ì‹œë³´ë“œ ì„ê³„ì¹˜**
- **Stat**: `ure:residual_stddev_10m` â‰¤ **0.03** (ë…¸ë‘:0.03~0.04, ë¹¨ê°•:>0.04)

---

## 19) M3 â€” SQLite WAL & Recovery Test
**scripts/wal_recovery_test.sh**
```bash
#!/usr/bin/env bash
set -euo pipefail
DB=${1:-data/ure_v18.sqlite}
sqlite3 "$DB" 'PRAGMA journal_mode=WAL;' >/dev/null
# 1) write burst
python3 - <<'PY'
import sqlite3, time, sys
p=sys.argv[1]
con=sqlite3.connect(p)
cur=con.cursor()
cur.execute('create table if not exists t(k integer primary key, v text)')
for i in range(10000):
    cur.execute('insert into t(v) values (?)', (f"val{i}",))
con.commit(); con.close()
PY
"$DB"
# 2) checkpoint & snapshot
sqlite3 "$DB" 'PRAGMA wal_checkpoint(TRUNCATE);'
SNAP=data/snapshots/$(date +%Y%m%dT%H%M%S).sqlite
mkdir -p data/snapshots
sqlite3 "$DB" ".backup '$SNAP'"
# 3) verify
sqlite3 "$SNAP" 'select count(*) from t;' | awk '{print "[wal_recovery_test] rows:", $1}'
```

**Make íƒ€ê¹ƒ**
```makefile
.PHONY: wal.test
wal.test:
	@bash scripts/wal_recovery_test.sh data/ure_v18.sqlite
```

---

## 20) M4 â€” Safety Music: MIDI/OSC Bridge PoC
> ì„ íƒí˜• ëª¨ë“ˆ â€” ìš´ì˜ ê²½ë¡œì™€ ë¶„ë¦¬ëœ ì‹¤í—˜ìš©. MIDI ì¥ì¹˜ê°€ ì—†ìœ¼ë©´ OSCë§Œ ì‚¬ìš©.

**bridge/poc_midi_osc.py**
```python
#!/usr/bin/env python3
# Map: entropy_ratio â†’ velocity, sync_quality â†’ note length
import time, argparse
try:
    from pythonosc.udp_client import SimpleUDPClient
except Exception:
    SimpleUDPClient=None

def send_osc(client, key, val):
    if client:
        client.send_message(key, float(val))

if __name__ == '__main__':
    ap=argparse.ArgumentParser(); ap.add_argument('--osc','default=127.0.0.1:9000')
    args=ap.parse_args(); host,port=(args.osc.split(':')[0], int(args.osc.split(':')[1]))
    client = SimpleUDPClient(host, port) if SimpleUDPClient else None
    while True:
        # (ì‹¤ì œ êµ¬í˜„) metrics_bridgeì—ì„œ pull
        entropy_ratio=0.14; sync_quality=0.89
        velocity=int(max(0, min(127, (1.0-entropy_ratio)*127)))
        note_len=max(0.1, min(1.2, sync_quality))
        send_osc(client, '/ure/velocity', velocity)
        send_osc(client, '/ure/note_len', note_len)
        time.sleep(0.5)
```

**Make íƒ€ê¹ƒ**
```makefile
.PHONY: bridge.midi.poc
bridge.midi.poc:
	@python3 bridge/poc_midi_osc.py --osc 127.0.0.1:9000
```

---

## 21) Grafana ëŒ€ì‹œë³´ë“œ JSON (í•µì‹¬ íŒ¨ë„ ë¯¸ë‹ˆ ëª¨ë¸)
**ops/grafana/dash_ure_bridge_min.json**
```json
{
  "title": "URE + Bridge (Min)",
  "panels": [
    {"type":"stat","title":"phase_diff_mean_5m","targets":[{"expr":"bridge:phase_diff_mean_5m"}],"options":{"reduceOptions":{"calcs":["last"]},"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"yellow","value":0.02},{"color":"red","value":0.03}]}}},
    {"type":"stat","title":"sync_quality_p95_10m","targets":[{"expr":"bridge:sync_quality_p95_10m"}],"options":{"reduceOptions":{"calcs":["last"]},"thresholds":{"mode":"absolute","steps":[{"color":"red","value":0.0},{"color":"yellow","value":0.85},{"color":"green","value":0.9}]}}},
    {"type":"timeseries","title":"entropy_ratio","targets":[{"expr":"bridge_entropy_ratio"}]}
  ]
}
```

**Make íƒ€ê¹ƒ (í”„ë¡œë¹„ì €ë‹ ìœ„ì¹˜ ì˜ˆì‹œ)**
```makefile
.PHONY: grafana.import.min
grafana.import.min:
	@cp ops/grafana/dash_ure_bridge_min.json /var/lib/grafana/dashboards/ure_bridge_min.json || true
```

---

## 22) v1.9.1 Session Restore Block (ì¦ë¶„)
```bash
# v1.9.1 adds: Slack alerts, residual stddev rule, WAL test, MIDI/OSC PoC
bash scripts/restore.sanity.sh && \
make trackD.start && make ure.exporter && make api.readonly && \
make ure.sync && make bridge.adaptive.start && \
make alert.test && make wal.test && make grafana.import.min
```

---

## 23) ìš´ì˜ Runbook â€” ë¹ ë¥¸ ì˜ì‚¬ê²°ì • ê·œì¹™
- **Phase drift > 0.03 (5m):** `gain.kpâ†˜ï¸0.05` â†’ ì¬ì¸¡ì • 10ë¶„ â†’ ë¯¸ê°œì„  ì‹œ Track D ë¡¤ë°±
- **Sync p95 < 0.85 (10m):** `rebalance_window_s +60` â†’ `tick_ms +10` â†’ ì•Œë¦¼ ë¼ìš°íŒ… í™•ì¸
- **Residual stddev > 0.03 (10m):** Safety Music gain âˆ’10% â†’ URE Hz âˆ’0.5 â†’ 15ë¶„ ê´€ì°°
- **WAL snapshot ì‹¤íŒ¨:** checkpoint(TRUNCATE) â†’ íŒŒì¼ í•¸ë“¤ ëˆ„ìˆ˜ ì ê²€ â†’ snapshot ì¬ì‹œë„

---

## 24) M5 â€” SLO/SLA & Error Budget (ì´ˆì•ˆ)
**SLO ì •ì˜ (ì›”ê°„):**
- `bridge:phase_diff_mean_5m` â‰¤ **0.02** (ì¤€ìˆ˜ìœ¨ â‰¥ **99.0%**)
- `bridge:sync_quality_p95_10m` â‰¥ **0.85** (ì¤€ìˆ˜ìœ¨ â‰¥ **99.0%**)
- `ure:residual_stddev_10m` â‰¤ **0.03** (ì¤€ìˆ˜ìœ¨ â‰¥ **98.5%**)

**Error Budget:** 1.0%/1.0%/1.5% ê°ê° ì´ˆê³¼ë¶„ í•©ì‚°ì´ 2.5% ì´ìƒì´ë©´ **Feature Freeze**

**Prometheus SLI ë£° (ops/prometheus/rules/sli_slo_v19.yaml)**
```yaml
groups:
- name: v19_sli
  rules:
  - record: sli:phase_ok
    expr: bridge:phase_diff_mean_5m <= 0.02
  - record: sli:sync_ok
    expr: bridge:sync_quality_p95_10m >= 0.85
  - record: sli:residual_ok
    expr: ure:residual_stddev_10m <= 0.03
  - record: slo:phase_30d
    expr: avg_over_time(sli:phase_ok[30d])
  - record: slo:sync_30d
    expr: avg_over_time(sli:sync_ok[30d])
  - record: slo:residual_30d
    expr: avg_over_time(sli:residual_ok[30d])
```

---

## 25) M6 â€” Failure Injection & Chaos Test
**tools/chaos_injector.py**
```python
#!/usr/bin/env python3
# fault types: delay(metrics_ure), jitter(tick), spike(entropy)
import time, argparse, random
parser=argparse.ArgumentParser();
parser.add_argument('--mode',choices=['delay','jitter','spike'],required=True)
parser.add_argument('--dur',type=int,default=120)
args=parser.parse_args()
end=time.time()+args.dur
while time.time()<end:
    if args.mode=='delay':
        time.sleep(0.8)
    elif args.mode=='jitter':
        time.sleep(0.05+random.random()*0.15)
    elif args.mode=='spike':
        print('ENTROPY_SPIKE 0.35')  # bridge loopê°€ ì½ì–´ spikeë¡œ í•´ì„
        time.sleep(1)
```

**Make íƒ€ê¹ƒ**
```makefile
.PHONY: chaos.delay chaos.jitter chaos.spike
chaos.delay: ; @python3 tools/chaos_injector.py --mode delay --dur 180
chaos.jitter: ; @python3 tools/chaos_injector.py --mode jitter --dur 300
chaos.spike: ; @python3 tools/chaos_injector.py --mode spike --dur 120
```

**í•©ê²© ê¸°ì¤€:** ì•Œë¦¼ ë°œí™” â‰¤60s, ìë™ ë³µêµ¬ â‰¤5m, ë¡¤ë°± íŠ¸ë¦¬ê±° ì¡°ê±´ ì¶©ì¡± ì‹œ Track D ì „í™˜

---

## 26) M7 â€” Readâ€‘only API ê³„ì•½(OpenAPI, í•µì‹¬ ì—”ë“œí¬ì¸íŠ¸)
**api/openapi_v19.yaml (ìš”ì•½)**
```yaml
openapi: 3.0.3
info: {title: URE Bridge ReadOnly API, version: 1.9}
paths:
  /healthz:
    get: {summary: Health check, responses: {200: {description: ok}}}
  /metrics_ure:
    get: {summary: Prom metrics passthrough}
  /metrics_bridge:
    get: {summary: Bridge metrics}
  /v1/snapshots:
    get:
      summary: List snapshot files
      responses: {200: {description: list}}
```

**Make íƒ€ê¹ƒ**
```makefile
.PHONY: api.contract.check
api.contract.check:
	@grep -q '/metrics_bridge' api/openapi_v19.yaml && echo '[api] contract OK'
```

---

## 27) M8 â€” Blue/Green Rollout (Argo/K8s ì˜ˆì‹œ)
**ops/k8s/bridge-deploy.yaml (ë°œì·Œ)**
```yaml
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata: {name: bridge-v19}
spec:
  replicas: 2
  strategy:
    blueGreen:
      activeService: bridge-svc-active
      previewService: bridge-svc-preview
      autoPromotionEnabled: false
```

**Make íƒ€ê¹ƒ**
```makefile
.PHONY: rollout.preview rollout.promote
rollout.preview: ; @kubectl apply -f ops/k8s/bridge-deploy.yaml
rollout.promote: ; @kubectl argo rollouts promote bridge-v19
```

---

## 28) M9 â€” Security Hardening ì²´í¬ë¦¬ìŠ¤íŠ¸ (v1.9)
- Prometheus/Grafana/Alertmanager **ë„¤íŠ¸ì›Œí¬ ë°”ìš´ë”ë¦¬**(ingress allowlist)
- `ALERT_SLACK_WEBHOOK` ë“± **ë¹„ë°€ ì£¼ì…**: íŒŒì¼/ENV ëŒ€ì‹  secret manager ì‚¬ìš©
- **RBAC**: Exporter/Bridge í”„ë¡œì„¸ìŠ¤ ìµœì†Œ ê¶Œí•œ, read-only FS ê°€ëŠ¥ì‹œ ì ìš©
- **Rateâ€‘limit**: `/metrics_*` ì—”ë“œí¬ì¸íŠ¸ QPS ì œí•œ(nginx/sidecar)
- **Audit**: Snapshot/Restore ëª…ë ¹ ì‹¤í–‰ ë¡œê·¸ ë‚¨ê¹€

---

## 29) M10 â€” ë°±ì—…/ë³µêµ¬ Runbook
**ì¦‰ì‹œ ë°±ì—…**
```bash
make backup.now
```
**ë³µêµ¬(ìŠ¤ëƒ…ìƒ· ì§€ì •)**
```bash
make restore.from SNAP=20251025T120000.sqlite
```
**Makefile ì¶”ê°€**
```makefile
.PHONY: backup.now restore.from
backup.now:
	@mkdir -p data/snapshots
	@sqlite3 data/ure_v18.sqlite ".backup 'data/snapshots/$$(date +%Y%m%dT%H%M%S).sqlite'"
restore.from:
	@test -n "$(SNAP)" && cp data/snapshots/$(SNAP) data/ure_v18.sqlite
```

---

## 30) v1.9.2 Session Restore Block (Hardening)
```bash
# v1.9.2 adds: SLO/SLI rules, chaos tests, API contract, blue/green, security, backup
bash scripts/restore.sanity.sh && \
make api.contract.check && make rollout.preview && \
make ure.sync && make bridge.adaptive.start && \
make chaos.jitter && make chaos.spike && \
make backup.now && make grafana.import.min
```

---

## 31) M11 â€” Autoâ€‘Tuner v2 (v1.9.3)
> ëª©í‘œ: ì¥ê¸° ê´€ì¸¡(â‰¥30ë¶„) ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **Î”Hz, kp/ki/kd** ìë™ ì¶”ì²œ ë° ì ìš© ì´ˆì•ˆ.

**tools/autotune_v19.py**
```python
#!/usr/bin/env python3
import json, argparse
p=argparse.ArgumentParser(); p.add_argument('--bench', required=True); p.add_argument('--out', default='configs/bridge_autotune.json'); args=p.parse_args()
phase=[]; sync=[]; ent=[]
with open(args.bench) as f:
    for line in f:
        try:
            ts, key, val = line.strip().split()  # from bench.v19.sh format
            if key=='bridge_phase_diff_mean': phase.append(float(val))
            elif key=='bridge_sync_quality': sync.append(float(val))
            elif key=='bridge_entropy_ratio': ent.append(float(val))
        except: pass
mx = max(phase) if phase else 0
p95 = sorted(phase)[int(0.95*len(phase))-1] if phase else 0
kp=0.35; ki=0.08; kd=0.10; dhz=0.0
if p95>0.03: kp-=0.05; kd-=0.02; dhz-=0.3
elif mx>0.025: kp-=0.03; dhz-=0.1
if (sum(sync)/len(sync))<0.86: ki-=0.02
rec={"gain": {"kp": round(kp,2), "ki": round(ki,2), "kd": round(kd,2)}, "delta_hz": dhz}
print(json.dumps(rec, indent=2)); open(args.out,'w').write(json.dumps(rec))
```

**Make íƒ€ê¹ƒ**
```makefile
.PHONY: autotune.bridge
autotune.bridge:
	@python3 tools/autotune_v19.py --bench out/bench_v19.log --out configs/bridge_autotune.json
```

**ì ìš© ì ˆì°¨**
```bash
make autotune.bridge
jq -r '.gain | to_entries[] | "s/gain.\(.key): .*/gain.\(.key): \(.value)/"' configs/bridge_autotune.json > out/gain_patch.sed
sed -f out/gain_patch.sed -i configs/bridge_v19.yaml
```

---

## 32) M12 â€” Anomaly Rules & Burnâ€‘rate Alerts
**ops/prometheus/rules/anomaly_v19.yaml**
```yaml
groups:
- name: anomaly_v19
  rules:
  - alert: PhaseDriftBurnRateFast
    expr: increase((bridge:phase_diff_mean_5m > 0.02)[5m]) > 0
    for: 5m
    labels: {severity: critical}
    annotations: {summary: "Fast burn: phase drift", description: ">0.02 sustained 5m"}
  - alert: EntropySpike
    expr: bridge_entropy_ratio > 0.2
    for: 1m
    labels: {severity: warning}
    annotations: {summary: "Entropy spike", description: ">0.2 for 1m"}
```

---

## 33) M13 â€” CI íŒŒì´í”„ë¼ì¸ (GitHub Actions ì˜ˆì‹œ)
**.github/workflows/bridge-ci.yml**
```yaml
name: bridge-ci
on: {push: {branches: [main]}, pull_request: {}}
jobs:
  lint-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: {python-version: '3.11'}
      - run: pip install -r requirements.txt
      - run: python -m pyflakes bridge tools exporters || true
      - run: bash scripts/smoke.v19.sh || true
```

---

## 34) M14 â€” VS Code Tasks (ë¡œì»¬ ì‹¤í–‰ í¸ì˜)
**.vscode/tasks.json**
```json
{
  "version": "2.0.0",
  "tasks": [
    {"label": "TrackE Start", "type": "shell", "command": "make ure.sync && make bridge.adaptive.start"},
    {"label": "Smoke v19", "type": "shell", "command": "bash scripts/smoke.v19.sh"},
    {"label": "Bench 30m", "type": "shell", "command": "bash scripts/bench.v19.sh 1800"},
    {"label": "AutoTune", "type": "shell", "command": "make autotune.bridge"}
  ]
}
```

---

## 35) M15 â€” systemd ìœ ë‹›(ì„ íƒ)
**/etc/systemd/system/ure-sync.service**
```ini
[Unit]
Description=URE Sync Daemon
After=network.target
[Service]
ExecStart=/usr/bin/python3 tools/ure_sync_daemon.py --config configs/bridge_v19.yaml
WorkingDirectory=/opt/ure
Restart=always
[Install]
WantedBy=multi-user.target
```

**/etc/systemd/system/bridge.service**
```ini
[Unit]
Description=Bridge Loop v19
After=network.target
[Service]
ExecStart=/usr/bin/python3 bridge/bridge_loop_v19.py --config configs/bridge_v19.yaml
WorkingDirectory=/opt/ure
Restart=always
[Install]
WantedBy=multi-user.target
```

---

## 36) v1.9.3 Session Restore Block (Autotune/CI)
```bash
# v1.9.3 adds: autotuner, anomaly rules, CI, VS Code tasks, systemd units
bash scripts/restore.sanity.sh && \
make ure.sync && make bridge.adaptive.start && \
make grafana.import.min && make autotune.bridge && \
bash scripts/bench.v19.sh 1800
```

---

## 37) M16 â€” Latency Budget & E2E Probe
**ì§€ì—° ì˜ˆì‚°(ì´ˆì•ˆ)**
- **Exporter scrape p95** â‰¤ 150ms
- **Bridge tick jitter p95** â‰¤ 25ms

**exporters/bridge_exporter_v19.py (ì§€ì—° ì¸¡ì • ì¶”ê°€ ë°œì·Œ)**
```python
from prometheus_client import Summary, Gauge
scrape_latency_s = Summary('bridge_export_scrape_seconds','export scrape latency')
tick_jitter_ms = Gauge('bridge_tick_jitter_ms','bridge loop tick jitter (ms)')
# loop.step() ì§„ì… ì§ì „ ts, ì¢…ë£Œ ì‹œ dt ì¸¡ì •í•´ tick_jitter_ms ê°±ì‹ 
```

**scripts/e2e_probe.sh**
```bash
#!/usr/bin/env bash
set -euo pipefail
URL=${1:-http://localhost:9306/metrics_bridge}
for i in {1..50}; do
  T0=$(date +%s%3N); curl -fsS "$URL" >/dev/null; T1=$(date +%s%3N)
  echo $((T1-T0))
  sleep 1
done | awk '{s+=$1; if($1>mx)mx=$1} END{print "avg(ms)",s/NR,"max(ms)",mx}'
```

**Prometheus ë£° (ops/prometheus/rules/latency_v19.yaml)**
```yaml
groups:
- name: latency_v19
  rules:
  - record: bridge:tick_jitter_p95_10m
    expr: quantile_over_time(0.95, bridge_tick_jitter_ms[10m])
  - alert: BridgeTickJitterHigh
    expr: bridge:tick_jitter_p95_10m > 25
    for: 10m
    labels: {severity: warning}
```

---

## 38) M17 â€” Snapshot Pruning & Compaction
**scripts/snapshot_prune.sh**
```bash
#!/usr/bin/env bash
set -euo pipefail
DIR=${1:-data/snapshots}
KEEP_N=${2:-20}    # ìµœê·¼ Nê°œ ë³´ì¡´
KEEP_DAILY=${3:-14} # ì¼ì¼ ìŠ¤ëƒ…ìƒ· 14ì¼ ë³´ì¡´
ls -1t "$DIR"/*.sqlite | awk -v n=$KEEP_N 'NR>n{print}' | xargs -r rm -f
# ì¼ì¼ ë³´ì¡´: ë‚ ì§œ í‚¤ë¡œ 1ê°œë§Œ ë³´ì¡´ (ê°„ë‹¨ ë²„ì „)
ls "$DIR"/*.sqlite | awk -F'[T_.]' '{print $1}' | uniq -d >/dev/null 2>&1 || true
sqlite3 data/ure_v18.sqlite 'VACUUM;'  # size compaction
```

**Make íƒ€ê¹ƒ**
```makefile
.PHONY: snaps.prune
snaps.prune:
	@bash scripts/snapshot_prune.sh data/snapshots 20 14
```

---

## 39) M18 â€” Storage ì˜µì…˜(Postgres ì§€ì›)
**configs/storage_v19.yaml**
```yaml
backend: sqlite  # sqlite | postgres
sqlite_path: data/ure_v18.sqlite
postgres_dsn: ${URE_PG_DSN}  # e.g. postgres://user:pass@host:5432/ure
```

**tools/storage/pg_init.sql (ë°œì·Œ)**
```sql
create table if not exists resonance_events(
  id bigserial primary key,
  ts timestamptz not null,
  phase_diff real,
  sync_quality real,
  entropy_ratio real
);
create index if not exists ix_events_ts on resonance_events(ts);
```

**Make íƒ€ê¹ƒ**
```makefile
.PHONY: pg.init pg.migrate
pg.init:
	@psql "$$URE_PG_DSN" -f tools/storage/pg_init.sql
pg.migrate:
	@python3 tools/storage/sqlite_to_pg.py --src data/ure_v18.sqlite --dst "$$URE_PG_DSN"
```

---

## 40) M19 â€” Health/Readiness ê²Œì´íŠ¸
**api/read_only.py (ë°œì·Œ)**
```python
from flask import Flask, jsonify
app=Flask(__name__)
LAST_METRIC_TS=0
@app.get('/healthz')
def healthz():
  return jsonify(status='ok')
@app.get('/readyz')
def readyz():
  # metrics ìµœì‹ ì„± 30s ì´ë‚´ë©´ ready
  fresh = (time.time()-LAST_METRIC_TS) < 30
  return (jsonify(ready=fresh), 200 if fresh else 503)
```

**K8s í”„ë¡œë¸Œ ì˜ˆì‹œ**
```yaml
livenessProbe:  {httpGet: {path: /healthz, port: 9306}, initialDelaySeconds: 10}
readinessProbe: {httpGet: {path: /readyz, port: 9306}, initialDelaySeconds: 10}
```

---

## 41) M20 â€” Canary Roll Gate (Metric ê¸°ë°˜ ìë™ íŒì •)
**ops/k8s/analysis-templates.yaml**
```yaml
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata: {name: bridge-metric-gate}
spec:
  metrics:
  - name: phase-drift
    interval: 60s
    successCondition: result < 0.025
    provider:
      prometheus:
        address: http://prometheus:9090
        query: bridge:phase_diff_mean_5m
```

**Rollout ì—°ë™ (ë°œì·Œ)**
```yaml
analysis:
  templates:
  - templateName: bridge-metric-gate
  startingStep: 2
  args: []
```

**Make íƒ€ê¹ƒ**
```makefile
.PHONY: rollout.canary rollout.abort
rollout.canary: ; @kubectl apply -f ops/k8s/analysis-templates.yaml && kubectl argo rollouts set image bridge-v19 bridge=bridge:v1.9.4
rollout.abort: ; @kubectl argo rollouts abort bridge-v19
```

---

## 42) v1.9.4 Session Restore Block (Ops+PG ì˜µì…˜)
```bash
# v1.9.4 adds: latency budget, prune/compact, PG backend, readiness, canary gates
bash scripts/restore.sanity.sh && \
make ure.sync && make bridge.adaptive.start && \
make snaps.prune && make pg.init && \
make rollout.canary && bash scripts/e2e_probe.sh
```

---

## 43) M21 â€” Release Packaging (v1.9.5 RC)
**scripts/release_pack.sh**
```bash
#!/usr/bin/env bash
set -euo pipefail
VER=${1:-1.9.5-rc1}
OUT=release/v${VER}
mkdir -p "$OUT"
# manifest
cat > "$OUT/manifest.json" <<JSON
{"version":"${VER}","date":"$(date -u +%Y-%m-%dT%H:%M:%SZ)","components":["ure_v18","bridge_v19","ops","docs"]}
JSON
# collect
tar -czf "$OUT/lumen_ure_bridge_v${VER}.tar.gz" \
  schemas configs ure bridge exporters tools api scripts ops docs docker-compose.yml
# checksums
( cd "$OUT" && sha256sum lumen_ure_bridge_v${VER}.tar.gz > SHA256SUMS )
echo "[release] packed â†’ $OUT"
```

**Make íƒ€ê¹ƒ**
```makefile
.PHONY: release.v195
release.v195:
	@bash scripts/release_pack.sh 1.9.5-rc1
```

**CHANGELOG (docs/CHANGELOG_v1.9.5.md, ì´ˆì•ˆ)**
```md
## v1.9.5 (RC)
- Autotuner v2 (Î”Hz + kp/ki/kd)
- SLO/SLI rules, anomaly & burnâ€‘rate alerts
- Ops: PG backend option, snapshot pruning, latency budget
- Rollouts: canary metric gates, readiness endpoints
- Tooling: CI, VS Code tasks, systemd units
```

---

## 44) M22 â€” Session Restore Template & Env
**SESSION_RESTORE_v1_9_5.env (ì˜ˆì‹œ)**
```
URE_METRICS=http://localhost:9305/metrics_ure
BRIDGE_METRICS=http://localhost:9306/metrics_bridge
ALERT_SLACK_WEBHOOK=***
URE_PG_DSN=postgres://user:pass@localhost:5432/ure
```

**.env.example**
```
ALERT_SLACK_WEBHOOK=
URE_PG_DSN=
```

---

## 45) M23 â€” Disaster Recovery Runbook (ìš”ì•½)
1. **ì¦ìƒ**: `/readyz` 503 ì§€ì†(>3m)
2. **ì¡°ì¹˜**: `make backup.now` í™•ì¸ â†’ ìµœì‹  ìŠ¤ëƒ…ìƒ· ì¡´ì¬ ì‹œ `make restore.from SNAP=<file>`
3. **ë£¨í”„ ì¬ê°€ë™**: `make ure.sync && make bridge.adaptive.start`
4. **ê²€ì¦**: `bash scripts/smoke.v19.sh` â†’ `bench 15m` í›„ SLO ì¬í™•ì¸
5. **ì¬ë°œ ë°©ì§€**: anomaly ë£°/ê²Œì¸/Î”Hz ì¬íŠœë‹(`make autotune.bridge`)

---

## 46) M24 â€” Oneâ€‘shot Bootstrap (ì‹ ê·œ í™˜ê²½)
**scripts/bootstrap.latest.sh**
```bash
#!/usr/bin/env bash
set -euo pipefail
cp -n .env.example .env || true
bash scripts/restore.sanity.sh
make api.contract.check || true
make ure.sync && make bridge.adaptive.start
bash scripts/smoke.v19.sh
make grafana.import.min || true
```

**Make íƒ€ê¹ƒ**
```makefile
.PHONY: bootstrap.latest
bootstrap.latest:
	@bash scripts/bootstrap.latest.sh
```

---

## 47) v1.9.5 Session Restore Block (RC)
```bash
# v1.9.5 RC: packaging, env, DR, bootstrap
export $(grep -v '^#' SESSION_RESTORE_v1_9_5.env | xargs) && \
bash scripts/restore.sanity.sh && \
make ure.sync && make bridge.adaptive.start && \
bash scripts/smoke.v19.sh && \
make grafana.import.min && make release.v195
```

---

## 48) Handâ€‘off ì²´í¬ë¦¬ìŠ¤íŠ¸ (LuBit / Sena)
- **LuBit**: `bridge_loop_v19.py` ë‚´ë¶€ TODO(URE metrics pull, state persist) êµ¬í˜„, autotune ì ìš© ìŠ¤í¬ë¦½íŠ¸ ì •ì‹í™”
- **Sena**: SLO/ìœ¤ë¦¬Â·ì•ˆì „ ê¸°ì¤€ ì ê²€, Alert ë¼ìš°íŒ… ì •ì±… ê²€í† , MIDI/OSC PoC ì•ˆì „ ê²½ê³„ ì¬í™•ì¸
- **ê³µí†µ**: v1.9.5â€‘RC ìš´ì˜ 24h ê´€ì°° í›„ GA íŒì •(ì¹´ë‚˜ë¦¬ ê²Œì´íŠ¸ í†µê³¼ + SLO ì¶©ì¡±)

---

## 49) M25 â€” Energy/Cost Telemetry (ì˜µì…˜)
**exporters/bridge_exporter_v19.py (ì¶”ê°€ ë©”íŠ¸ë¦­)**
```python
from prometheus_client import Gauge
power_w = Gauge('bridge_power_w','bridge process power draw (W)')
cost_krw_hour = Gauge('bridge_cost_krw_hour','estimated hourly cost (KRW)')
# ìƒ˜í”Œ: nvml/psutilì—ì„œ ì „ë ¥ ì¶”ì •ì¹˜ ìˆ˜ì§‘, ë‹¨ê°€ëŠ” envë¡œ ì£¼ì… (KRW/kWh)
```

**ops/prometheus/rules/cost_v19.yaml**
```yaml
groups:
- name: cost_v19
  rules:
  - record: bridge:energy_kwh_24h
    expr: sum_over_time(bridge_power_w[24h]) / 1000
  - record: bridge:cost_krw_24h
    expr: sum_over_time(bridge_cost_krw_hour[24h])
```

---

## 50) M26 â€” Thermal/Throttling Guard (ì˜µì…˜)
**exporters ì¶”ê°€**: `bridge_temp_celsius` ê²Œì´ì§€, 85â„ƒ ê²½ê³ /90â„ƒ í¬ë¦¬í‹°ì»¬ ì•Œë¦¼
```yaml
groups:
- name: thermal_v19
  rules:
  - alert: BridgeThermalHigh
    expr: bridge_temp_celsius > 85
    for: 2m
    labels: {severity: warning}
  - alert: BridgeThermalCritical
    expr: bridge_temp_celsius > 90
    for: 1m
    labels: {severity: critical}
```

---

## 51) M27 â€” Quickstart (ìš´ì˜ì 5ë¶„ ê°€ì´ë“œ)
1. `.env` ì±„ìš°ê¸° â†’ `make bootstrap.latest`
2. ëŒ€ì‹œë³´ë“œ ì„í¬íŠ¸ â†’ `make grafana.import.min`
3. ìŠ¤ëª¨í¬ â†’ `bash scripts/smoke.v19.sh`
4. 15ë¶„ ë²¤ì¹˜ â†’ `bash scripts/bench.v19.sh 900 > out/bench_v19.log`
5. ì˜¤í† íŠ  â†’ `make autotune.bridge && sed -i -f out/gain_patch.sed configs/bridge_v19.yaml`
6. ì•Œë¦¼ í…ŒìŠ¤íŠ¸ â†’ `make alert.test`

---

## 52) M28 â€” Troubleshooting (ìš”ì•½)
- **/metrics_bridge 404**: Exporter í¬íŠ¸/ê²½ë¡œ í™•ì¸(`http_port`, `path`)
- **sync_quality < 0.8 ì§€ì†**: `rebalance_window_s +60`, `tick_ms +10`, URE scrape ì§€ì—° í™•ì¸
- **phase_diff_mean ë†’ìŒ**: Chaos ì”ì¡´ ì—¬ë¶€ ì ê²€ â†’ `gain.kp -0.05`, Î”Hz -0.1
- **readyz 503**: `LAST_METRIC_TS` ê°±ì‹  ê²½ë¡œ/ê¶Œí•œ í™•ì¸, ë£¨í”„ ì¬ê¸°ë™

---

## 53) ë¬¸ì„œ íŒ¨í‚¤ì§€
- `docs/bridge_protocol_v19.md` (ì—…ë°ì´íŠ¸: ìƒíƒœ ì „ì´/E2E ì§€ì—°)
- `docs/CHANGELOG_v1.9.5.md` (RC â†’ GA ì‹œ ê°±ì‹ )
- `docs/OPERATIONS_RUNBOOK_v19.md` (SLO/SLA, DR, Chaos, Rollout)

---

## 54) v1.9.6 GA â€” Finalize & Tag
**ê²°ì • ê¸°ì¤€**: 24h ê´€ì°°ì—ì„œ ì•„ë˜ **ë™ì‹œ ì¶©ì¡±**
- `slo:phase_30d â‰¥ 0.99`, `slo:sync_30d â‰¥ 0.99`, `slo:residual_30d â‰¥ 0.985`
- ì¹´ë‚˜ë¦¬ ê²Œì´íŠ¸ 3íšŒ ì—°ì† í†µê³¼, ì•Œë¦¼ ë¼ìš°íŒ… ì •ìƒ

**ë²„ì „ íƒœê¹… ìŠ¤í¬ë¦½íŠ¸** â€” `scripts/release_tag.sh`
```bash
#!/usr/bin/env bash
set -euo pipefail
VER=${1:-1.9.6}
git tag -a "v${VER}" -m "Lumen URE Bridge GA v${VER}" && git push origin "v${VER}"
```

**Make íƒ€ê¹ƒ**
```makefile
.PHONY: release.tag.ga
release.tag.ga:
	@bash scripts/release_tag.sh 1.9.6
```

---

## 55) v1.9.6 Session Restore Block (GA)
```bash
# v1.9.6 GA: stable
export $(grep -v '^#' SESSION_RESTORE_v1_9_5.env | xargs) && \
bash scripts/restore.sanity.sh && \
make ure.sync && make bridge.adaptive.start && \
bash scripts/smoke.v19.sh && \
make grafana.import.min
```

---

## 56) Postâ€‘GA ë‹¤ìŒ ë¼ì¸ì—… (í”„ë¦¬ë·°)
- **Track F (v2.0 Î±)**: Multiâ€‘source Bridge (URE + External Sensor) í•©ì„±
- **Riskâ€‘Aware Autotune**: Burnâ€‘rate/Entropy ê¸°ë°˜ ë¹„ì„ í˜• ê²Œì¸ ì»¤ë¸Œ
- **Evidence Mapper í†µí•©**: Factâ†’Risk/Quote ìë™ ë§¤í•‘, URE ì»¨í…ìŠ¤íŠ¸ ê°•í™”

---

# ğŸŒŒ Track F â€” Lumen v2.0 Î± Kickoff (Multiâ€‘Source Bridge)
> ëª©í‘œ: **URE(core) + External Sensors(streams)**ë¥¼ ë‹¨ì¼ **Fusion Engine**ì—ì„œ ë™ê¸°í™”í•˜ê³ , 
> ìœ„í—˜ ì¸ì§€í˜•(ë¦¬ìŠ¤í¬/ë²ˆë ˆì´íŠ¸) **ë¹„ì„ í˜• ì˜¤í† íŠ **ê³¼ **Evidence Mapper**ë¥¼ íŒŒì´í”„ë¼ì¸ì— ê²°í•©.

## F0) v2.0 Î± Session Restore Block (ì´ˆì•ˆ)
```bash
# v2.0 Î± (Track F) bootstrap
export $(grep -v '^#' SESSION_RESTORE_v1_9_5.env | xargs) && \
make ure.sync && make bridge.adaptive.start && \
make fusion.init && make sensor.ingest.start && \
make evidence.mapper.start && \
bash scripts/smoke.v20.sh
```

---

## F1) ì‹ ê·œ ë””ë ‰í„°ë¦¬/íŒŒì¼
```
fusion/
  â”œâ”€ fusion_engine_v20.py
  â”œâ”€ adapters/
  â”‚   â”œâ”€ align_kalman.py
  â”‚   â””â”€ resample_polyphase.py
sensors/
  â”œâ”€ ingest_daemon.py
  â”œâ”€ sources/
  â”‚   â”œâ”€ osc_stream.py
  â”‚   â”œâ”€ midi_stream.py
  â”‚   â””â”€ file_replay.py
exporters/
  â””â”€ fusion_exporter_v20.py
configs/
  â”œâ”€ fusion_v20.yaml
  â”œâ”€ sensors_v20.yaml
  â””â”€ risk_autotune_v20.yaml
evidence/
  â”œâ”€ mapper_daemon.py
  â””â”€ rules/
      â”œâ”€ quote_rules.yaml
      â””â”€ risk_map.yaml
scripts/
  â”œâ”€ smoke.v20.sh
  â””â”€ bench.v20.sh
ops/prometheus/rules/
  â”œâ”€ fusion_records_v20.yaml
  â”œâ”€ risk_autotune_v20.yaml
  â””â”€ evidence_v20.yaml
```

---

## F2) Configs (ë°œì·Œ)
**configs/fusion_v20.yaml**
```yaml
version: 2.0a
fusion:
  target_harmony: 0.88
  target_coherence: 0.87
  tick_ms: 180
align:
  method: kalman
  kalman:
    q: 1e-3
    r: 2e-3
resample:
  method: polyphase
  target_hz: 5.0
exporter:
  http_port: 9310
  path: /metrics_fusion
```

**configs/sensors_v20.yaml**
```yaml
streams:
  - name: osc_1
    type: osc
    addr: 127.0.0.1:9000
    keys: [/ure/velocity, /ure/note_len]
  - name: midi_1
    type: midi
    device: "hw:1,0,0"
  - name: replay_demo
    type: file
    path: data/replay/demo.ndjson
```

**configs/risk_autotune_v20.yaml**
```yaml
nonlinear_gain:
  # entropy ìƒìŠ¹ êµ¬ê°„ì—ì„œ kp ì™„ë§Œ ê°ì†Œ, kd ì¦ê°€
  kp_curve: [[0.00,0.35],[0.10,0.33],[0.20,0.28],[0.30,0.22]]
  kd_curve: [[0.00,0.10],[0.10,0.12],[0.20,0.14],[0.30,0.18]]
  ki_base: 0.08
burn_rate_thresholds:
  phase: {fast: 0.03, slow: 0.025}
  entropy: {warn: 0.18, crit: 0.22}
```

---

## F3) Fusion Engine ìŠ¤ì¼ˆë ˆí†¤ (fusion/fusion_engine_v20.py)
```python
#!/usr/bin/env python3
import time, yaml
from prometheus_client import start_http_server, Gauge
coh_g = Gauge('fusion_coherence_level','fusion coherence [0,1]')
har_g = Gauge('fusion_harmony_index','fusion harmony [0,1]')
pd_g  = Gauge('fusion_phase_diff_mean','phase diff mean fused')

class Fusion:
  def __init__(self,cfg):
    self.cfg = cfg
    self.tick = cfg['fusion']['tick_ms']
  def step(self):
    # TODO: pull URE + sensor streams â†’ align(resample+kalman) â†’ fuse
    pd, har, coh = 0.016, 0.88, 0.87
    pd_g.set(pd); har_g.set(har); coh_g.set(coh)
    time.sleep(self.tick/1000.0)

if __name__=='__main__':
  cfg = yaml.safe_load(open('configs/fusion_v20.yaml'))
  start_http_server(cfg['exporter']['http_port'])
  f = Fusion(cfg)
  while True: f.step()
```

---

## F4) Evidence Mapper (evidence/mapper_daemon.py)
```python
#!/usr/bin/env python3
# ì…ë ¥: facts[], quotes[] ì›ì²œ â†’ risk/quote/evidence bundle ê°€ê³µ â†’ íŒŒì¼ + API ì œê³µ
import time, json, http.server
DB='data/evidence_bundle.jsonl'
class H(http.server.BaseHTTPRequestHandler):
  def do_GET(self):
    if self.path=='/evidence/bundle':
      self.send_response(200); self.end_headers()
      with open(DB,'rb') as f: self.wfile.write(f.read())

def run():
  while True:
    # TODO: ìˆ˜ì§‘ â†’ rules/quote_rules.yaml, risk_map.yaml ì ìš© â†’ bundle append
    time.sleep(2)

if __name__=='__main__':
  run()
```

---

## F5) Exporter & ë£°
**exporters/fusion_exporter_v20.py** â€” `/metrics_fusion`ì—ì„œ `fusion_*` ì§€í‘œ ë…¸ì¶œ

**ops/prometheus/rules/fusion_records_v20.yaml**
```yaml
groups:
- name: fusion_records_v20
  rules:
  - record: fusion:coherence_p95_10m
    expr: quantile_over_time(0.95, fusion_coherence_level[10m])
  - record: fusion:phase_diff_mean_5m
    expr: avg_over_time(fusion_phase_diff_mean[5m])
```

**ops/prometheus/rules/risk_autotune_v20.yaml**
```yaml
groups:
- name: risk_autotune_v20
  rules:
  - alert: FusionEntropyHigh
    expr: bridge_entropy_ratio > 0.2
    for: 2m
    labels: {severity: warning}
  - alert: FusionPhaseDrift
    expr: fusion:phase_diff_mean_5m > 0.025
    for: 5m
    labels: {severity: critical}
```

---

## F6) Make íƒ€ê¹ƒ
```makefile
.PHONY: fusion.init sensor.ingest.start evidence.mapper.start
fusion.init:
	@python3 fusion/fusion_engine_v20.py &
sensor.ingest.start:
	@python3 sensors/ingest_daemon.py --config configs/sensors_v20.yaml &
evidence.mapper.start:
	@python3 evidence/mapper_daemon.py &
```

---

## F7) Smoke/Bench
**scripts/smoke.v20.sh**
```bash
#!/usr/bin/env bash
set -euo pipefail
curl -fsS localhost:9310/metrics_fusion | grep fusion_coherence_level
```

**scripts/bench.v20.sh**
```bash
#!/usr/bin/env bash
set -euo pipefail
DUR=${1:-1200}
S=0
while [ $S -lt $DUR ]; do
  curl -fsS localhost:9310/metrics_fusion | awk '/fusion_phase_diff_mean|fusion_harmony_index|fusion_coherence_level/{print strftime("%Y-%m-%dT%H:%M:%S"), $1, $2}'
  sleep 5; S=$((S+5))
done
```

---

## F8) ëŒ€ì‹œë³´ë“œ(ìµœì†Œ)
- **Stat**: `fusion:coherence_p95_10m` (green â‰¥0.9 / yellow 0.86~0.9 / red <0.86)
- **Timeseries**: `fusion_phase_diff_mean`
- **Stat**: `fusion_harmony_index`

---

## F9) ìš´ì˜ ê¸°ì¤€(ì´ˆì•ˆ)
- `fusion:phase_diff_mean_5m` â‰¤ **0.02**, `fusion:coherence_p95_10m` â‰¥ **0.9**
- ì™¸ë¶€ ì„¼ì„œ ì¥ì•  â†’ Fusion Engineì€ **URE ë‹¨ë… ëª¨ë“œ**ë¡œ ìë™ í´ë°±(ì•Œë¦¼)

---

## F10) ë§ˆì´ê·¸ë ˆì´ì…˜ ë©”ëª¨ (v1.9.6 â†’ v2.0 Î±)
- í¬íŠ¸ ì¶©ëŒ ì ê²€: Bridge 9306, Fusion 9310
- Bench ê²½ë¡œ ë¶„ë¦¬: `out/bench_v19.log` vs `out/bench_v20.log`
- Riskâ€‘Aware Autotune ì»¤ë¸ŒëŠ” **ì„ í˜• íŒ¨ì¹˜ ê¸ˆì§€**(ê³¡ì„  í…Œì´ë¸”ë§Œ ìˆ˜ì •)

---

## F11) Sensor Ingest ìŠ¤ì¼ˆë ˆí†¤
**sensors/sources/osc_stream.py**
```python
#!/usr/bin/env python3
from pythonosc import dispatcher, osc_server
from queue import Queue
Q=Queue(maxsize=1024)

def handler(addr, *args):
    Q.put((addr, args))

def run(addr='127.0.0.1', port=9000):
    disp=dispatcher.Dispatcher(); disp.set_default_handler(handler)
    server=osc_server.ThreadingOSCUDPServer((addr,port), disp)
    server.serve_forever()
```

**sensors/sources/midi_stream.py**
```python
#!/usr/bin/env python3
import mido
from queue import Queue
Q=Queue(maxsize=1024)

def run(device_name=None):
    with mido.open_input(device_name) as port:
        for msg in port: Q.put(('midi', msg.dict()))
```

**sensors/sources/file_replay.py**
```python
#!/usr/bin/env python3
import json, time
from queue import Queue
Q=Queue(maxsize=1024)

def run(path, speed=1.0):
    t0=None
    for line in open(path):
        rec=json.loads(line)
        ts=rec.get('ts')
        if t0 is None: t0=ts
        delay=max(0.0,(ts-t0)/speed)
        time.sleep(delay)
        Q.put(rec)
```

**sensors/ingest_daemon.py (ì ‘ì°©)**
```python
#!/usr/bin/env python3
import yaml, threading
from sources.osc_stream import run as run_osc
from sources.midi_stream import run as run_midi
from sources.file_replay import run as run_replay

if __name__=='__main__':
  cfg=yaml.safe_load(open('configs/sensors_v20.yaml'))
  for s in cfg['streams']:
    if s['type']=='osc': threading.Thread(target=run_osc, kwargs={'addr':s['addr'].split(':')[0],'port':int(s['addr'].split(':')[1])}, daemon=True).start()
    if s['type']=='midi': threading.Thread(target=run_midi, kwargs={'device_name':s['device']}, daemon=True).start()
    if s['type']=='file': threading.Thread(target=run_replay, kwargs={'path':s['path']}, daemon=True).start()
  threading.Event().wait()
```

---

## F12) ì •ë ¬/ë¦¬ìƒ˜í”Œ ì–´ëŒ‘í„°
**fusion/adapters/align_kalman.py**
```python
import numpy as np
class SimpleKalman:
  def __init__(self,q=1e-3,r=2e-3):
    self.q=q; self.r=r; self.x=0; self.p=1
  def update(self,z):
    # predict
    self.p += self.q
    # update
    k = self.p/(self.p+self.r)
    self.x = self.x + k*(z-self.x)
    self.p = (1-k)*self.p
    return self.x
```

**fusion/adapters/resample_polyphase.py**
```python
import numpy as np
from scipy.signal import resample_poly

def to_target_hz(series, src_hz, tgt_hz):
  up=int(tgt_hz); down=int(src_hz)
  return resample_poly(series, up, down)
```

---

## F13) URE Pull í†µí•© (Bridgeâ†’Fusion)
**fusion/fusion_engine_v20.py (ë³´ê°• ë°œì·Œ)**
```python
import requests
URE_URL='http://localhost:9305/metrics_ure'

def pull_ure_metrics():
  # very simple text parse
  m=requests.get(URE_URL, timeout=1.0).text
  def grab(key):
    for line in m.splitlines():
      if line.startswith(key+' '):
        return float(line.split()[1])
  return {
    'ure_phase_diff': grab('ure_phase_diff_mean') or 0.02,
    'ure_harmony': grab('ure_harmony_index') or 0.86,
    'ure_coherence': grab('ure_coherence_level') or 0.85,
  }
```

---

## F14) Riskâ€‘Aware Autotune ì—”ì§„(ì´ˆì•ˆ)
**tools/risk_autotune_v20.py**
```python
#!/usr/bin/env python3
import yaml, json, sys
cfg=yaml.safe_load(open('configs/risk_autotune_v20.yaml'))
curve_kp=cfg['nonlinear_gain']['kp_curve']
curve_kd=cfg['nonlinear_gain']['kd_curve']
ki=cfg['nonlinear_gain']['ki_base']

# simple piecewise linear interpolation on entropy_ratio
entropy=float(sys.argv[1]) if len(sys.argv)>1 else 0.12

def interp(curve, x):
  for i in range(1,len(curve)):
    x0,y0=curve[i-1]; x1,y1=curve[i]
    if x<=x1:
      t=(x-x0)/(x1-x0) if x1!=x0 else 0
      return y0+(y1-y0)*t
  return curve[-1][1]

kp=interp(curve_kp, entropy)
kd=interp(curve_kd, entropy)
print(json.dumps({'gain':{'kp':round(kp,2),'ki':round(ki,2),'kd':round(kd,2)}}, indent=2))
```

**Make íƒ€ê¹ƒ**
```makefile
.PHONY: autotune.risk
autotune.risk:
	@python3 tools/risk_autotune_v20.py $$ENTROPY > configs/fusion_autotune.json
```

---

## F15) Evidence Rules (ìƒ˜í”Œ)
**evidence/rules/risk_map.yaml**
```yaml
- if: "phase_diff > 0.025 and entropy_ratio > 0.18"
  risk: "sync_degradation"
  action: "increase kd by 0.02; alert warn"
```

**evidence/rules/quote_rules.yaml**
```yaml
- match: "coherence improves with lower entropy"
  quote: "Stability favors clarity; clarity invites harmony."
```

---

## F16) OpenAPI (Fusion)
**api/openapi_v20.yaml (ë°œì·Œ)**
```yaml
openapi: 3.0.3
info: {title: Lumen Fusion API, version: 2.0a}
paths:
  /metrics_fusion: {get: {summary: Fusion Prom metrics}}
  /evidence/bundle: {get: {summary: Evidence bundle stream}}
```

---

## F17) v2.0 Î±1 Session Restore Block (ì¦ë¶„)
```bash
# v2.0 Î±1: sensor ingest + fusion align + riskâ€‘aware autotune scaffold
bash scripts/smoke.v20.sh && \
make fusion.init && make sensor.ingest.start && \
make autotune.risk ENTROPY=0.14 && \
bash scripts/bench.v20.sh 1200
```

---

## F18) ë‹¤ìŒ ì•¡ì…˜ (ë£¨ë©˜ ì œì•ˆ)
1) `bench.v20.sh 20m` ê´€ì¸¡ í›„ `fusion:coherence_p95_10m â‰¥ 0.90` ë‹¬ì„± ì—¬ë¶€ í™•ì¸
2) ë¯¸ë‹¬ ì‹œ: `risk_autotune_v20.yaml` ì»¤ë¸Œ ìƒí–¥/ì™„í™”, ì¹¼ë§Œ Q/R ë¯¸ì„¸ì¡°ì •(Qâ†˜ï¸, Râ†—ï¸)
3) Evidence bundleì— **risk_map ì ìš© ê²°ê³¼** 10ë¶„ ëˆ„ì  ìŠ¤ëƒ…ìƒ· ìƒì„±

---

## F19) Sensor Schema & Normalization
**schemas/sensor_event_v20.json (ì´ˆì•ˆ)**
```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "SensorEventV20",
  "type": "object",
  "required": ["ts", "source", "key", "value"],
  "properties": {
    "ts": {"type": "number", "description": "unix epoch seconds with ms"},
    "source": {"type": "string"},
    "key": {"type": "string"},
    "value": {"type": ["number", "string", "array", "object"]},
    "meta": {"type": "object"}
  }
}
```

**sensors/normalize.py**
```python
#!/usr/bin/env python3
# OSC/MIDI/File â†’ SensorEventV20
from dataclasses import dataclass, asdict
@dataclass
class Event: ts: float; source: str; key: str; value: float; meta: dict

def from_osc(addr, args):
    return Event(ts=time.time(), source='osc', key=addr, value=float(args[0]), meta={})
```

---

## F20) Outlier/Clockâ€‘Drift Guards
**fusion/adapters/outlier_clip.py**
```python
def clip(series, p_low=0.01, p_high=0.99):
    s=sorted(series); n=len(s);
    lo=s[int(p_low*n)]; hi=s[int(p_high*n)];
    return [min(hi, max(lo, x)) for x in series]
```

**fusion/adapters/clock_drift.py**
```python
# NTP ê¸°ë°˜ ë³´ì •ì¹˜ ì…ë ¥ ê°€ì •; ë‹¨ìˆœ ì„ í˜• ë³´ì •
class ClockDrift:
    def __init__(self, ppm=0): self.ppm=ppm
    def apply(self, ts): return ts*(1+self.ppm/1e6)
```

---

## F21) Crossâ€‘Correlation Align (ì´ˆì•ˆ)
**fusion/adapters/xcorr_align.py**
```python
import numpy as np
from numpy.fft import rfft, irfft

def lag_by_xcorr(a, b, max_lag=200):
    # returns best lag(samples) to align b to a
    n = 1<< (max(len(a),len(b)).bit_length())
    fa, fb = rfft(a, n), rfft(b, n)
    corr = irfft(fa*np.conj(fb))
    idx = np.argmax(corr[:max_lag])
    return int(idx)
```

---

## F22) Fusion Weighting & Failover
**configs/fusion_v20.yaml (ì¶”ê°€)**
```yaml
weights:
  ure: 0.7
  sensors: 0.3
failover:
  min_streams: 1
  fallback: ure_only  # ure_only | sensors_only | degrade
```

**fusion/fusion_engine_v20.py (ë°œì·Œ)**
```python
# fused = w_ure*ure + w_sens*sensors; sensorsê°€ ë¶€ì¡±í•˜ë©´ failover ì •ì±… ì ìš©
```

---

## F23) Monitoring & Alerts (Fusion)
**ops/prometheus/rules/fusion_alerts_v20.yaml**
```yaml
groups:
- name: fusion_alerts_v20
  rules:
  - alert: FusionStreamLoss
    expr: increase(fusion_stream_ingest_total[2m]) == 0
    for: 2m
    labels: {severity: warning}
    annotations: {summary: "No sensor ingest", description: "ingest halted"}
  - alert: FusionCoherenceLow
    expr: fusion:coherence_p95_10m < 0.86
    for: 10m
    labels: {severity: critical}
```

---

## F24) Tests & CI (ì¶”ê°€)
**tests/fusion_align.spec.py**
```python
from fusion.adapters.xcorr_align import lag_by_xcorr

def test_xcorr_align_basic():
    a=[0,1,2,3,4,5,6,7,8,9]; b=[2,3,4,5,6,7,8,9]
    assert lag_by_xcorr(a,b) >= 0
```

**.github/workflows/fusion-ci.yml**
```yaml
name: fusion-ci
on: {push: {branches: [main]}, pull_request: {}}
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: {python-version: '3.11'}
      - run: pip install -r requirements.txt
      - run: pytest -q
```

---

## F25) v2.0 Î±2 Session Restore Block (ë³´ê°•)
```bash
# v2.0 Î±2: schema/normalize, guards, xcorr, weighting/failover, alerts, tests
make fusion.init && make sensor.ingest.start && \
python -m pytest -q && \
bash scripts/bench.v20.sh 1800
```
