"""
SLO Exporter for Cloud Run Environment

Cloud Run í™˜ê²½ì—ì„œ ì„œë¹„ìŠ¤ ìˆ˜ì¤€ ëª©í‘œ(SLO)ë¥¼ ì¶”ì í•˜ê³  í‰ê°€í•˜ëŠ” Exporter
Kubernetes ê¸°ë°˜ ì›ë³¸ Lumen SLO Exporterë¥¼ Cloud Runì— ë§ê²Œ ì ì‘

ì¸¡ì • í•­ëª©:
- ê°€ìš©ì„± (Availability): ì„±ê³µë¥  ê¸°ë°˜
- ë ˆì´í„´ì‹œ (Latency): P95, P99 ì„ê³„ê°’
- ì—ëŸ¬ìœ¨ (Error Rate): 4xx, 5xx ì—ëŸ¬
- ì²˜ë¦¬ëŸ‰ (Throughput): ì´ˆë‹¹ ìš”ì²­ ìˆ˜
"""

from google.cloud import monitoring_v3
import datetime
from typing import Dict, List, Optional, Tuple
import logging
import os
import json

logger = logging.getLogger(__name__)


class SLOExporterCloudRun:
    """Cloud Run í™˜ê²½ì—ì„œ SLOë¥¼ ì¶”ì í•˜ê³  í‰ê°€í•˜ëŠ” Exporter"""
    
    # SLO ëª©í‘œ ì •ì˜
    SLO_TARGETS = {
        "availability": 99.5,  # 99.5% ê°€ìš©ì„± (ì›”ê°„ 3.6ì‹œê°„ ë‹¤ìš´íƒ€ì„ í—ˆìš©)
        "latency_p95": 200,    # P95 ë ˆì´í„´ì‹œ < 200ms
        "latency_p99": 500,    # P99 ë ˆì´í„´ì‹œ < 500ms
        "error_rate": 0.1,     # ì—ëŸ¬ìœ¨ < 0.1%
    }
    
    # ì•Œë¦¼ ì„ê³„ê°’ (SLO ëª©í‘œ ëŒ€ë¹„)
    ALERT_THRESHOLDS = {
        "critical": 0.95,  # 95% ë‹¬ì„± ì‹œ CRITICAL
        "warning": 0.98,   # 98% ë‹¬ì„± ì‹œ WARNING
    }
    
    def __init__(self, project_id: str, service_name: str = "ion-api-canary"):
        """
        Args:
            project_id: GCP í”„ë¡œì íŠ¸ ID
            service_name: Cloud Run ì„œë¹„ìŠ¤ ì´ë¦„
        """
        self.project_id = project_id
        self.service_name = service_name
        self.monitoring_client = monitoring_v3.MetricServiceClient()
        self.project_name = f"projects/{project_id}"
    
    def get_availability(self, hours: int = 24) -> Dict[str, float]:
        """
        ê°€ìš©ì„± ì¸¡ì •: ì„±ê³µí•œ ìš”ì²­ ë¹„ìœ¨
        
        Args:
            hours: ì¸¡ì • ê¸°ê°„ (ì‹œê°„)
        
        Returns:
            Dict with:
                - availability: ê°€ìš©ì„± (%)
                - total_requests: ì´ ìš”ì²­ ìˆ˜
                - successful_requests: ì„±ê³µí•œ ìš”ì²­ ìˆ˜
                - failed_requests: ì‹¤íŒ¨í•œ ìš”ì²­ ìˆ˜
                - slo_target: SLO ëª©í‘œ
                - slo_achieved: SLO ë‹¬ì„± ì—¬ë¶€
        """
        try:
            metric_type = "run.googleapis.com/request_count"
            
            now = datetime.datetime.utcnow()
            end_time = now
            start_time = now - datetime.timedelta(hours=hours)
            
            interval = monitoring_v3.TimeInterval({
                "start_time": {"seconds": int(start_time.timestamp())},
                "end_time": {"seconds": int(end_time.timestamp())},
            })
            
            # ì „ì²´ ìš”ì²­ ìˆ˜
            total_request = monitoring_v3.ListTimeSeriesRequest({
                "name": self.project_name,
                "filter": f'metric.type="{metric_type}" AND resource.labels.service_name="{self.service_name}"',
                "interval": interval,
            })
            
            # ì‹¤íŒ¨ ìš”ì²­ ìˆ˜ (5xxë§Œ, 4xxëŠ” í´ë¼ì´ì–¸íŠ¸ ì—ëŸ¬ë¡œ ê°„ì£¼)
            failed_request = monitoring_v3.ListTimeSeriesRequest({
                "name": self.project_name,
                "filter": f'metric.type="{metric_type}" AND resource.labels.service_name="{self.service_name}" AND metric.labels.response_code_class="5"',
                "interval": interval,
            })
            
            total_results = self.monitoring_client.list_time_series(request=total_request)
            failed_results = self.monitoring_client.list_time_series(request=failed_request)
            
            # ì´ ìš”ì²­ ìˆ˜ ê³„ì‚°
            total_count = sum(
                sum(point.value.int64_value for point in result.points)
                for result in total_results
            )
            
            # ì‹¤íŒ¨ ìš”ì²­ ìˆ˜ ê³„ì‚°
            failed_count = sum(
                sum(point.value.int64_value for point in result.points)
                for result in failed_results
            )
            
            # ê°€ìš©ì„± ê³„ì‚°
            if total_count == 0:
                availability = 100.0
                successful_count = 0
            else:
                successful_count = total_count - failed_count
                availability = (successful_count / total_count) * 100
            
            # SLO ë‹¬ì„± ì—¬ë¶€
            slo_target = self.SLO_TARGETS["availability"]
            slo_achieved = availability >= slo_target
            
            result = {
                "availability": availability,
                "total_requests": total_count,
                "successful_requests": successful_count,
                "failed_requests": failed_count,
                "slo_target": slo_target,
                "slo_achieved": slo_achieved,
            }
            
            logger.info(f"Availability: {availability:.2f}% (target: {slo_target}%), achieved: {slo_achieved}")
            return result
        
        except Exception as e:
            logger.error(f"Failed to get availability: {e}")
            return {
                "availability": 0.0,
                "total_requests": 0,
                "successful_requests": 0,
                "failed_requests": 0,
                "slo_target": self.SLO_TARGETS["availability"],
                "slo_achieved": False,
            }
    
    def get_latency(self, hours: int = 24) -> Dict[str, float]:
        """
        ë ˆì´í„´ì‹œ ì¸¡ì •: P95, P99
        
        Args:
            hours: ì¸¡ì • ê¸°ê°„ (ì‹œê°„)
        
        Returns:
            Dict with:
                - latency_p95: P95 ë ˆì´í„´ì‹œ (ms)
                - latency_p99: P99 ë ˆì´í„´ì‹œ (ms)
                - slo_p95_target: P95 ëª©í‘œ (ms)
                - slo_p99_target: P99 ëª©í‘œ (ms)
                - slo_p95_achieved: P95 SLO ë‹¬ì„± ì—¬ë¶€
                - slo_p99_achieved: P99 SLO ë‹¬ì„± ì—¬ë¶€
        """
        try:
            metric_type = "run.googleapis.com/request_latencies"
            
            now = datetime.datetime.utcnow()
            end_time = now
            start_time = now - datetime.timedelta(hours=hours)
            
            interval = monitoring_v3.TimeInterval({
                "start_time": {"seconds": int(start_time.timestamp())},
                "end_time": {"seconds": int(end_time.timestamp())},
            })
            
            # P95 ë ˆì´í„´ì‹œ
            p95_aggregation = monitoring_v3.Aggregation({
                "alignment_period": {"seconds": 300},
                "per_series_aligner": monitoring_v3.Aggregation.Aligner.ALIGN_DELTA,
                "cross_series_reducer": monitoring_v3.Aggregation.Reducer.REDUCE_PERCENTILE_95,
            })
            
            p95_request = monitoring_v3.ListTimeSeriesRequest({
                "name": self.project_name,
                "filter": f'metric.type="{metric_type}" AND resource.labels.service_name="{self.service_name}"',
                "interval": interval,
                "aggregation": p95_aggregation,
            })
            
            # P99 ë ˆì´í„´ì‹œ
            p99_aggregation = monitoring_v3.Aggregation({
                "alignment_period": {"seconds": 300},
                "per_series_aligner": monitoring_v3.Aggregation.Aligner.ALIGN_DELTA,
                "cross_series_reducer": monitoring_v3.Aggregation.Reducer.REDUCE_PERCENTILE_99,
            })
            
            p99_request = monitoring_v3.ListTimeSeriesRequest({
                "name": self.project_name,
                "filter": f'metric.type="{metric_type}" AND resource.labels.service_name="{self.service_name}"',
                "interval": interval,
                "aggregation": p99_aggregation,
            })
            
            p95_results = self.monitoring_client.list_time_series(request=p95_request)
            p99_results = self.monitoring_client.list_time_series(request=p99_request)
            
            # P95 ê³„ì‚°
            latency_p95 = 0.0
            for result in p95_results:
                if result.points:
                    latency_p95 = result.points[-1].value.double_value
                    break
            
            # P99 ê³„ì‚°
            latency_p99 = 0.0
            for result in p99_results:
                if result.points:
                    latency_p99 = result.points[-1].value.double_value
                    break
            
            # SLO ë‹¬ì„± ì—¬ë¶€
            slo_p95_target = self.SLO_TARGETS["latency_p95"]
            slo_p99_target = self.SLO_TARGETS["latency_p99"]
            
            slo_p95_achieved = latency_p95 <= slo_p95_target if latency_p95 > 0 else True
            slo_p99_achieved = latency_p99 <= slo_p99_target if latency_p99 > 0 else True
            
            result = {
                "latency_p95": latency_p95,
                "latency_p99": latency_p99,
                "slo_p95_target": slo_p95_target,
                "slo_p99_target": slo_p99_target,
                "slo_p95_achieved": slo_p95_achieved,
                "slo_p99_achieved": slo_p99_achieved,
            }
            
            logger.info(f"Latency P95: {latency_p95:.2f}ms (target: {slo_p95_target}ms), P99: {latency_p99:.2f}ms (target: {slo_p99_target}ms)")
            return result
        
        except Exception as e:
            logger.error(f"Failed to get latency: {e}")
            return {
                "latency_p95": 0.0,
                "latency_p99": 0.0,
                "slo_p95_target": self.SLO_TARGETS["latency_p95"],
                "slo_p99_target": self.SLO_TARGETS["latency_p99"],
                "slo_p95_achieved": False,
                "slo_p99_achieved": False,
            }
    
    def get_error_rate(self, hours: int = 24) -> Dict[str, float]:
        """
        ì—ëŸ¬ìœ¨ ì¸¡ì •: 4xx, 5xx ë¹„ìœ¨
        
        Args:
            hours: ì¸¡ì • ê¸°ê°„ (ì‹œê°„)
        
        Returns:
            Dict with:
                - error_rate: ì—ëŸ¬ìœ¨ (%)
                - error_4xx_count: 4xx ì—ëŸ¬ ìˆ˜
                - error_5xx_count: 5xx ì—ëŸ¬ ìˆ˜
                - total_requests: ì´ ìš”ì²­ ìˆ˜
                - slo_target: SLO ëª©í‘œ
                - slo_achieved: SLO ë‹¬ì„± ì—¬ë¶€
        """
        try:
            metric_type = "run.googleapis.com/request_count"
            
            now = datetime.datetime.utcnow()
            end_time = now
            start_time = now - datetime.timedelta(hours=hours)
            
            interval = monitoring_v3.TimeInterval({
                "start_time": {"seconds": int(start_time.timestamp())},
                "end_time": {"seconds": int(end_time.timestamp())},
            })
            
            # ì „ì²´ ìš”ì²­ ìˆ˜
            total_request = monitoring_v3.ListTimeSeriesRequest({
                "name": self.project_name,
                "filter": f'metric.type="{metric_type}" AND resource.labels.service_name="{self.service_name}"',
                "interval": interval,
            })
            
            # 4xx ì—ëŸ¬
            error_4xx_request = monitoring_v3.ListTimeSeriesRequest({
                "name": self.project_name,
                "filter": f'metric.type="{metric_type}" AND resource.labels.service_name="{self.service_name}" AND metric.labels.response_code_class="4"',
                "interval": interval,
            })
            
            # 5xx ì—ëŸ¬
            error_5xx_request = monitoring_v3.ListTimeSeriesRequest({
                "name": self.project_name,
                "filter": f'metric.type="{metric_type}" AND resource.labels.service_name="{self.service_name}" AND metric.labels.response_code_class="5"',
                "interval": interval,
            })
            
            total_results = self.monitoring_client.list_time_series(request=total_request)
            error_4xx_results = self.monitoring_client.list_time_series(request=error_4xx_request)
            error_5xx_results = self.monitoring_client.list_time_series(request=error_5xx_request)
            
            # ì¹´ìš´íŠ¸ ê³„ì‚°
            total_count = sum(
                sum(point.value.int64_value for point in result.points)
                for result in total_results
            )
            
            error_4xx_count = sum(
                sum(point.value.int64_value for point in result.points)
                for result in error_4xx_results
            )
            
            error_5xx_count = sum(
                sum(point.value.int64_value for point in result.points)
                for result in error_5xx_results
            )
            
            # ì—ëŸ¬ìœ¨ ê³„ì‚°
            if total_count == 0:
                error_rate = 0.0
            else:
                total_errors = error_4xx_count + error_5xx_count
                error_rate = (total_errors / total_count) * 100
            
            # SLO ë‹¬ì„± ì—¬ë¶€
            slo_target = self.SLO_TARGETS["error_rate"]
            slo_achieved = error_rate <= slo_target
            
            result = {
                "error_rate": error_rate,
                "error_4xx_count": error_4xx_count,
                "error_5xx_count": error_5xx_count,
                "total_requests": total_count,
                "slo_target": slo_target,
                "slo_achieved": slo_achieved,
            }
            
            logger.info(f"Error rate: {error_rate:.2f}% (target: {slo_target}%), achieved: {slo_achieved}")
            return result
        
        except Exception as e:
            logger.error(f"Failed to get error rate: {e}")
            return {
                "error_rate": 0.0,
                "error_4xx_count": 0,
                "error_5xx_count": 0,
                "total_requests": 0,
                "slo_target": self.SLO_TARGETS["error_rate"],
                "slo_achieved": False,
            }
    
    def evaluate_slo_status(self, hours: int = 24) -> Dict[str, any]:
        """
        ì „ì²´ SLO ìƒíƒœ í‰ê°€
        
        Args:
            hours: ì¸¡ì • ê¸°ê°„ (ì‹œê°„)
        
        Returns:
            Dict with:
                - availability: ê°€ìš©ì„± ë°ì´í„°
                - latency: ë ˆì´í„´ì‹œ ë°ì´í„°
                - error_rate: ì—ëŸ¬ìœ¨ ë°ì´í„°
                - overall_status: ì „ì²´ ìƒíƒœ (HEALTHY/WARNING/CRITICAL)
                - slo_compliance: SLO ì¤€ìˆ˜ìœ¨ (%)
                - failed_slos: ì‹¤íŒ¨í•œ SLO ëª©ë¡
        """
        # ê° ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        availability = self.get_availability(hours)
        latency = self.get_latency(hours)
        error_rate = self.get_error_rate(hours)
        
        # SLO ë‹¬ì„± ì—¬ë¶€ í™•ì¸
        slo_checks = {
            "availability": availability["slo_achieved"],
            "latency_p95": latency["slo_p95_achieved"],
            "latency_p99": latency["slo_p99_achieved"],
            "error_rate": error_rate["slo_achieved"],
        }
        
        # ì‹¤íŒ¨í•œ SLO ëª©ë¡
        failed_slos = [name for name, achieved in slo_checks.items() if not achieved]
        
        # SLO ì¤€ìˆ˜ìœ¨
        total_slos = len(slo_checks)
        achieved_slos = sum(1 for achieved in slo_checks.values() if achieved)
        slo_compliance = (achieved_slos / total_slos) * 100
        
        # ì „ì²´ ìƒíƒœ ê²°ì •
        if slo_compliance == 100:
            overall_status = "HEALTHY"
        elif slo_compliance >= 75:
            overall_status = "WARNING"
        else:
            overall_status = "CRITICAL"
        
        result = {
            "availability": availability,
            "latency": latency,
            "error_rate": error_rate,
            "overall_status": overall_status,
            "slo_compliance": slo_compliance,
            "failed_slos": failed_slos,
        }
        
        logger.info(f"SLO Status: {overall_status}, Compliance: {slo_compliance:.1f}%")
        return result
    
    def generate_report(self, hours: int = 24) -> str:
        """
        SLO ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            hours: ì¸¡ì • ê¸°ê°„ (ì‹œê°„)
        
        Returns:
            Markdown í˜•ì‹ ë¦¬í¬íŠ¸
        """
        status_data = self.evaluate_slo_status(hours)
        
        # ìƒíƒœ ì•„ì´ì½˜
        status_icon_map = {
            "HEALTHY": "âœ…",
            "WARNING": "âš ï¸",
            "CRITICAL": "âŒ",
        }
        status_icon = status_icon_map.get(status_data["overall_status"], "â“")
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = f"""
# SLO Report

**Date**: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**Service**: {self.service_name}  
**Project**: {self.project_id}  
**Period**: Last {hours} hours

---

## {status_icon} Overall Status: {status_data["overall_status"]}

**SLO Compliance**: {status_data["slo_compliance"]:.1f}%

"""
        
        if status_data["failed_slos"]:
            report += f"**Failed SLOs**: {', '.join(status_data['failed_slos'])}\n\n"
        else:
            report += "**All SLOs achieved** âœ…\n\n"
        
        report += "---\n\n"
        
        # ê°€ìš©ì„±
        avail = status_data["availability"]
        avail_icon = "âœ…" if avail["slo_achieved"] else "âŒ"
        report += f"""
## {avail_icon} Availability

- **Current**: {avail["availability"]:.2f}%
- **Target**: {avail["slo_target"]}%
- **Total Requests**: {avail["total_requests"]:,}
- **Successful**: {avail["successful_requests"]:,}
- **Failed (5xx)**: {avail["failed_requests"]:,}
- **Status**: {'PASS' if avail["slo_achieved"] else 'FAIL'}

"""
        
        # ë ˆì´í„´ì‹œ
        lat = status_data["latency"]
        lat_p95_icon = "âœ…" if lat["slo_p95_achieved"] else "âŒ"
        lat_p99_icon = "âœ…" if lat["slo_p99_achieved"] else "âŒ"
        report += f"""
## Latency

### {lat_p95_icon} P95 Latency
- **Current**: {lat["latency_p95"]:.2f}ms
- **Target**: {lat["slo_p95_target"]}ms
- **Status**: {'PASS' if lat["slo_p95_achieved"] else 'FAIL'}

### {lat_p99_icon} P99 Latency
- **Current**: {lat["latency_p99"]:.2f}ms
- **Target**: {lat["slo_p99_target"]}ms
- **Status**: {'PASS' if lat["slo_p99_achieved"] else 'FAIL'}

"""
        
        # ì—ëŸ¬ìœ¨
        err = status_data["error_rate"]
        err_icon = "âœ…" if err["slo_achieved"] else "âŒ"
        report += f"""
## {err_icon} Error Rate

- **Current**: {err["error_rate"]:.2f}%
- **Target**: < {err["slo_target"]}%
- **4xx Errors**: {err["error_4xx_count"]:,}
- **5xx Errors**: {err["error_5xx_count"]:,}
- **Total Requests**: {err["total_requests"]:,}
- **Status**: {'PASS' if err["slo_achieved"] else 'FAIL'}

---

## ğŸ’¡ Recommendations

"""
        
        # ê¶Œì¥ì‚¬í•­
        if status_data["overall_status"] == "HEALTHY":
            report += """
âœ… **All systems operational**
- Continue monitoring
- Maintain current configuration
- Review trends weekly
"""
        elif status_data["overall_status"] == "WARNING":
            report += """
âš ï¸ **Some SLOs need attention**

Actions:
1. Review failed SLO metrics
2. Investigate root causes
3. Adjust configuration if needed
4. Increase monitoring frequency
"""
        else:
            report += """
âŒ **Critical: Multiple SLO violations**

Immediate Actions:
1. Check service health
2. Review recent deployments
3. Investigate infrastructure issues
4. Consider rollback if necessary
5. Alert team and stakeholders
"""
        
        report += "\n---\n"
        
        return report
    
    def export_to_cloud_monitoring(self, status_data: Dict[str, any]) -> None:
        """
        SLO ë©”íŠ¸ë¦­ì„ Cloud Monitoring Custom Metricìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
        
        Args:
            status_data: SLO ìƒíƒœ ë°ì´í„°
        """
        try:
            # SLO ì¤€ìˆ˜ìœ¨ ë©”íŠ¸ë¦­
            series = monitoring_v3.TimeSeries()
            series.metric.type = "custom.googleapis.com/slo_compliance"
            series.resource.type = "cloud_run_revision"
            series.resource.labels["project_id"] = self.project_id
            series.resource.labels["service_name"] = self.service_name
            
            now = datetime.datetime.utcnow()
            point = monitoring_v3.Point({
                "interval": {
                    "end_time": {"seconds": int(now.timestamp())},
                },
                "value": {"double_value": status_data["slo_compliance"]},
            })
            series.points = [point]
            
            self.monitoring_client.create_time_series(
                name=self.project_name,
                time_series=[series]
            )
            
            logger.info(f"Exported SLO compliance to Cloud Monitoring: {status_data['slo_compliance']:.1f}%")
        
        except Exception as e:
            logger.error(f"Failed to export to Cloud Monitoring: {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logging.basicConfig(level=logging.INFO)
    
    project_id = os.getenv("GCP_PROJECT_ID", "naeda-genesis")
    service_name = os.getenv("CLOUD_RUN_SERVICE", "ion-api-canary")
    
    exporter = SLOExporterCloudRun(project_id, service_name)
    
    # SLO ìƒíƒœ í‰ê°€
    status_data = exporter.evaluate_slo_status(hours=24)
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    report = exporter.generate_report(hours=24)
    print(report)
    
    # Cloud Monitoringì— ë‚´ë³´ë‚´ê¸°
    exporter.export_to_cloud_monitoring(status_data)
    
    # ê²°ê³¼ ë°˜í™˜ (ëª¨ë‹ˆí„°ë§ í†µí•©ìš©)
    result = {
        "overall_status": status_data["overall_status"],
        "slo_compliance": status_data["slo_compliance"],
        "failed_slos": status_data["failed_slos"],
    }
    
    # JSON ì¶œë ¥
    print("\n=== SLO Status (JSON) ===")
    print(json.dumps(result, indent=2))
    
    # Exit code ì„¤ì •
    if status_data["overall_status"] == "HEALTHY":
        exit(0)
    elif status_data["overall_status"] == "WARNING":
        exit(1)
    else:
        exit(2)


if __name__ == "__main__":
    main()
