#!/usr/bin/env python3
"""
Lumen Gateway í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
from pathlib import Path

# .env íŒŒì¼ ëª…ì‹œì  ë¡œë“œ
from dotenv import load_dotenv

env_path = Path(__file__).parent / ".env"
load_dotenv(env_path)

print(f"âœ… Loaded .env from: {env_path}")

# ion-mentoring ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

import os

from app.api.feature_flags import feature_flags, is_lumen_enabled
from app.integrations.lumen_client import get_lumen_client

print("\nğŸ” Environment Variables:")
print(f"  LUMEN_GATE_ENABLED: {os.getenv('LUMEN_GATE_ENABLED')}")
print(f"  LUMEN_GATEWAY_URL: {os.getenv('LUMEN_GATEWAY_URL')}")

print("\nğŸ” Feature Flag Status:")
print(f"  is_lumen_enabled(): {is_lumen_enabled()}")

print("\nğŸ” Feature Flag Manager:")
for name, flag in feature_flags._flags.items():
    print(f"  {name}: enabled={flag.enabled}")

print("\nğŸ§ª Testing Lumen Gateway Client...")
try:
    client = get_lumen_client()
    print(f"  âœ… Client created: {client.gateway_url}")

    # Health Check
    print("\nğŸ” Health Check:")
    is_healthy = client.health_check()
    print(f"  Health: {'âœ… OK' if is_healthy else 'âŒ FAILED'}")

    if is_healthy:
        # Inference Test
        print("\nğŸ§ª Inference Test:")
        result = client.infer(message="ì°½ì˜ì ì´ê³  ê°ì„±ì ì¸ ì•„ì´ë””ì–´", user_id="test-script")
        print(f"  Success: {result.success}")
        print(f"  Persona: {result.persona.emoji} {result.persona.name}")
        print(f"  Response: {result.response[:100]}...")

except Exception as e:
    print(f"  âŒ Error: {e}")
    import traceback

    traceback.print_exc()

print("\nâœ… Test Complete")
