# Phase 4 배포 실패 Post-Mortem 가이드
**작성 일시**: 2025-10-21 오후
**목적**: 배포 실패 후 **원인 분석 및 개선** 프로세스
**상태**: 📋 **준비 완료**

---

## 📋 개요

배포 실패는 끝이 아니라 **학습의 시작**입니다.

이 문서는 배포 실패 후 다음을 수행하는 방법을 제시합니다:
1. 즉시 영향 최소화
2. 근본 원인 분석 (RCA)
3. 개선사항 도출
4. 팀 학습 및 공유

---

## 🔄 Post-Mortem 프로세스

### Phase 1: 긴급 대응 (실패 직후 0-30분)

#### Step 1: 롤백 완료 확인
```powershell
# 1. 트래픽이 legacy로 완전히 복구되었나?
.\check_monitoring_status.ps1

# 2. 모든 지표가 정상으로 돌아왔나?
#    - 에러율 < 0.5%
#    - P95 < 200ms
#    - 메모리 < 70%

# 3. 사용자 서비스 정상인가?
curl https://ion-api-64076350717.us-central1.run.app/health
```

#### Step 2: 긴급 증거 보존
```powershell
# 증거 수집 (이것을 놓치면 나중에 분석 불가!)

# 1. 에러 로그 수집
$timestamp = Get-Date -Format "yyyyMMdd_HHmmss"
gcloud logging read "resource.type=cloud_run_revision AND severity=ERROR" `
  --limit 500 > "evidence_errors_${timestamp}.txt"

# 2. 메트릭 스냅샷
.\get_canary_metrics.ps1 > "evidence_metrics_${timestamp}.json"

# 3. 배포 설정 저장
gcloud run services describe ion-api-canary --region us-central1 `
  > "evidence_canary_config_${timestamp}.json"

# 4. 영향받은 기능 목록 작성
# (나중에 참고)
Write-Host "증거 파일들을 logs/ 디렉토리에 보관했습니다"
```

#### Step 3: 팀 공지 및 업데이트

**Slack 메시지 템플릿**:
```
🚨 [INCIDENT] Phase 4 Canary 배포 실패

상황:
  배포 시간: 2025-10-22 14:00 UTC
  실패 감지: 14:XX UTC (배포 후 XX분)
  원인: [TBD - 분석 중]
  롤백 완료: 14:XX UTC

현재 상태:
  ✅ 서비스: 정상 복구됨
  ✅ 트래픽: 100% legacy로 복구
  ✅ 에러율: 정상 수준

다음 단계:
  1. 원인 분석 (1-2시간)
  2. Post-Mortem 회의 (2시간 후)
  3. 개선사항 도출 및 계획

Post-Mortem 회의: 15:00 UTC #critical-incidents 채널
```

---

### Phase 2: 근본 원인 분석 (RCA) (30분-2시간)

#### Step 1: 코드 변경사항 검토

```markdown
# 질문 1: 배포된 코드의 어느 부분이 문제였나?

## 체크리스트:

### 새 기능들
- [ ] 추천 엔진 (Recommendation Engine)
  - [ ] 로직 검토
  - [ ] 데이터베이스 쿼리
  - [ ] 외부 API 호출

- [ ] 멀티턴 대화 (MultiTurn Engine)
  - [ ] 세션 관리 로직
  - [ ] 상태 저장 메커니즘
  - [ ] 메모리 누수 가능성

- [ ] 세션 관리자 (Session Manager)
  - [ ] Redis 연결
  - [ ] 데이터 직렬화
  - [ ] TTL 설정

### 기존 코드 변경
- [ ] API 라우팅 변경
- [ ] 인증/인가 로직
- [ ] 에러 처리
- [ ] 로깅 변경

### 배포 설정 변경
- [ ] 환경 변수
- [ ] 리소스 할당
- [ ] 스케일링 정책
- [ ] 네트워크 설정
```

#### Step 2: 에러 로그 분석

```powershell
# 수집한 에러 로그 분석

# 1. 가장 많이 나타나는 에러 패턴 찾기
$errors = Get-Content "evidence_errors_*.txt" | Select-String "ERROR"
$errors | Group-Object -Property { $_.Line -replace '.*Exception: ', '' } |
  Sort-Object -Property Count -Descending |
  Select-Object -First 10

# 2. 에러 발생 시각대로 분석
# 배포 직후인가? 30분 후인가?
# → 이것이 원인을 암시한다

# 3. 영향받은 엔드포인트 특정
# /api/v2/chat?
# /api/v2/recommendations?
# /api/v2/session?
```

#### Step 3: 성능 데이터 분석

```json
// evidence_metrics_*.json 파일 분석

{
  "canary": {
    "request_count": 500,
    "error_count": 45,          // ← 에러율 9% (정상: 0.5%)
    "error_rate": "9.0%",
    "avg_response_time_ms": 450, // ← 느림 (정상: 150ms)
    "p95_response_time_ms": 850, // ← 매우 느림 (정상: 200ms)
    "p99_response_time_ms": 2100 // ← 극히 느림
  }
}

// 분석:
// 1. 에러가 9%인가? → 로직 버그 가능성
// 2. 응답이 느린가? → 성능 문제 또는 데이터베이스 문제
// 3. P99가 극히 느린가? → 아웃라이어 쿼리 또는 외부 API 타임아웃
```

#### Step 4: 테스트 커버리지 검토

```markdown
# 질문 2: 왜 테스트를 통과했는데 프로덕션에서 실패했나?

## 가능한 원인들:

1. **테스트 환경 vs 프로덕션 환경 차이**
   - [ ] 데이터 볼륨 (테스트: 100 rows vs 프로덕션: 1M rows)
   - [ ] 동시 사용자 수 (테스트: 10 vs 프로덕션: 1000)
   - [ ] 외부 API 응답 시간 (테스트: mock vs 프로덕션: real)
   - [ ] 네트워크 지연 (테스트: localhost vs 프로덕션: WAN)

2. **테스트 커버리지 부족**
   - [ ] 해당 기능의 단위 테스트 있나?
   - [ ] 통합 테스트 있나?
   - [ ] 부하 테스트 있나? (N > 1000 요청)
   - [ ] 엣지 케이스 테스트 있나? (empty data, null, timeout)

3. **프로덕션 특화 시나리오 미팅**
   - [ ] 세션이 만료되는 경우
   - [ ] 데이터베이스가 느린 경우
   - [ ] 외부 API가 타임아웃되는 경우
   - [ ] 메모리가 부족한 경우
```

#### Step 5: 인프라 설정 검토

```markdown
# 질문 3: 인프라 설정 문제인가?

## 체크리스트:

### 리소스 할당
- [ ] CPU: 예상 부하에 충분한가?
- [ ] 메모리: 예상 메모리 사용량을 고려했나?
- [ ] 디스크: 로그나 캐시 때문에 가득 찬 건 아닌가?

### 데이터베이스
- [ ] 연결 풀 크기: 충분한가?
- [ ] 타임아웃: 너무 짧지는 않나?
- [ ] 성능: 슬로우 쿼리 로그 확인했나?

### 캐싱
- [ ] Redis 연결: 정상인가?
- [ ] 캐시 히트율: 낮지는 않나?
- [ ] 메모리 사용: 가득 찼나?

### 네트워크
- [ ] 방화벽 규칙: 올바른가?
- [ ] DNS: 정상인가?
- [ ] 외부 API 접근: 가능한가?
```

---

### Phase 3: Post-Mortem 회의 (2시간 후)

#### 회의 목표
```
✅ 근본 원인 정의
✅ 원인이 발생하게 된 프로세스 파악
✅ 개선사항 도출
✅ 팀 학습 촉진 (비난 아님!)
```

#### 회의 참석자
```
필수:
  - 배포 리더 (Sena)
  - 백엔드 엔지니어 (Gitco)
  - DevOps 엔지니어 (Lubit)

권장:
  - 모니터링 담당 (Lemun)
  - 매니저
  - QA 담당자 (테스트 관련 실패인 경우)
```

> Gitco 후속 조치 절차는 `docs/GITCO_ORCHESTRATION_HANDOFF.md`에서 최신 내용을 확인하세요.

#### 회의 구조 (90분)

**00:00-10:00분: 타임라인 구성**
```
배포 13:00 UTC - 최종 점검
배포 14:00 UTC - 배포 시작
배포 14:05 UTC - 초기 메트릭 확인
배포 14:15 UTC - 이상 신호 첫 발견
배포 14:35 UTC - 롤백 결정
배포 14:38 UTC - 롤백 완료

→ 중요: 정확한 시간과 누가 뭘 했는지 기록
```

**10:00-40:00분: 근본 원인 분석**
```
Q: "가장 직접적인 원인은 무엇인가?"
A: "추천 엔진 쿼리가 N+1 문제를 가지고 있어서 응답이 느렸다"

Q: "왜 그런 코드가 배포되었나?"
A: "테스트 데이터가 너무 작아서 N+1 문제가 발견되지 않았다"

Q: "왜 테스트 데이터가 작았나?"
A: "프로덕션 데이터 크기를 고려하지 않고 테스트를 작성했다"

→ 5개의 Why로 근본 원인에 도달
```

**40:00-60:00분: 개선사항 도출**
```
이제부터는 다음을 확인해야 한다:

1. 코드 변경사항
   - [ ] 추천 엔진에 성능 테스트 추가
   - [ ] 1000+ 행 데이터로 테스트
   - [ ] 응답 시간 임계값 설정 (< 500ms)

2. 테스트 프로세스
   - [ ] 프로덕션 크기의 테스트 데이터 준비
   - [ ] 부하 테스트 필수화
   - [ ] 프로덕션 환경과 유사한 staging 환경 구축

3. 배포 프로세스
   - [ ] Canary 기간 연장 (1시간 → 2시간)
   - [ ] 모니터링 임계값 강화
   - [ ] 자동 롤백 조건 검토

4. 인프라
   - [ ] 데이터베이스 쿼리 모니터링 추가
   - [ ] 슬로우 쿼리 로그 분석 자동화
```

**60:00-90:00분: 액션 아이템 정리**
```
|우선순위|작업|담당자|기한|영향도|
|--------|-----|------|-----|------|
|P0|추천엔진 N+1 쿼리 수정|Gitco|2일|Critical|
|P1|부하테스트 기준 상향|Lubit|1주|High|
|P1|Staging 환경 개선|DevOps|2주|High|
|P2|모니터링 알림 강화|Lemun|1주|Medium|
|P3|팀 교육 프로그램|Sena|1개월|Low|
```

---

### Phase 4: 개선사항 실행 (1주-1개월)

#### Step 1: 임시 조치 (Hotfix)
```
즉시 배포할 수 없는 완벽한 해결책이 있다면,
일단 임시 조치로 문제를 완화하는 것도 방법입니다.

예: N+1 쿼리 문제
  임시: 쿼리 결과 캐싱 (1시간 TTL)
  영구: 쿼리 최적화 및 조인 사용
```

#### Step 2: 근본 해결
```
배포 실패의 근본 원인을 제거합니다.

예: N+1 쿼리 문제
  - ORM 쿼리 최적화
  - 인덱스 추가
  - 캐싱 전략 개선
```

#### Step 3: 테스트 강화
```
같은 문제가 다시 발생하지 않도록
테스트를 추가합니다.

예: N+1 쿼리 문제
  - 부하 테스트: 1000+ 행 데이터
  - 성능 테스트: P95 < 200ms 보증
  - 통합 테스트: 추천 엔진 정상 동작
```

#### Step 4: 프로세스 개선
```
프로세스 차원의 개선으로
같은 유형의 문제를 예방합니다.

예: 성능 문제 예방
  - 배포 전 성능 벤치마크 필수화
  - Staging 환경에서 부하 테스트 필수
  - Canary 배포 기간 연장
```

---

## 📊 Post-Mortem 보고서 템플릿

배포 실패 후 공식 보고서를 작성하세요:

```markdown
# [Phase 4] Post-Mortem Report

## 기본 정보
- **사건 ID**: INCIDENT-20251022-001
- **사건명**: Phase 4 Canary 배포 실패 (응답시간 증가)
- **발생 일시**: 2025-10-22 14:15 UTC
- **감지 시간**: 14:35 UTC (20분 후)
- **복구 시간**: 14:38 UTC (3분)
- **총 영향 시간**: 20분
- **심각도**: HIGH

## 임팩트
- **영향받은 사용자**: 약 500명 (전체의 1%)
- **에러율**: 0.5% → 9% (18배 증가)
- **응답시간**: 150ms → 450ms (3배 증가)
- **기능 가용성**: 90.5%

## 근본 원인
추천 엔진의 N+1 쿼리 문제로 인해 응답 시간이 과도하게 증가했습니다.
- 단일 추천 요청 시 400번의 개별 데이터베이스 쿼리 발생
- 각 쿼리 평균 1ms → 총 400ms (타임아웃 설정 전 발생)

## 타임라인
| 시간 | 이벤트 | 담당자 |
|------|--------|--------|
| 14:00 | 배포 시작 | Sena |
| 14:05 | 초기 메트릭 정상 | Lemun |
| 14:15 | P95 응답시간 증가 감지 | 자동 모니터링 |
| 14:35 | 사람이 이상 신호 확인 | Lemun |
| 14:37 | 롤백 결정 및 시작 | Sena |
| 14:38 | 롤백 완료, 메트릭 정상화 | Gitco |

## 근본 원인 분석 (5 Whys)
1. **왜 응답 시간이 증가했나?**
   - 데이터베이스 쿼리 시간이 400ms 소요

2. **왜 쿼리 시간이 길어졌나?**
   - 400번의 개별 쿼리 발생 (N+1 문제)

3. **왜 N+1 문제가 있었나?**
   - 추천 엔진 코드에 조인 대신 루프 쿼리 사용

4. **왜 그런 코드가 배포되었나?**
   - 테스트 데이터가 100행만 있어서 문제 미발견

5. **왜 테스트 데이터가 작았나?**
   - 프로덕션 데이터 크기(50M행)를 고려하지 않음

## 개선사항
| 우선순위 | 작업 | 담당자 | 기한 | 상태 |
|----------|------|--------|------|------|
| P0 | N+1 쿼리 수정 (조인으로 변경) | Gitco | 2일 | [  ] |
| P1 | 추천 엔진 성능 테스트 추가 | Gitco | 1주 | [  ] |
| P1 | Staging 데이터 크기 프로덕션 동기화 | Lubit | 1주 | [  ] |
| P2 | 데이터베이스 모니터링 강화 | Lemun | 1주 | [  ] |

## 배운 점 (Lessons Learned)
1. **테스트 데이터 크기가 중요하다**
   - 프로덕션 데이터 크기를 반영한 테스트 필수

2. **성능 테스트는 선택이 아니라 필수다**
   - 부하 테스트 없이 배포하면 안 됨

3. **Canary 배포는 실제 효과가 있다**
   - 20분 만에 문제를 감지하고 복구

4. **모니터링 임계값 설정이 중요하다**
   - P95 > 200ms 임계값이 좋은 조기 경보 역할

## 재발 방지책
1. Staging 환경을 프로덕션과 동일한 데이터 크기로 유지
2. 배포 전 필수적으로 부하 테스트 실행 (1000+ 사용자 시뮬레이션)
3. ORM 쿼리 분석 자동화 (N+1 감지 도구 도입)
4. 성능 회귀 테스트 추가

## 결론
이번 사건은 **프로덕션 데이터 크기를 고려한 테스트의 중요성**을 명확히 보여주었습니다.
앞으로는 테스트 환경과 프로덕션 환경의 차이를 최소화하여 이런 문제를 예방하겠습니다.
```

---

## 🔄 반복 및 학습

### 다음 배포에 적용할 사항
```markdown
이번 실패로부터 배운 것을 다음 배포 체크리스트에 추가:

- [ ] Staging 데이터 크기 확인 (프로덕션 크기의 80% 이상)
- [ ] 부하 테스트 실행 (최소 1000 동시 사용자)
- [ ] 데이터베이스 쿼리 분석 (N+1 감지)
- [ ] 성능 회귀 테스트 통과
- [ ] P95 응답시간 < 200ms 검증
```

### 팀 교육
```
배포 실패 후 팀 전체가 배워야 할 내용:

1. 이번 사건의 타임라인과 대응
2. 근본 원인 분석 방법 (5 Whys)
3. 성능 문제 예방 기법
4. 모니터링 및 알림 해석 방법
```

---

## ✅ Post-Mortem 체크리스트

배포 실패 후 반드시 해야 할 일:

```
기본:
  □ 롤백 완료 확인
  □ 긴급 증거 수집
  □ 팀 공지

분석 (1-2시간):
  □ 코드 변경사항 검토
  □ 에러 로그 분석
  □ 성능 데이터 분석
  □ 테스트 커버리지 검토
  □ 인프라 설정 검토

Post-Mortem (2시간 후):
  □ 회의 참석자 모임
  □ 타임라인 구성
  □ 근본 원인 분석 (5 Whys)
  □ 개선사항 도출
  □ 액션 아이템 정리

보고:
  □ Post-Mortem 보고서 작성
  □ 팀에 공유
  □ 개선사항 추적

예방:
  □ 개선사항 구현
  □ 테스트 강화
  □ 프로세스 개선
  □ 팀 교육
```

---

## 🎯 결론

배포 실패는 **조직의 실력을 보여주는 순간**입니다.

```
실패 후:
  ❌ 나쁜 팀: "누가 문제를 일으켰나?" (비난)
  ✅ 좋은 팀: "뭐가 문제였나?" (분석)
  🌟 훌륭한 팀: "어떻게 재발을 막을까?" (개선)
```

이 가이드가 여러분을 **훌륭한 팀**으로 만드는 데 도움이 되길 바랍니다.

---

**작성자**: Sena (세나)
**상태**: 📋 준비 완료
**다음 단계**: 배포 실패 시 이 가이드를 따르세요!
