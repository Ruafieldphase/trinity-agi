"""
Lumen Gateway Client

Lumen Gateway í•˜ì´ë¸Œë¦¬ë“œ AI ì‹œìŠ¤í…œê³¼ Ion Mentoring APIë¥¼ ì—°ê²°í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸
"""

import logging
import asyncio
import os
from datetime import datetime
from typing import Any, Dict, List, Optional

import httpx
from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)


class PersonaInfo(BaseModel):
    """í˜ë¥´ì†Œë‚˜ ì •ë³´"""

    name: str
    type: str
    emoji: str
    specialty: str


class LumenInferenceRequest(BaseModel):
    """Lumen Gateway ì¶”ë¡  ìš”ì²­"""

    message: str
    persona_key: Optional[str] = None  # Noneì´ë©´ ìë™ ì„ íƒ
    session_id: Optional[str] = "default"
    user_id: Optional[str] = None


class LumenInferenceResponse(BaseModel):
    """Lumen Gateway ì¶”ë¡  ì‘ë‹µ"""

    success: bool
    persona: PersonaInfo
    response: str
    sources: List[str]
    timestamp: str
    metadata: Dict[str, Any] = Field(default_factory=dict)


class LumenGatewayClient:
    """
    Lumen Gateway í´ë¼ì´ì–¸íŠ¸

    Lumen Gatewayì˜ í•˜ì´ë¸Œë¦¬ë“œ AI ì¶”ë¡  ì‹œìŠ¤í…œì„ í˜¸ì¶œí•˜ê³ 
    Ion Mentoring APIì™€ í†µí•©í•©ë‹ˆë‹¤.
    """

    def __init__(self, gateway_url: Optional[str] = None, timeout: int = 5, max_retries: int = 1):
        """
        Args:
            gateway_url: Lumen Gateway URL (ê¸°ë³¸ê°’: í™˜ê²½ ë³€ìˆ˜ LUMEN_GATEWAY_URL)
            timeout: ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì´ˆ) - ìµœì í™”: 30ì´ˆ â†’ 5ì´ˆ
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ - ìµœì í™”: 2íšŒ â†’ 1íšŒ
        """
        self.gateway_url = gateway_url or os.getenv(
            "LUMEN_GATEWAY_URL", "http://localhost:5000"  # ë¡œì»¬ ê°œë°œ ê¸°ë³¸ê°’
        )
        self.timeout = timeout
        self.max_retries = max_retries

        # ë¹„ë™ê¸° HTTP í´ë¼ì´ì–¸íŠ¸ (Connection Pool ìë™ ê´€ë¦¬)
        self.client = httpx.AsyncClient(
            timeout=timeout, limits=httpx.Limits(max_keepalive_connections=5, max_connections=10)
        )

        # í˜ë¥´ì†Œë‚˜ ë§¤í•‘ (Ion Mentoring â†” Lumen Gateway)
        self.persona_mapping = {
            "lua": "moon",  # ë£¨ì•„ ğŸŒ™ â†’ moon
            "elo": "square",  # ì—˜ë¡œ ğŸ“ â†’ square
            "nuri": "earth",  # ëˆ„ë¦¬ ğŸŒ â†’ earth
            "sena": "pen",  # ì„¸ë‚˜ âœ’ï¸ â†’ pen
        }

        logger.info(
            "LumenGatewayClient initialized with async httpx client",
            extra={"gateway_url": self.gateway_url, "timeout": timeout, "max_retries": max_retries},
        )

    async def close(self):
        """HTTP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ (ë¦¬ì†ŒìŠ¤ ì •ë¦¬)"""
        await self.client.aclose()

    def _detect_persona_from_query(self, query: str) -> Optional[str]:
        """
        ì¿¼ë¦¬ ë‚´ìš©ì—ì„œ ìµœì  í˜ë¥´ì†Œë‚˜ ìë™ ì„ íƒ

        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬

        Returns:
            str: í˜ë¥´ì†Œë‚˜ í‚¤ (moon/square/earth/pen) ë˜ëŠ” None
        """
        query_lower = query.lower()

        # í‚¤ì›Œë“œ ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ ì„ íƒ
        if any(
            word in query_lower for word in ["ì°½ì˜", "ì•„ì´ë””ì–´", "ìƒìƒ", "ëŠë‚Œ", "ê°ì„±", "ì˜ê°"]
        ):
            return "moon"  # ë£¨ì•„ ğŸŒ™
        elif any(word in query_lower for word in ["ì •ë¦¬", "êµ¬ì¡°", "ì²´ê³„", "ë¶„ì„", "ê³„íš", "ë‹¨ê³„"]):
            return "square"  # ì—˜ë¡œ ğŸ“
        elif any(word in query_lower for word in ["ê´€ì°°", "ë©”íƒ€", "ê· í˜•", "ì „ì²´", "í†µì°°", "íŒ¨í„´"]):
            return "earth"  # ëˆ„ë¦¬ ğŸŒ
        else:
            return "pen"  # ì„¸ë‚˜ âœ’ï¸ (ê¸°ë³¸ê°’)

    async def _infer_async(
        self,
        message: str,
        persona_key: Optional[str] = None,
        session_id: Optional[str] = "default",
        user_id: Optional[str] = None,
    ) -> LumenInferenceResponse:
        """
        Lumen Gatewayë¥¼ í†µí•´ AI ì¶”ë¡  ì‹¤í–‰ (ë¹„ë™ê¸°)

        Args:
            message: ì‚¬ìš©ì ë©”ì‹œì§€
            persona_key: í˜ë¥´ì†Œë‚˜ í‚¤ (Noneì´ë©´ ìë™ ì„ íƒ)
            session_id: ì„¸ì…˜ ID
            user_id: ì‚¬ìš©ì ID

        Returns:
            LumenInferenceResponse: ì¶”ë¡  ê²°ê³¼

        Raises:
            httpx.HTTPError: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        # í˜ë¥´ì†Œë‚˜ ìë™ ì„ íƒ
        if persona_key is None:
            persona_key = self._detect_persona_from_query(message)
            logger.info(
                f"Auto-selected persona: {persona_key}",
                extra={"message": message[:50], "persona": persona_key},
            )

        # Lumen Gateway API í˜¸ì¶œ (ì‹¤ì œ ì—”ë“œí¬ì¸íŠ¸: /chat)
        endpoint = f"{self.gateway_url}/chat"
        payload = {
            "message": message,
            "persona": persona_key,  # Lumen GatewayëŠ” 'persona' í•„ë“œ ì‚¬ìš©
            "session_id": session_id,
        }

        last_error = None
        for attempt in range(self.max_retries + 1):
            try:
                logger.info(
                    f"Calling Lumen Gateway (attempt {attempt + 1}/{self.max_retries + 1})",
                    extra={"endpoint": endpoint, "persona": persona_key},
                )

                response = await self.client.post(
                    endpoint, json=payload, headers={"Content-Type": "application/json"}
                )

                response.raise_for_status()  # HTTP ì—ëŸ¬ ì‹œ ì˜ˆì™¸ ë°œìƒ

                data = response.json()

                logger.info(
                    "Lumen Gateway response received",
                    extra={
                        "status_code": response.status_code,
                        "success": data.get("success"),
                        "persona_name": data.get("persona", {}).get("name"),
                        "response_length": len(data.get("response", "")),
                    },
                )

                # Lumen Gateway ì‘ë‹µ í˜•ì‹ íŒŒì‹±
                # {"success": true, "persona": {...}, "response": "...", "sources": [...]}
                if not data.get("success", False):
                    error_msg = data.get("error", "Unknown error")
                    logger.error(
                        f"Lumen Gateway returned success=false: {error_msg}",
                        extra={"full_response": data},
                    )
                    raise ValueError(f"Lumen Gateway returned success=false: {error_msg}")

                persona_data = data.get("persona", {})

                return LumenInferenceResponse(
                    success=True,
                    persona=PersonaInfo(
                        name=persona_data.get("name", "ì„¸ë‚˜"),
                        type=persona_data.get("type", "ë¸Œë¦¬ì§€í˜•"),
                        emoji=persona_data.get("emoji", "âœ’ï¸"),
                        specialty=persona_data.get("specialty", "ì—°ê²°, í†µí•©"),
                    ),
                    response=data.get("response", ""),
                    sources=data.get("sources", ["Google AI Studio"]),
                    timestamp=datetime.now().isoformat(),
                    metadata={"lumen_persona_key": persona_key},
                )

            except httpx.TimeoutException as e:
                last_error = e
                logger.warning(
                    f"Lumen Gateway timeout (attempt {attempt + 1})", extra={"error": str(e)}
                )
                if attempt < self.max_retries:
                    continue

            except httpx.HTTPError as e:
                last_error = e
                status_code = None
                if isinstance(e, httpx.HTTPStatusError):
                    status_code = e.response.status_code

                logger.error(
                    f"Lumen Gateway API error (attempt {attempt + 1})",
                    extra={"error": str(e), "status_code": status_code},
                )
                if attempt < self.max_retries:
                    continue

            except Exception as e:
                last_error = e
                logger.error("Unexpected error calling Lumen Gateway", extra={"error": str(e)})
                break

        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ fallback ì‘ë‹µ ë°˜í™˜
        logger.error("All retries failed for Lumen Gateway", extra={"last_error": str(last_error)})

        return self._create_fallback_response(message, persona_key or "pen")

    def infer(
        self,
        message: str,
        persona_key: Optional[str] = None,
        session_id: Optional[str] = "default",
        user_id: Optional[str] = None,
    ) -> LumenInferenceResponse:
        """ë™ê¸°ì‹ ë˜í¼: ë‚´ë¶€ì ìœ¼ë¡œ ë¹„ë™ê¸° ë¡œì§ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        try:
            return asyncio.run(self._infer_async(message=message, persona_key=persona_key, session_id=session_id, user_id=user_id))
        except RuntimeError as e:
            # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ ë‚´ì—ì„œ í˜¸ì¶œëœ ê²½ìš° (ì˜ˆ: FastAPI ë“±)
            # ì„ì‹œ ì´ë²¤íŠ¸ ë£¨í”„ë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì´ ì´ìƒì ì´ì§€ë§Œ,
            # í…ŒìŠ¤íŠ¸ í˜¸í™˜ì„±ì„ ìœ„í•´ ê°„ë‹¨ fallback ìœ¼ë¡œ ë™ì‘í•˜ë„ë¡ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            # ì—¬ê¸°ì„œëŠ” ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ì§€ ì•Šê³  fallback ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
            logger.warning(f"infer() called inside running event loop, returning fallback: {e}")
            persona_key_eff = persona_key or self._detect_persona_from_query(message)
            return self._create_fallback_response(message, persona_key_eff or "pen")

    def _create_fallback_response(self, message: str, persona_key: str) -> LumenInferenceResponse:
        """
        Lumen Gateway í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ Fallback ì‘ë‹µ ìƒì„±

        Args:
            message: ì›ë³¸ ë©”ì‹œì§€
            persona_key: í˜ë¥´ì†Œë‚˜ í‚¤

        Returns:
            LumenInferenceResponse: Fallback ì‘ë‹µ
        """
        fallback_personas = {
            "moon": PersonaInfo(name="ë£¨ì•„", type="ê°ì‘í˜•", emoji="ğŸŒ™", specialty="ì§ê°, ì°½ì˜"),
            "square": PersonaInfo(name="ì—˜ë¡œ", type="êµ¬ì¡°í˜•", emoji="ğŸ“", specialty="ë…¼ë¦¬, ì²´ê³„"),
            "earth": PersonaInfo(name="ëˆ„ë¦¬", type="ê´€ì°°í˜•", emoji="ğŸŒ", specialty="ë©”íƒ€, ê· í˜•"),
            "pen": PersonaInfo(name="ì„¸ë‚˜", type="ë¸Œë¦¬ì§€í˜•", emoji="âœ’ï¸", specialty="ì—°ê²°, í†µí•©"),
        }

        persona = fallback_personas.get(persona_key, fallback_personas["pen"])

        fallback_message = (
            f"{persona.emoji} {persona.name}ì…ë‹ˆë‹¤. "
            f"í˜„ì¬ Lumen Gatewayì— ì—°ê²°í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤. "
            f"ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        )

        return LumenInferenceResponse(
            success=False,
            persona=persona,
            response=fallback_message,
            sources=["fallback"],
            timestamp=datetime.now().isoformat(),
            metadata={"fallback": True, "reason": "gateway_unavailable"},
        )

    async def _health_check_async(self) -> bool:
        """
        Lumen Gateway í—¬ìŠ¤ ì²´í¬ (ë¹„ë™ê¸°)

        Returns:
            bool: ì •ìƒ ì—¬ë¶€
        """
        try:
            # Lumen GatewayëŠ” /status ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
            endpoint = f"{self.gateway_url}/status"
            response = await self.client.get(endpoint)

            if response.status_code == 200:
                data = response.json()
                return data.get("ready", False)

            return False
        except Exception as e:
            logger.warning(f"Lumen Gateway health check failed: {e}")
            return False

    def health_check(self) -> bool:
        """ë™ê¸°ì‹ ë˜í¼: ë‚´ë¶€ì ìœ¼ë¡œ ë¹„ë™ê¸° ë¡œì§ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        try:
            return asyncio.run(self._health_check_async())
        except RuntimeError as e:
            logger.warning(f"health_check() called inside running event loop: {e}")
            return False
        except Exception as e:
            logger.warning(f"Lumen Gateway health check failed: {e}")
            return False


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒì )
_lumen_client_instance: Optional[LumenGatewayClient] = None


def get_lumen_client() -> LumenGatewayClient:
    """
    Lumen Gateway í´ë¼ì´ì–¸íŠ¸ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜

    Returns:
        LumenGatewayClient: í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤
    """
    global _lumen_client_instance

    if _lumen_client_instance is None:
        _lumen_client_instance = LumenGatewayClient()

    return _lumen_client_instance


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰

    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )


async def _test_main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë¹„ë™ê¸°)"""
    import sys

    # í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    client = LumenGatewayClient(gateway_url="http://localhost:5000")

    try:
        # í—¬ìŠ¤ ì²´í¬
        print("\nğŸ” Health Check...")
        is_healthy = client.health_check()
        print(f"Lumen Gateway Health: {'âœ… OK' if is_healthy else 'âŒ FAILED'}\n")

        if not is_healthy:
            print("âš ï¸ Lumen Gateway is not running. Start it first:")
            print("  cd d:\\nas_backup\\LLM_Unified")
            print("  python lumen_hybrid_gateway.py")
            sys.exit(1)

        # ì¶”ë¡  í…ŒìŠ¤íŠ¸
        print("ğŸ§ª Testing inference...")
        test_queries = [
            "ì°½ì˜ì ì¸ ì•„ì´ë””ì–´ê°€ í•„ìš”í•´",
            "ì´ ë¬¸ì œë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ë¶„ì„í•´ì¤˜",
            "ì „ì²´ì ì¸ ìƒí™©ì„ ë©”íƒ€ì ìœ¼ë¡œ ë³´ê³  ì‹¶ì–´",
            "ì—¬ëŸ¬ ê´€ì ì„ í†µí•©í•´ì„œ ì„¤ëª…í•´ì¤˜",
        ]

        for query in test_queries:
            print(f"\nğŸ“ Query: {query}")
            result = client.infer(message=query)
            print(f"   Persona: {result.persona.emoji} {result.persona.name}")
            print(f"   Success: {result.success}")
            print(f"   Response: {result.response[:100]}...")
            print(f"   Sources: {result.sources}")

    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        await client.close()


# === Lumen Agent System Integration ===


class AgentExecuteRequest(BaseModel):
    """ì—ì´ì „íŠ¸ ì‹¤í–‰ ìš”ì²­"""

    task: str
    files: Optional[List[str]] = None
    persona: Optional[str] = None
    output: Optional[str] = None


class AgentExecuteResponse(BaseModel):
    """ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‘ë‹µ"""

    success: bool
    agent: str
    persona: str
    task: str
    files_analyzed: List[str]
    output_file: str
    execution_time: float
    metadata: Dict[str, Any] = Field(default_factory=dict)


async def execute_agent(
    task: str,
    files: Optional[List[str]] = None,
    persona: Optional[str] = None,
    output: Optional[str] = None,
) -> AgentExecuteResponse:
    """
    Lumen Agent System ì‹¤í–‰ (ë¹„ë™ê¸° ë˜í¼)

    Args:
        task: ìˆ˜í–‰í•  ì‘ì—…
        files: ë¶„ì„í•  íŒŒì¼ ëª©ë¡
        persona: í˜ë¥´ì†Œë‚˜ ê°•ì œ ì§€ì • (Noneì´ë©´ ìë™ ê°ì§€)
        output: ê²°ê³¼ ì €ì¥ ê²½ë¡œ

    Returns:
        AgentExecuteResponse: ì‹¤í–‰ ê²°ê³¼

    Raises:
        ImportError: lumen_agent_system.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ì„ ë•Œ
        Exception: ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ
    """
    import sys
    import time
    from pathlib import Path

    # lumen_agent_system.py ì„í¬íŠ¸
    project_root = Path(__file__).parent.parent.parent.parent
    sys.path.insert(0, str(project_root))

    try:
        from lumen_agent_system import LumenAgentSystem
    except ImportError as e:
        logger.error(f"Failed to import lumen_agent_system: {e}")
        raise ImportError(
            "lumen_agent_system.py not found. " "Make sure it's in the LLM_Unified directory."
        )

    # ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì‹¤í–‰
    system = LumenAgentSystem()
    start_time = time.time()

    result = system.execute(task=task, files=files, persona=persona)

    execution_time = time.time() - start_time

    # ì‘ë‹µ ìƒì„±
    return AgentExecuteResponse(
        success=True,
        agent=result["agent"],
        persona=result["persona"],
        task=task,
        files_analyzed=result.get("files_analyzed", files or []),
        output_file=result["output_file"],
        execution_time=execution_time,
        metadata={
            "auto_detected": persona is None,
            "detected_persona": result.get("detected_persona"),
        },
    )


if __name__ == "__main__":
    import asyncio

    asyncio.run(_test_main())
