"""
Gitko Integrated Orchestrator - ê¸°ì¡´ êµ¬ì¡° í†µí•© ë²„ì „
====================================================

ê¸°ì¡´ ì‹œìŠ¤í…œ í†µí•©:
1. naeda-ai-core: /dispatch-agent-task íŒ¨í„´ (ìì—°ì–´ â†’ JSON â†’ INBOX)
2. orchestrator_main: TaskDefinition, TaskExecution, State Management
3. local_file_agent: CLI ë„êµ¬ í†µí•©, Context Storage
4. LangGraph: Send() ê¸°ë°˜ ë³‘ë ¬ ë””ìŠ¤íŒ¨ì¹˜

ëª©í‘œ: Gitkoê°€ ëŒ€í™” ì¤‘ ìë™ìœ¼ë¡œ ì‘ì—…ì„ ê°ì§€í•˜ê³  ê¸°ì¡´ ì¸í”„ë¼ë¥¼ í™œìš©í•˜ì—¬ ì‹¤í–‰
"""

import asyncio
import json
import subprocess
import uuid
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from pathlib import Path
from typing import Dict, List, Literal, Optional

# ============================================================================
# 1. ê¸°ì¡´ orchestrator_mainì˜ TaskDefinition/TaskStatus ì¬ì‚¬ìš©
# ============================================================================


class TaskStatus(Enum):
    """ì‘ì—… ìƒíƒœ (orchestrator_mainê³¼ ë™ì¼)"""

    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    RETRYING = "retrying"
    CANCELLED = "cancelled"
    SKIPPED = "skipped"


class AgentType(Enum):
    """ì—ì´ì „íŠ¸ íƒ€ì…"""

    GITKO = "gitko"  # ì§ì ‘ êµ¬í˜„
    LUBIT = "lubit"  # ë¦¬ë·°/ê²€ì¦
    SIAN = "sian"  # ë¦¬íŒ©í„°ë§/ê°œì„ 
    PARALLEL = "parallel"  # Lubit + Sian ë³‘ë ¬


@dataclass
class TaskContext:
    """ì‘ì—… ì»¨í…ìŠ¤íŠ¸ (naeda-ai-coreì˜ AgentTaskRequestì™€ ìœ ì‚¬)"""

    task_id: str = field(
        default_factory=lambda: f"task_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S_%f')}"
    )
    task_type: Literal["review", "refactor", "parallel", "none"] = "none"
    description: str = ""
    confidence: float = 0.0
    files_mentioned: List[str] = field(default_factory=list)
    keywords: List[str] = field(default_factory=list)
    agent: AgentType = AgentType.GITKO

    # orchestrator_mainê³¼ì˜ í†µí•©
    status: TaskStatus = TaskStatus.PENDING
    max_retries: int = 2
    timeout_seconds: int = 120

    # ì‹¤í–‰ ë©”íƒ€ë°ì´í„°
    created_at: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
    started_at: Optional[str] = None
    completed_at: Optional[str] = None


@dataclass
class DispatchResult:
    """ì‘ì—… ì‹¤í–‰ ê²°ê³¼ (orchestrator_mainì˜ TaskExecutionê³¼ ìœ ì‚¬)"""

    task_id: str
    agent: str
    status: Literal["success", "error", "timeout"]
    artifacts: List[Path] = field(default_factory=list)
    summary: str = ""
    elapsed_ms: int = 0
    error_message: Optional[str] = None

    # orchestrator_main í†µí•©
    execution_id: str = field(default_factory=lambda: f"exec_{uuid.uuid4().hex[:8]}")
    retry_count: int = 0


# ============================================================================
# 2. INBOX ê¸°ë°˜ ì‘ì—… ë””ìŠ¤íŒ¨ì¹˜ (naeda-ai-core íŒ¨í„´)
# ============================================================================


class AgentInboxDispatcher:
    """
    naeda-ai-coreì˜ /dispatch-agent-task íŒ¨í„´ì„ ë¡œì»¬ì—ì„œ êµ¬í˜„
    - ìì—°ì–´ ì„¤ëª… â†’ JSON ë³€í™˜
    - INBOXì— ì‘ì—… íŒŒì¼ ìƒì„±
    - ì—ì´ì „íŠ¸ê°€ INBOXë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ì‘ì—… ìˆ˜í–‰
    """

    def __init__(self, repo_root: Path):
        self.repo_root = repo_root

        # local_file_agentì˜ CONTEXT_STORAGE íŒ¨í„´ í™œìš©
        self.inbox_path = repo_root / "LLM_Unified" / "agent_inbox_local"
        self.inbox_path.mkdir(parents=True, exist_ok=True)

        self.outputs_path = repo_root / "outputs"
        self.outputs_path.mkdir(parents=True, exist_ok=True)

        self.scripts_path = repo_root / "scripts"

    def create_task_json(self, task_ctx: TaskContext) -> Path:
        """
        ì‘ì—… ì»¨í…ìŠ¤íŠ¸ë¥¼ JSON íŒŒì¼ë¡œ ë³€í™˜í•˜ì—¬ INBOXì— ì €ì¥
        (naeda-ai-coreì˜ dispatch_agent_task ë¡œì§)
        """
        task_json = {
            "task_id": task_ctx.task_id,
            "action": f"DISPATCH_{task_ctx.agent.value.upper()}",
            "payload": {
                "task_type": task_ctx.task_type,
                "description": task_ctx.description,
                "confidence": task_ctx.confidence,
                "files": task_ctx.files_mentioned,
                "keywords": task_ctx.keywords,
                "max_retries": task_ctx.max_retries,
                "timeout_seconds": task_ctx.timeout_seconds,
            },
            "metadata": {"created_at": task_ctx.created_at, "status": task_ctx.status.value},
        }

        task_file = self.inbox_path / f"{task_ctx.task_id}.json"
        with open(task_file, "w", encoding="utf-8") as f:
            json.dump(task_json, f, ensure_ascii=False, indent=2)

        return task_file

    async def dispatch_to_inbox(self, task_ctx: TaskContext) -> Path:
        """INBOXì— ì‘ì—… íŒŒì¼ ìƒì„± (ë¹„ë™ê¸°)"""
        return await asyncio.to_thread(self.create_task_json, task_ctx)

    def check_task_completion(self, task_id: str) -> Optional[DispatchResult]:
        """
        INBOXì—ì„œ ì™„ë£Œëœ ì‘ì—… ê²°ê³¼ í™•ì¸
        (ì—ì´ì „íŠ¸ê°€ ì‘ì—… ì™„ë£Œ ì‹œ {task_id}_result.json ìƒì„±í•œë‹¤ê³  ê°€ì •)
        """
        result_file = self.inbox_path / f"{task_id}_result.json"
        if not result_file.exists():
            return None

        with open(result_file, "r", encoding="utf-8") as f:
            result_data = json.load(f)

        return DispatchResult(
            task_id=task_id,
            agent=result_data.get("agent", "unknown"),
            status=result_data.get("status", "error"),
            artifacts=[Path(p) for p in result_data.get("artifacts", [])],
            summary=result_data.get("summary", ""),
            elapsed_ms=result_data.get("elapsed_ms", 0),
            error_message=result_data.get("error_message"),
        )


# ============================================================================
# 3. PowerShell ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ê¸° (ê¸°ì¡´ ìŠ¤í¬ë¦½íŠ¸ í™œìš©)
# ============================================================================


class PowerShellScriptExecutor:
    """
    ê¸°ì¡´ PowerShell ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” ì–´ëŒ‘í„°
    (gitko_auto_dispatch.ps1, dispatch_to_lubit_and_sian.ps1 ë“±)
    """

    def __init__(self, repo_root: Path):
        self.repo_root = repo_root
        self.scripts_dir = repo_root / "scripts"
        self.outputs_dir = repo_root / "outputs"

    async def execute_script(
        self, script_name: str, args: List[str], timeout: int = 120
    ) -> DispatchResult:
        """PowerShell ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰"""
        start = datetime.now(timezone.utc)
        script_path = self.scripts_dir / script_name

        cmd = [
            "powershell",
            "-NoProfile",
            "-ExecutionPolicy",
            "Bypass",
            "-File",
            str(script_path),
        ] + args

        try:
            proc = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                # PowerShell ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
                creationflags=(
                    subprocess.CREATE_NO_WINDOW if hasattr(subprocess, "CREATE_NO_WINDOW") else 0
                ),
            )

            stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=timeout)

            elapsed = int((datetime.now(timezone.utc) - start).total_seconds() * 1000)

            # ì¸ì½”ë”© ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            try:
                stdout.decode("utf-8", errors="replace")
                stderr_text = stderr.decode("utf-8", errors="replace")
            except Exception:
                str(stdout)
                stderr_text = str(stderr)

            # ìƒì„±ëœ ì•„í‹°íŒ©íŠ¸ ê²€ìƒ‰
            artifacts = list(self.outputs_dir.glob("*"))
            recent_artifacts = sorted(artifacts, key=lambda p: p.stat().st_mtime, reverse=True)[
                :5
            ]  # ìµœê·¼ 5ê°œ

            return DispatchResult(
                task_id=f"ps_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}",
                agent=script_name.replace(".ps1", ""),
                status="success" if proc.returncode == 0 else "error",
                artifacts=recent_artifacts,
                summary=f"Script {script_name} completed",
                elapsed_ms=elapsed,
                error_message=stderr_text if proc.returncode != 0 else None,
            )

        except asyncio.TimeoutError:
            return DispatchResult(
                task_id=f"ps_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}",
                agent=script_name.replace(".ps1", ""),
                status="timeout",
                summary=f"Script {script_name} timed out after {timeout}s",
                elapsed_ms=timeout * 1000,
            )
        except Exception as e:
            return DispatchResult(
                task_id=f"ps_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}",
                agent=script_name.replace(".ps1", ""),
                status="error",
                summary=f"Script execution failed: {str(e)}",
                elapsed_ms=0,
                error_message=str(e),
            )


# ============================================================================
# 4. í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (LangGraph Send() íŒ¨í„´)
# ============================================================================


class GitkoIntegratedOrchestrator:
    """
    ëª¨ë“  ê¸°ì¡´ êµ¬ì¡°ë¥¼ í†µí•©í•œ ì¤‘ì•™ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°

    í†µí•© ìš”ì†Œ:
    - orchestrator_main: ì‘ì—… ìƒíƒœ ê´€ë¦¬
    - naeda-ai-core: INBOX ê¸°ë°˜ ë””ìŠ¤íŒ¨ì¹˜
    - local_file_agent: CLI ë„êµ¬ ë° Context Storage
    - gitko_auto_dispatch.ps1: ê¸°ì¡´ PowerShell ë¡œì§
    """

    def __init__(self, repo_root: Path, use_inbox: bool = True, use_powershell: bool = True):
        self.repo_root = repo_root
        self.use_inbox = use_inbox
        self.use_powershell = use_powershell

        # ê¸°ì¡´ ì‹œìŠ¤í…œ í†µí•©
        self.inbox_dispatcher = AgentInboxDispatcher(repo_root)
        self.ps_executor = PowerShellScriptExecutor(repo_root)

        # ì‘ì—… ì¶”ì  (orchestrator_main íŒ¨í„´)
        self.active_tasks: Dict[str, TaskContext] = {}
        self.pending_results: Dict[str, asyncio.Task] = {}

    async def dispatch_task(self, task_ctx: TaskContext) -> str:
        """
        ì‘ì—… ë””ìŠ¤íŒ¨ì¹˜ (LangGraph Send() íŒ¨í„´)

        ë‘ ê°€ì§€ ì‹¤í–‰ ë°©ì‹:
        1. INBOX ê¸°ë°˜ (naeda-ai-core íŒ¨í„´): ëŠìŠ¨í•œ ê²°í•©, ì—ì´ì „íŠ¸ê°€ ë…ë¦½ ì‹¤í–‰
        2. PowerShell ì§ì ‘ ì‹¤í–‰: ë¹ ë¥¸ í”¼ë“œë°±, ê¸°ì¡´ ìŠ¤í¬ë¦½íŠ¸ í™œìš©
        """
        self.active_tasks[task_ctx.task_id] = task_ctx
        task_ctx.status = TaskStatus.RUNNING
        task_ctx.started_at = datetime.now(timezone.utc).isoformat()

        if self.use_inbox:
            # INBOX ë°©ì‹: ì‘ì—… íŒŒì¼ ìƒì„±
            await self.inbox_dispatcher.dispatch_to_inbox(task_ctx)
            # ì—ì´ì „íŠ¸ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ ëŒ€ê¸°
            result_task = asyncio.create_task(
                self._wait_for_inbox_result(task_ctx.task_id, task_ctx.timeout_seconds)
            )
        else:
            # PowerShell ì§ì ‘ ì‹¤í–‰
            result_task = asyncio.create_task(self._execute_powershell_task(task_ctx))

        self.pending_results[task_ctx.task_id] = result_task
        return task_ctx.task_id

    async def _wait_for_inbox_result(self, task_id: str, timeout: int) -> DispatchResult:
        """INBOXì—ì„œ ê²°ê³¼ í´ë§"""
        start = datetime.now(timezone.utc)
        poll_interval = 2  # 2ì´ˆë§ˆë‹¤ ì²´í¬

        while (datetime.now(timezone.utc) - start).total_seconds() < timeout:
            result = self.inbox_dispatcher.check_task_completion(task_id)
            if result:
                return result
            await asyncio.sleep(poll_interval)

        # íƒ€ì„ì•„ì›ƒ
        return DispatchResult(
            task_id=task_id,
            agent="inbox_timeout",
            status="timeout",
            summary=f"Task did not complete within {timeout}s",
            elapsed_ms=timeout * 1000,
        )

    async def _execute_powershell_task(self, task_ctx: TaskContext) -> DispatchResult:
        """PowerShell ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰"""
        # ì—ì´ì „íŠ¸ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ìŠ¤í¬ë¦½íŠ¸ ì„ íƒ
        script_map = {
            AgentType.LUBIT: "prepare_lubit_review_packet.ps1",
            AgentType.SIAN: None,  # Python ë„êµ¬ ì‚¬ìš©
            AgentType.PARALLEL: "dispatch_to_lubit_and_sian.ps1",
            AgentType.GITKO: "gitko_auto_dispatch.ps1",
        }

        script_name = script_map.get(task_ctx.agent)

        if script_name:
            # ìŠ¤í¬ë¦½íŠ¸ë³„ íŒŒë¼ë¯¸í„° ë§¤í•‘
            if script_name == "dispatch_to_lubit_and_sian.ps1":
                args = ["-Issue", task_ctx.description]
            else:
                args = ["-WorkRequest", task_ctx.description]

            return await self.ps_executor.execute_script(
                script_name, args, task_ctx.timeout_seconds
            )
        else:
            # Python ë„êµ¬ ì‹¤í–‰ (Sianì˜ ê²½ìš°)
            return await self._execute_python_tool(task_ctx)

    async def _execute_python_tool(self, task_ctx: TaskContext) -> DispatchResult:
        """Python ë„êµ¬ ì‹¤í–‰ (gemini_code_assist_poc.py ë“±)"""
        start = datetime.now(timezone.utc)
        tool_script = self.repo_root / "tools" / "gemini_code_assist_poc.py"
        venv_python = self.repo_root / "LLM_Unified" / ".venv" / "Scripts" / "python.exe"

        python_exe = str(venv_python) if venv_python.exists() else "python"
        out_file = self.inbox_dispatcher.outputs_path / f"sian_{task_ctx.task_id}.md"

        cmd = [
            python_exe,
            str(tool_script),
            "--issue",
            task_ctx.description,
            "--out",
            str(out_file),
        ]

        try:
            proc = await asyncio.create_subprocess_exec(
                *cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE
            )

            stdout, stderr = await asyncio.wait_for(
                proc.communicate(), timeout=task_ctx.timeout_seconds
            )

            elapsed = int((datetime.now(timezone.utc) - start).total_seconds() * 1000)

            return DispatchResult(
                task_id=task_ctx.task_id,
                agent="sian",
                status="success" if proc.returncode == 0 else "error",
                artifacts=[out_file] if out_file.exists() else [],
                summary="Python tool completed",
                elapsed_ms=elapsed,
                error_message=stderr.decode() if proc.returncode != 0 else None,
            )

        except asyncio.TimeoutError:
            return DispatchResult(
                task_id=task_ctx.task_id,
                agent="sian",
                status="timeout",
                summary="Python tool timed out",
                elapsed_ms=task_ctx.timeout_seconds * 1000,
            )

    async def get_result(self, task_id: str, timeout: float = 5.0) -> Optional[DispatchResult]:
        """ì‘ì—… ê²°ê³¼ í™•ì¸ (íƒ€ì„ì•„ì›ƒ ë‚´ì— ì™„ë£Œë˜ë©´ ë°˜í™˜)"""
        if task_id not in self.pending_results:
            return None

        result_task = self.pending_results[task_id]

        try:
            result = await asyncio.wait_for(result_task, timeout=timeout)

            # ì‘ì—… ì™„ë£Œ ì²˜ë¦¬
            if task_id in self.active_tasks:
                self.active_tasks[task_id].status = TaskStatus.COMPLETED
                self.active_tasks[task_id].completed_at = datetime.now(timezone.utc).isoformat()

            del self.pending_results[task_id]
            return result

        except asyncio.TimeoutError:
            return None  # ì•„ì§ ì§„í–‰ ì¤‘

    def format_result_summary(self, result: DispatchResult) -> str:
        """ê²°ê³¼ë¥¼ ëŒ€í™”ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·"""
        lines = [
            f"## ğŸ¤– {result.agent.upper()} ì—ì´ì „íŠ¸ ì‘ì—… ì™„ë£Œ",
            "",
            f"**ìƒíƒœ**: {result.status}",
            f"**ì†Œìš” ì‹œê°„**: {result.elapsed_ms}ms",
            f"**ìš”ì•½**: {result.summary}",
        ]

        if result.artifacts:
            lines.append("")
            lines.append("**ìƒì„±ëœ íŒŒì¼**:")
            for artifact in result.artifacts:
                lines.append(f"- `{artifact.name}`")

        if result.error_message:
            lines.append("")
            lines.append("**ì˜¤ë¥˜**:")
            lines.append(f"```\n{result.error_message}\n```")

        return "\n".join(lines)


# ============================================================================
# 5. ëŒ€í™” ë¶„ì„ê¸° (ê¸°ì¡´ ConversationAnalyzer ê°œì„ )
# ============================================================================


class IntegratedConversationAnalyzer:
    """
    ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ (ê¸°ì¡´ íŒ¨í„´ ìœ ì§€ + í–¥ìƒ)
    """

    PATTERNS = {
        "review": [
            r"\b(review|validate|check|audit|inspect|verify)\b",
            r"(ë¦¬ë·°|ê²€í† |í™•ì¸|ê²€ì¦|ì ê²€|ê²€ì‚¬)",
        ],
        "refactor": [
            r"\b(refactor|optimize|improve|enhance|modernize)\b",
            r"(ê°œì„ |ë¦¬íŒ©í„°|ìµœì í™”|ì„±ëŠ¥|í–¥ìƒ)",
        ],
        "parallel": [
            r"\b(review.*improve|improve.*review)\b",
            r"(ë¦¬ë·°.*ê°œì„ |ê°œì„ .*ë¦¬ë·°)",
            r"\b(both|comprehensive|thorough)\b",
            r"(ì „ì²´|ì¢…í•©|í¬ê´„)",
        ],
    }

    def __init__(self, confidence_threshold: float = 0.6):
        self.threshold = confidence_threshold

    def analyze(self, message: str, context: Optional[str] = None) -> TaskContext:
        """ëŒ€í™” ë¶„ì„ â†’ TaskContext ìƒì„±"""
        import re

        full_text = f"{message} {context or ''}".lower()

        scores = {"review": 0.0, "refactor": 0.0, "parallel": 0.0}
        matched_keywords = []

        for task_type, patterns in self.PATTERNS.items():
            for pattern in patterns:
                matches = re.findall(pattern, full_text, re.IGNORECASE)
                if matches:
                    scores[task_type] += len(matches) * 0.5  # 0.3 â†’ 0.5ë¡œ ì¦ê°€
                    matched_keywords.extend(matches)

        # ì ìˆ˜ ì •ê·œí™”
        for task_type in scores:
            scores[task_type] = min(scores[task_type], 1.0)

        # ì‘ì—… íƒ€ì… ê²°ì •
        if scores["parallel"] > self.threshold:
            task_type = "parallel"
            confidence = scores["parallel"]
            agent = AgentType.PARALLEL
        elif scores["review"] > self.threshold and scores["refactor"] > self.threshold:
            task_type = "parallel"
            confidence = (scores["review"] + scores["refactor"]) / 2
            agent = AgentType.PARALLEL
        elif scores["review"] > self.threshold:
            task_type = "review"
            confidence = scores["review"]
            agent = AgentType.LUBIT
        elif scores["refactor"] > self.threshold:
            task_type = "refactor"
            confidence = scores["refactor"]
            agent = AgentType.SIAN
        else:
            task_type = "none"
            confidence = 0.0
            agent = AgentType.GITKO

        # íŒŒì¼ íŒ¨í„´ ì¶”ì¶œ
        file_pattern = r"[a-zA-Z0-9_\-/\\]+\.(?:py|js|ts|md|json|ps1)"
        files_mentioned = re.findall(file_pattern, full_text)

        return TaskContext(
            task_type=task_type,
            description=message[:200],
            confidence=confidence,
            files_mentioned=list(set(files_mentioned)),
            keywords=list(set(matched_keywords)),
            agent=agent,
        )


# ============================================================================
# 6. í…ŒìŠ¤íŠ¸ ë° ì‚¬ìš© ì˜ˆì‹œ
# ============================================================================


async def test_integrated_orchestrator():
    """í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í…ŒìŠ¤íŠ¸"""

    repo_root = Path("d:/nas_backup")

    # 1. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”
    orchestrator = GitkoIntegratedOrchestrator(
        repo_root=repo_root, use_inbox=False, use_powershell=True  # PowerShell ì§ì ‘ ì‹¤í–‰ ëª¨ë“œ
    )

    # 2. ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = IntegratedConversationAnalyzer(confidence_threshold=0.6)

    # 3. í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ë“¤
    test_messages = [
        "Please review the deployment scripts and suggest improvements",
        "ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ê²€í† í•´ì£¼ì„¸ìš”",
        "ì½”ë“œ ì„±ëŠ¥ì„ ê°œì„ í•´ì£¼ì„¸ìš”",
    ]

    for msg in test_messages:
        print(f"\n{'='*60}")
        print(f"ë©”ì‹œì§€: {msg}")
        print(f"{'='*60}")

        # ë¶„ì„
        task_ctx = analyzer.analyze(msg)
        print(f"ê°ì§€ëœ ì‘ì—…: {task_ctx.task_type}")
        print(f"ì‹ ë¢°ë„: {task_ctx.confidence:.0%}")
        print(f"ì—ì´ì „íŠ¸: {task_ctx.agent.value}")

        if task_ctx.task_type != "none":
            # ë””ìŠ¤íŒ¨ì¹˜
            print("\nì‘ì—… ë””ìŠ¤íŒ¨ì¹˜ ì¤‘...")
            task_id = await orchestrator.dispatch_task(task_ctx)

            # ê²°ê³¼ ëŒ€ê¸° (ìµœëŒ€ 5ì´ˆ)
            result = await orchestrator.get_result(task_id, timeout=5.0)

            if result:
                print(f"\n{orchestrator.format_result_summary(result)}")
            else:
                print("\nâ³ ì‘ì—…ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê³„ì† ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤...")


if __name__ == "__main__":
    import asyncio

    asyncio.run(test_integrated_orchestrator())
