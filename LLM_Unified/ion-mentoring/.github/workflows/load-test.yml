name: 부하 테스트 (Scheduled Load Testing)

on:
    # 매일 오전 3시(UTC) / 12 PM(KST)에 실행됩니다.
    schedule:
        - cron: "0 3 * * *"

    # 수동 실행 지원
    workflow_dispatch:
        inputs:
            test_duration:
                description: "테스트 지속 시간 (분)"
                required: false
                default: "5"
            max_users:
                description: "최대 동시 사용자 수"
                required: false
                default: "200"

env:
    API_HOST: https://ion-api-64076350717.us-central1.run.app
    PYTHON_VERSION: "3.13"

jobs:
    load-test:
        name: Locust 부하 테스트
        runs-on: ubuntu-latest
        timeout-minutes: 30

        steps:
            - name: 코드 체크아웃
              uses: actions/checkout@v4

            - name: Python ${{ env.PYTHON_VERSION }} 설정
              uses: actions/setup-python@v4
              with:
                  python-version: ${{ env.PYTHON_VERSION }}
                  cache: "pip"

            - name: 의존성 설치
              run: |
                  python -m pip install --upgrade pip
                  pip install -r ion-mentoring/requirements-api.txt

            - name: 출력 디렉토리 생성
              run: mkdir -p ion-mentoring/outputs

            - name: Light 시나리오 실행
              working-directory: ion-mentoring
              continue-on-error: true
              run: |
                  python -m locust -f load_test.py \
                    --host=${{ env.API_HOST }} \
                    --users 10 \
                    --spawn-rate 0.5 \
                    --run-time 2m \
                    --headless \
                    --csv=outputs/load_test_light

            - name: Medium 시나리오 실행
              working-directory: ion-mentoring
              continue-on-error: true
              run: |
                  sleep 30
                  python -m locust -f load_test.py \
                    --host=${{ env.API_HOST }} \
                    --users 50 \
                    --spawn-rate 2 \
                    --run-time 3m \
                    --headless \
                    --csv=outputs/load_test_medium

            - name: Heavy 시나리오 실행
              working-directory: ion-mentoring
              continue-on-error: true
              run: |
                  sleep 30
                  python -m locust -f load_test.py \
                    --host=${{ env.API_HOST }} \
                    --users 100 \
                    --spawn-rate 5 \
                    --run-time 5m \
                    --headless \
                    --csv=outputs/load_test_heavy

            - name: Stress 시나리오 실행
              working-directory: ion-mentoring
              continue-on-error: true
              run: |
                  sleep 30
                  python -m locust -f load_test.py \
                    --host=${{ env.API_HOST }} \
                    --users ${{ github.event.inputs.max_users || '150' }} \
                    --spawn-rate 5 \
                    --run-time ${{ github.event.inputs.test_duration || '10' }}m \
                    --headless \
                    --csv=outputs/load_test_stress

            - name: 테스트 결과 요약 생성
              if: always()
              working-directory: ion-mentoring
              run: |
                  cat > outputs/test_summary.md << 'EOF'
                  # 부하 테스트 결과 요약

                  **실행 시간**: $(date -u +'%Y-%m-%d %H:%M:%S UTC')
                  **브랜치**: ${{ github.ref_name }}
                  **커밋**: ${{ github.sha }}

                  ## 시나리오 결과

                  ### Light (10 users, 2min)
                  - CSV: [load_test_light_stats.csv](./load_test_light_stats.csv)
                  - HTML: [load_test_light.html](./load_test_light.html)

                  ### Medium (50 users, 3min)
                  - CSV: [load_test_medium_stats.csv](./load_test_medium_stats.csv)
                  - HTML: [load_test_medium.html](./load_test_medium.html)

                  ### Heavy (100 users, 5min)
                  - CSV: [load_test_heavy_stats.csv](./load_test_heavy_stats.csv)
                  - HTML: [load_test_heavy.html](./load_test_heavy.html)

                  ### Stress (${{ github.event.inputs.max_users || '200' }} users, ${{ github.event.inputs.test_duration || '10' }}min)
                  - CSV: [load_test_stress_stats.csv](./load_test_stress_stats.csv)

                  ## 다음 단계

                  1. HTML 리포트에서 상세 지표 확인
                  2. P95/P99 latency가 목표치 초과 시 성능 최적화
                  3. Cloud Monitoring 대시보드에서 인스턴스 스케일링 검토
                  EOF

            - name: 불필요한 파일 정리
              if: always()
              working-directory: ion-mentoring
              run: |
                  rm -f outputs/*.html || true
                  rm -rf outputs/load_test_*_stats_history.csv || true

            - name: 테스트 결과 아티팩트 업로드
              if: always()
              continue-on-error: true
              uses: actions/upload-artifact@v4
              with:
                  name: load-test-results-${{ github.run_number }}
                  path: |
                      ion-mentoring/outputs/*.csv
                      ion-mentoring/outputs/test_summary.md
                  retention-days: 3

            - name: 실패 시 Slack 알림 (선택사항)
              if: failure()
              env:
                SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
              run: |
                  echo "부하 테스트 실패! 상세 내용은 GitHub Actions 로그를 확인하세요."
                  if [ -n "$SLACK_WEBHOOK_URL" ]; then
                    curl -X POST -H 'Content-type: application/json' \
                    --data "{\"text\":\"[${{ github.repository }}] 부하 테스트 실패! 확인이 필요합니다.\n링크: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}\"}" \
                    "$SLACK_WEBHOOK_URL"
                  fi

    analyze:
        name: 결과 분석 및 리포트
        runs-on: ubuntu-latest
        needs: load-test
        if: always()

        steps:
            - name: 아티팩트 존재 확인
              id: check_artifacts
              run: |
                  api_url="https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts"
                  token="${{ secrets.GITHUB_TOKEN }}"
                  artifact_name="load-test-results-${{ github.run_number }}"
                  
                  echo "Checking for artifact: $artifact_name"
                  response=$(curl -s -H "Authorization: Bearer $token" "$api_url")
                  count=$(echo "$response" | python3 -c "import sys, json; print(sum(1 for a in json.load(sys.stdin).get('artifacts', []) if a['name'] == '$artifact_name'))")
                  
                  echo "Found $count matching artifacts"
                  echo "found=$count" >> $GITHUB_OUTPUT

            - name: 아티팩트 다운로드
              if: steps.check_artifacts.outputs.found != '0'
              uses: actions/download-artifact@v4
              with:
                  name: load-test-results-${{ github.run_number }}
                  path: results

            - name: 아티팩트 누락 경고
              if: steps.check_artifacts.outputs.found == '0'
              run: |
                  echo "::warning::부하 테스트 결과 아티팩트를 찾을 수 없습니다. 분석을 건너뜁니다."
                  mkdir -p results
                  echo '{}' > results/load_test_light_stats.csv # 더미 파일 생성으로 후속 단계 에러 방지

            - name: 성능 지표 추출 (Python)
              run: |
                  cat > analyze.py << 'EOF'
                  import csv
                  import json
                  from pathlib import Path

                  results_dir = Path("results")
                  scenarios = ["light", "medium", "heavy", "stress"]

                  summary = {"scenarios": {}}

                  for scenario in scenarios:
                      stats_file = results_dir / f"load_test_{scenario}_stats.csv"
                      if not stats_file.exists():
                          continue
                          
                      with open(stats_file, 'r') as f:
                          reader = csv.DictReader(f)
                          rows = list(reader)
                          if not rows:
                              continue
                          
                          # Aggregated row (마지막 행)
                          agg = rows[-1]
                          summary["scenarios"][scenario] = {
                              "total_requests": int(agg.get("Request Count", 0)),
                              "failures": int(agg.get("Failure Count", 0)),
                              "avg_response_time": float(agg.get("Average Response Time", 0)),
                              "p95_response_time": float(agg.get("95%", 0)),
                              "p99_response_time": float(agg.get("99%", 0)),
                              "requests_per_sec": float(agg.get("Requests/s", 0))
                          }

                  print(json.dumps(summary, indent=2))

                  with open("results/metrics.json", "w") as f:
                      json.dump(summary, f, indent=2)
                  EOF

                  python analyze.py

            - name: 성능 리포트 업로드
              uses: actions/upload-artifact@v4
              with:
                  name: performance-metrics-${{ github.run_number }}
                  path: results/metrics.json
                  retention-days: 90
