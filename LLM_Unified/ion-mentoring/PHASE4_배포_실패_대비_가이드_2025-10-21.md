# Phase 4 배포 실패 대비 가이드
**작성 일시**: 2025-10-21 오후
**목적**: 배포 중 최악의 경우에 대한 완벽한 대응 계획
**상태**: 📋 **준비 완료**

---

## 🎯 개요

배포는 계획대로 진행되지 않을 수 있습니다. 이 문서는 **배포 실패 시나리오별 대응 방법**을 제시합니다.

### 목표
```
✅ 배포 실패를 빠르게 감지
✅ 즉시 대응 (5분 이내 롤백)
✅ 사용자 영향 최소화
✅ 원인 분석 및 사후 대응
```

---

## 🚨 배포 실패 시나리오

### Scenario 1: 배포 직후 에러율 급증

**증상**:
```
[14:05] 배포 후 5분
  에러율: 0% → 5% (급증!)
  원인: 새 코드 버그 또는 API 호환성 문제
```

**즉시 조치 (1단계: 자동 감지)**:
```
✓ 모니터링 시스템이 에러율 > 1% 감지
✓ 3회 연속 감지 시 자동 롤백 트리거
✓ Slack에 자동 알림
```

**수동 대응 (2단계: 만약 자동 롤백 실패)**:
```powershell
# 즉시 실행 (< 30초)
cd d:\nas_backup\LLM_Unified\ion-mentoring\scripts

# 롤백 실행
.\rollback_phase4_canary.ps1

# 상태 확인
.\check_monitoring_status.ps1
```

**예상 복구 시간**: 2-3분

**사후 조치**:
- [ ] 에러 로그 분석 (Cloud Logging)
- [ ] 배포 전 코드 리뷰 재검토
- [ ] 새 테스트 케이스 추가
- [ ] 다음 배포 일정 연기

---

### Scenario 2: 응답 시간 급증

**증상**:
```
[14:15] 배포 후 15분
  P95 응답시간: 150ms → 800ms (급증!)
  원인: 추천 엔진 성능 문제, DB 쿼리 병목
```

**기본 원인 진단**:
```
Q1: 모든 엔드포인트가 느린가?
  A. YES → 인프라 문제 (메모리/CPU/네트워크)
  A. NO → 특정 기능 문제 (추천 엔진)

Q2: 메모리/CPU는 정상인가?
  A. YES → 응용 로직 문제
  A. NO → 자동 스케일링 또는 리소스 증설
```

**즉시 조치**:
```powershell
# 1. 현재 메트릭 확인
.\get_canary_metrics.ps1

# 2. GCP Cloud Logging에서 느린 요청 확인
gcloud logging read "resource.type=cloud_run_revision AND jsonPayload.latency_ms > 500" --limit 10

# 3. 어디가 느린지 파악
#    - API 엔드포인트별 응답 시간 확인
#    - DB 쿼리 성능 확인
#    - 외부 API 호출 시간 확인

# 3-1. 특정 기능이 문제라면
#      → rate_limit_probe.ps1으로 해당 엔드포인트 테스트
.\rate_limit_probe.ps1 -RequestsPerSide 20 -DelayMsBetweenRequests 100
```

**대응 옵션**:

| 조치 | 시간 | 위험도 | 결과 |
|------|------|--------|------|
| **Option A: 롤백** | 2분 | 낮음 | 즉시 정상화 |
| Option B: 트래픽 줄임 | 1분 | 낮음 | 부분 개선 |
| Option C: 리소스 증설 | 5분 | 중간 | 개선될 수 있음 |
| Option D: 디버그 후 핫픽스 | 30분+ | 높음 | 위험함 |

**권고**: **Option A (롤백)** 선택 권고
```powershell
.\rollback_phase4_canary.ps1
```

**예상 복구 시간**: 2-3분

**사후 조치**:
- [ ] 성능 테스트 보충 (새 기능별 최악의 경우)
- [ ] DB 쿼리 최적화
- [ ] 외부 API 타임아웃 설정 검토
- [ ] 메모리 누수 가능성 확인

---

### Scenario 3: 메모리 폭발

**증상**:
```
[14:30] 배포 후 30분
  메모리: 60% → 95% → 99% (계속 증가)
  원인: 메모리 누수, 세션 데이터 누적
```

**진단**:
```
Q1: 모든 인스턴스가 메모리 증가하나?
  A. YES → 애플리케이션 메모리 누수
  A. NO → 특정 인스턴스 문제

Q2: 메모리가 언제부터 증가했나?
  A. 배포 직후 → 새 코드 문제 거의 확실
  A. 30분 후 → 시간에 따른 누적 (세션 등)
```

**즉시 조치** (이 경우는 매우 중대한 문제):
```powershell
# 1. 긴급 롤백 (메모리 폭발은 서비스 중단 위험)
.\rollback_phase4_canary.ps1 -Force

# 2. 상태 확인
.\check_monitoring_status.ps1

# 3. 메모리 덤프 수집 (사후 분석용)
# GCP Cloud Profiler에서 메모리 프로파일 다운로드
```

**예상 복구 시간**: 2-5분

**사후 조치**:
- [ ] 메모리 프로파일 분석
- [ ] 세션 저장소 검토 (Redis 용량)
- [ ] 메모리 누수 테스트 추가
- [ ] 부하 테스트 기간 연장 (최소 24시간)

---

### Scenario 4: 데이터 손실/오염

**증상**:
```
[14:45] 배포 후 45분
  사용자 보고: "내 대화 기록이 사라졌어요"
  원인: 데이터베이스 마이그레이션 버그, 세션 삭제 로직 오류
```

**이것은 CRITICAL 상황입니다!**

**즉시 조치**:
```
1️⃣ 00:00 - 즉시 롤백
   .\rollback_phase4_canary.ps1 -Force

2️⃣ 01:00 - 데이터 복구 시작
   - 최근 백업에서 영향받은 데이터 복구
   - 트랜잭션 로그 검토

3️⃣ 02:00 - 사용자 공지
   - 데이터 손실 사건 공식 발표
   - 복구 예정 시간 안내
   - 보상 계획 수립

4️⃣ 04:00 - 완전 복구 확인
   - 데이터 무결성 검증
   - 영향받은 사용자 개별 확인
```

**예상 복구 시간**: 2-4시간 (데이터 백업 크기에 따라)

**이 경우는 절대 무시하면 안 됩니다!**

---

### Scenario 5: Canary 서비스 완전 다운

**증상**:
```
[14:35] 배포 후 35분
  상태: "Canary 서비스 응답 없음"
  원인: 서비스 충돌, 배포 스크립트 오류, GCP 문제
```

**즉시 조치**:
```powershell
# 1. 서비스 상태 확인
gcloud run services describe ion-api-canary --region us-central1

# 2. 로그 확인
gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=ion-api-canary" --limit 50

# 3. 롤백 또는 재배포
.\rollback_phase4_canary.ps1 -Force

# 4. 대체 경로 확인
# 트래픽이 legacy로 자동 리다이렉트되는가?
curl https://ion-api-64076350717.us-central1.run.app/health
```

**예상 복구 시간**: 1-2분 (자동 복구 가능)

---

## 📋 롤백 체크리스트

배포 실패 시 **이 순서대로** 롤백을 진행하세요:

### Phase 1: 즉시 (0-1분)
```
□ 롤백 결정 (자동 또는 수동)
□ 팀에 Slack 긴급 알림
□ rollback_phase4_canary.ps1 실행
```

### Phase 2: 확인 (1-2분)
```
□ 트래픽 100% legacy로 복구 확인
□ 에러율 정상화 확인 (< 0.5%)
□ 응답 시간 정상화 확인 (P95 < 200ms)
```

### Phase 3: 검증 (2-5분)
```
□ 사용자 보고 (Slack) "서비스 정상입니다"
□ Cloud Logging에서 에러 대폭 감소 확인
□ Grafana 대시보드에서 모든 지표 녹색 확인
```

### Phase 4: 기록 (5-10분)
```
□ 롤백 사건 기록 (타임스탬프, 이유, 조치)
□ 팀 회의 일정 예약 (Post-Mortem)
□ 원인 분석 시작
```

---

## 🔍 원인 분석 프로세스

배포 실패 후 해야 할 일:

### 1단계: 실시간 증거 수집 (롤백 직후)

```powershell
# Cloud Logging에서 에러 로그 추출
gcloud logging read "resource.type=cloud_run_revision AND severity=ERROR" \
  --limit 100 > error_logs_$(Get-Date -Format yyyyMMdd_HHmmss).txt

# 메트릭 스냅샷 저장
.\get_canary_metrics.ps1 > metrics_snapshot_$(Get-Date -Format yyyyMMdd_HHmmss).json

# 배포 설정 저장
gcloud run services describe ion-api-canary --region us-central1 > canary_config_$(Get-Date -Format yyyyMMdd_HHmmss).json
```

### 2단계: 코드 검토 (사건 직후)

```
1. 배포된 코드에서 문제 찾기
   - 새 기능: 추천 엔진
   - 새 기능: 멀티턴 대화
   - 새 기능: 세션 관리
   - 변경: API 엔드포인트 구조

2. 테스트 커버리지 분석
   - 해당 기능의 테스트가 있었나?
   - 테스트를 통과했는데 왜 실패했나?
   - 프로덕션 환경에서만 발생하는 문제인가?

3. 인프라 설정 검토
   - 환경 변수 설정
   - 리소스 할당
   - 네트워크 정책
```

### 3단계: Post-Mortem 회의

이 부분은 별도의 **PHASE4_배포_실패_Post-Mortem_가이드**에서 다룹니다.

---

## 🛡️ 배포 중 모니터링 핵심 메트릭

배포 중 **5분마다** 이것들을 확인하세요:

### Red Flags (즉시 조치 필요)
```
🔴 에러율 > 1.0%        → 롤백 고려
🔴 P95 > 500ms          → 롤백 고려
🔴 메모리 > 85%         → 롤백 고려
🔴 CPU > 90%            → 롤백 고려
🔴 서비스 다운          → 즉시 롤백
```

### Yellow Flags (주의 필요)
```
🟡 에러율 > 0.5%        → 원인 파악
🟡 P95 > 200ms          → 원인 파악
🟡 메모리 > 70%         → 트렌드 감시
🟡 CPU > 70%            → 트렌드 감시
```

### Green Flags (정상)
```
🟢 에러율 < 0.5%
🟢 P95 < 200ms
🟢 메모리 < 70%
🟢 CPU < 70%
🟢 사용자 피드백 긍정적
```

---

## 📊 배포 실패 결정 기준

| 상황 | 판단 | 조치 |
|------|------|------|
| 에러율 > 1% (1회) | 주의 | 모니터링 강화 |
| 에러율 > 1% (3회 연속) | 위험 | 롤백 권고 |
| 데이터 손실 | 위기 | 즉시 롤백 + 복구 |
| 메모리 폭발 | 위기 | 즉시 롤백 |
| 서비스 다운 | 위기 | 즉시 롤백 |

---

## 🚨 긴급 연락처

배포 실패 시 **즉시 연락할 사람들**:

| 역할 | 이름 | 연락 방법 | 응답 시간 |
|------|------|----------|----------|
| 배포 리더 | Sena | Slack #operations | 1분 |
| 백엔드 엔지니어 | Gitco | Slack #backend | 2분 |
| DevOps 엔지니어 | Lubit | Slack #devops | 2분 |
| 모니터링 담당 | Lemun | Slack #monitoring | 3분 |
| 매니저 | [TBD] | 전화 | 5분 |

> 참고: Gitco 수행 절차는 `docs/GITCO_ORCHESTRATION_HANDOFF.md`에서 최신 버전을 확인하세요.

**긴급 Slack 채널**: `#critical-incidents`

---

## 📝 배포 실패 기록 템플릿

배포 실패 후 다음을 기록하세요:

```markdown
# [Phase 4] 배포 실패 기록

**발생 일시**: 2025-10-22 14:XX UTC
**실패 유형**: [에러율 급증 / 응답시간 증가 / 메모리 폭발 / 데이터 손실 / 기타]
**심각도**: [Critical / High / Medium / Low]
**감지 시간**: 배포 후 X분
**롤백 시간**: XX분 XX초

## 증상
- 에러율: X% 증가
- P95 응답시간: X ms
- 메모리: X% → X%

## 원인 (사후 분석)
- [근본 원인 작성]

## 영향
- 영향받은 사용자 수: X명
- 데이터 손실: [있음/없음]
- 서비스 다운 시간: X분

## 조치
- [취한 조치 기록]

## 개선사항
- [다음번 예방 방법]
```

---

## ✅ 배포 실패 대비 체크리스트

지금 바로 확인하세요:

```
□ rollback_phase4_canary.ps1 파일 존재 및 테스트됨
□ 롤백 명령어 팀이 알고 있음
□ 백업 데이터 존재 및 접근 가능
□ GCP 권한 (롤백 권한) 확인
□ Cloud Logging 접근 권한 확인
□ 긴급 연락처 최신 상태
□ Post-Mortem 회의실 예약 가능
□ 커뮤니케이션 템플릿 준비
□ 사용자 알림 템플릿 준비
□ 팀이 이 가이드를 읽음
```

---

## 🎯 결론

배포는 예상대로 진행되지 않을 수 있습니다.

**하지만** 다음을 준비하면 대부분의 실패 상황을 **2-3분 내에 복구**할 수 있습니다:

```
1. 명확한 롤백 절차
2. 실시간 모니터링
3. 빠른 의사결정
4. 팀의 사전 준비
```

**이 가이드는 배포를 더 안전하게 만드는 도구입니다.**

---

**작성자**: Sena (세나)
**상태**: 📋 준비 완료
**마지막 검토**: 2025-10-21 오후
**배포 당일 준비**: 이 가이드를 팀과 함께 검토하세요!
