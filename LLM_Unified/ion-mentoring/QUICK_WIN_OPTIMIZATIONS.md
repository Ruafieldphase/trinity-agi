# ë¹ ë¥¸ ì„±ëŠ¥ ê°œì„  (Quick Win Optimizations)

ë°°í¬ í›„ ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ê³ íš¨ìœ¨ ìµœì í™” ëª©ë¡ (1-2ì£¼ ë‚´ êµ¬í˜„)

**ëª©í‘œ**: ì‘ë‹µ ì‹œê°„ 5-15% ë‹¨ì¶•, ìš´ì˜ ë¶€í•˜ 50% ê°ì†Œ
**ë³µì¡ë„**: LOW-MEDIUM (ê° 1-3ì¼ ì†Œìš”)
**ìœ„í—˜ë„**: LOW (ê¸°ì¡´ ê¸°ëŠ¥ ë³€ê²½ ì—†ìŒ)

---

## ğŸ¯ Quick Win ìµœì í™” ìˆœìœ„

### Priority 1: ì‘ë‹µ ìºì‹± (3ì¼, 10% ê°œì„ )

#### í˜„ì¬ ìƒíƒœ
- ë™ì¼ ì…ë ¥: ë§¤ë²ˆ ì „ì²´ ì²˜ë¦¬
- Vertex AI í˜¸ì¶œ: í•­ìƒ ìƒˆë¡œ ìˆ˜í–‰
- ë°˜ë³µ íŒ¨í„´ ì—†ìŒ

#### ê°œì„  í›„
- ë™ì¼ ì…ë ¥: ìºì‹œì—ì„œ ì¦‰ì‹œ ë°˜í™˜
- ë°˜ë³µ ìš”ì²­ ê°ì†Œ: ì˜ˆìƒ 30-50%
- ë©”ëª¨ë¦¬ ì¶”ê°€: ì•½ 50MB

#### êµ¬í˜„ ì½”ë“œ

```python
# app/cache_manager.py (ì‹ ê·œ)
import hashlib
import time
from typing import Optional, Dict, Any
from functools import wraps

class SimpleCache:
    """ì‘ë‹µ ìºì‹± ë§¤ë‹ˆì €"""

    def __init__(self, ttl: int = 1800, max_size: int = 500):
        self.cache = {}
        self.ttl = ttl
        self.max_size = max_size
        self.hits = 0
        self.misses = 0

    def _get_key(self, message: str, persona_filters: Optional[Dict] = None) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        cache_data = f"{message}:{str(persona_filters)}"
        return hashlib.md5(cache_data.encode()).hexdigest()

    def get(self, message: str, persona_filters: Optional[Dict] = None) -> Optional[Dict[str, Any]]:
        """ìºì‹œì—ì„œ ì¡°íšŒ"""
        key = self._get_key(message, persona_filters)

        if key in self.cache:
            value, timestamp = self.cache[key]
            if time.time() - timestamp < self.ttl:
                self.hits += 1
                return value
            else:
                del self.cache[key]

        self.misses += 1
        return None

    def set(self, message: str, response: Dict[str, Any], persona_filters: Optional[Dict] = None) -> None:
        """ìºì‹œì— ì €ì¥"""
        key = self._get_key(message, persona_filters)

        # ìš©ëŸ‰ ì´ˆê³¼ ì‹œ ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
        if len(self.cache) >= self.max_size:
            oldest_key = min(
                self.cache.keys(),
                key=lambda k: self.cache[k][1]
            )
            del self.cache[oldest_key]

        self.cache[key] = (response, time.time())

    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„"""
        total = self.hits + self.misses
        hit_rate = (self.hits / total * 100) if total > 0 else 0

        return {
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate": hit_rate,
            "cache_size": len(self.cache),
            "memory_mb": len(self.cache) * 2,  # ëŒ€ëµì  ì¶”ì •
        }

    def clear(self) -> None:
        """ìºì‹œ ì´ˆê¸°í™”"""
        self.cache.clear()
        self.hits = 0
        self.misses = 0

# app/main.py ìˆ˜ì •
from app.cache_manager import SimpleCache

cache_manager = SimpleCache(ttl=1800, max_size=500)

@app.post("/chat")
async def chat(request: ChatRequest) -> ChatResponse:
    """ìºì‹œë¥¼ í™œìš©í•œ ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸"""

    # Step 1: ìºì‹œ í™•ì¸
    cached_response = cache_manager.get(request.message)
    if cached_response:
        logger.info(f"Cache hit for message: {request.message[:50]}")
        return ChatResponse(**cached_response)

    # Step 2: ìºì‹œ ë¯¸ìŠ¤ - ì „ì²´ ì²˜ë¦¬
    logger.info(f"Cache miss, processing: {request.message[:50]}")

    response = await persona_pipeline.process(request.message)
    response_dict = response.dict()

    # Step 3: ìºì‹œì— ì €ì¥
    cache_manager.set(request.message, response_dict)

    return ChatResponse(**response_dict)

# ìºì‹œ í†µê³„ ì—”ë“œí¬ì¸íŠ¸ (ëª¨ë‹ˆí„°ë§ìš©)
@app.get("/metrics/cache")
async def get_cache_stats():
    """ìºì‹œ í†µê³„ ì¡°íšŒ"""
    return cache_manager.get_stats()
```

#### ë°°í¬ ì „ëµ
1. **ê°œë°œ**: ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸ (1ì¼)
2. **ìŠ¤í…Œì´ì§•**: ìŠ¤í…Œì´ì§• í™˜ê²½ ë°°í¬ (1ì¼)
3. **í”„ë¡œë•ì…˜**: Feature flagë¡œ ì ì§„ì  ë¡¤ì•„ì›ƒ
   - Day 1: 10% íŠ¸ë˜í”½
   - Day 2: 50% íŠ¸ë˜í”½
   - Day 3: 100% íŠ¸ë˜í”½

---

### Priority 2: ë¡œê¹… ìµœì í™” (ë°°ì¹˜í™”, 3ì¼, 15% ê°œì„ )

#### í˜„ì¬ ìƒíƒœ
- ëª¨ë“  ë¡œê·¸: ì¦‰ì‹œ ì „ì†¡
- GCP í˜¸ì¶œ: ìš”ì²­ë‹¹ 10+ íšŒ
- ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­: ë†’ìŒ

#### ê°œì„  í›„
- ë¡œê·¸: ë²„í¼ë§ í›„ ë°°ì¹˜ ì „ì†¡
- GCP í˜¸ì¶œ: ìš”ì²­ë‹¹ 1íšŒ (ë°°ì¹˜)
- ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­: 90% ê°ì†Œ

#### êµ¬í˜„ ì½”ë“œ

```python
# app/batch_logger.py (ì‹ ê·œ)
import queue
import threading
import time
from typing import Dict, Any, List
from datetime import datetime

class BatchedGoogleCloudLogger:
    """ë°°ì¹˜ ë¡œê¹… ë§¤ë‹ˆì €"""

    def __init__(self, batch_size: int = 50, flush_interval: int = 5):
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self.buffer = []
        self.lock = threading.Lock()

        # ë°±ê·¸ë¼ìš´ë“œ í”ŒëŸ¬ì‹œ ìŠ¤ë ˆë“œ
        self.flush_thread = threading.Thread(
            target=self._periodic_flush,
            daemon=True
        )
        self.flush_thread.start()

        self.flushed_count = 0
        self.batches_count = 0

    def add_log(self, log_entry: Dict[str, Any]) -> None:
        """ë¡œê·¸ ì¶”ê°€"""
        with self.lock:
            self.buffer.append({
                **log_entry,
                "timestamp": datetime.utcnow().isoformat(),
            })

            # ë°°ì¹˜ í¬ê¸° ë„ë‹¬ ì‹œ í”ŒëŸ¬ì‹œ
            if len(self.buffer) >= self.batch_size:
                self._flush_batch()

    def _flush_batch(self) -> None:
        """ë°°ì¹˜ í”ŒëŸ¬ì‹œ"""
        if not self.buffer:
            return

        batch = self.buffer.copy()
        self.buffer.clear()

        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì „ì†¡
        threading.Thread(
            target=self._send_batch,
            args=(batch,),
            daemon=True
        ).start()

    def _send_batch(self, batch: List[Dict[str, Any]]) -> None:
        """ë°°ì¹˜ ì „ì†¡"""
        try:
            # Google Cloud Loggingì— ë°°ì¹˜ ì „ì†¡
            from google.cloud import logging as cloud_logging

            client = cloud_logging.Client()
            logger = client.logger("ion-api")

            for entry in batch:
                logger.log_struct(entry)

            self.flushed_count += len(batch)
            self.batches_count += 1

        except Exception as e:
            print(f"Failed to send batch: {e}")

    def _periodic_flush(self) -> None:
        """ì •ê¸°ì  í”ŒëŸ¬ì‹œ"""
        while True:
            time.sleep(self.flush_interval)
            with self.lock:
                if self.buffer:
                    self._flush_batch()

    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„"""
        return {
            "total_flushed": self.flushed_count,
            "total_batches": self.batches_count,
            "current_buffer_size": len(self.buffer),
        }

# app/main.py ìˆ˜ì •
batch_logger = BatchedGoogleCloudLogger(batch_size=50, flush_interval=5)

# ê¸°ì¡´ ë¡œê¹… ëŒ€ì‹  ë°°ì¹˜ ë¡œê¹… ì‚¬ìš©
@app.middleware("http")
async def log_request(request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time

    batch_logger.add_log({
        "method": request.method,
        "path": request.url.path,
        "status_code": response.status_code,
        "process_time_ms": process_time * 1000,
    })

    response.headers["X-Process-Time"] = str(process_time)
    return response
```

#### ê¸°ëŒ€ íš¨ê³¼
- ë¡œê¹… ì˜¤ë²„í—¤ë“œ: 50% ê°ì†Œ
- GCP í˜¸ì¶œ: 90% ê°ì†Œ
- ë©”ëª¨ë¦¬: +20MB

---

### Priority 3: ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™” (2ì¼, 8% ê°œì„ )

#### í˜„ì¬ ìƒíƒœ
- ì¿¼ë¦¬: ìµœì í™” ì—†ìŒ
- N+1 ë¬¸ì œ: ê°€ëŠ¥ì„± ë†’ìŒ
- ì¸ë±ìŠ¤: ê¸°ë³¸ë§Œ ì„¤ì •

#### ê°œì„  í›„
- ì¿¼ë¦¬: ì¡°ì¸ ìµœì í™”
- ì¿¼ë¦¬ ìºì‹±: ìì£¼ ì‚¬ìš©í•˜ëŠ” ì¿¼ë¦¬
- ì¸ë±ìŠ¤: ì„±ëŠ¥ ìµœì í™”

#### êµ¬í˜„ ì½”ë“œ

```python
# í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ (í•„ìš”ì‹œ)
# ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„

# Cloud SQL - ëŠë¦° ì¿¼ë¦¬ ë¡œê·¸ í™œì„±í™”
"""
ALTER DATABASE {database_name} SET log_min_duration_statement = 1000;
-- 1ì´ˆ ì´ìƒ ê±¸ë¦¬ëŠ” ì¿¼ë¦¬ë§Œ ë¡œê¹…
"""

# ì¸ë±ìŠ¤ ì¶”ê°€
"""
CREATE INDEX idx_persona_response_time ON responses (persona_id, created_at);
CREATE INDEX idx_session_lookup ON memory_coordinates (session_id);
"""

# SQLAlchemy ì¿¼ë¦¬ ìµœì í™”
from sqlalchemy.orm import joinedload

# ë‚˜ìœ ì˜ˆ: N+1 ì¿¼ë¦¬
responses = db.query(Response).all()
for response in responses:
    print(response.persona.name)  # N+1 ì¿¼ë¦¬ ë°œìƒ

# ì¢‹ì€ ì˜ˆ: eager loading
responses = db.query(Response).options(
    joinedload(Response.persona)
).all()
```

---

## ğŸ“Š Performance Regression ê²€ì‚¬

### Week 1-2: ëª¨ë‹ˆí„°ë§

```python
# ë§¤ì¼ ì•„ì¹¨ ì„±ëŠ¥ ë¹„êµ (ìë™í™” ê°€ëŠ¥)
baseline = {
    "p95_latency": 1800,  # ms
    "error_rate": 0.01,   # 1%
    "memory_mb": 280,
}

current = {
    "p95_latency": 1820,  # ms
    "error_rate": 0.009,  # 0.9%
    "memory_mb": 290,
}

# í™•ì¸ í•­ëª©
assert current["p95_latency"] < baseline["p95_latency"] * 1.1  # 110% ì´ìƒ ì¦ê°€ ê¸ˆì§€
assert current["error_rate"] < baseline["error_rate"] * 1.5    # 150% ì´ìƒ ì¦ê°€ ê¸ˆì§€
assert current["memory_mb"] < baseline["memory_mb"] * 1.2      # 120% ì´ìƒ ì¦ê°€ ê¸ˆì§€
```

---

## ğŸ¯ ì ìš© ì¼ì •

### Week 1 (ë°°í¬ í›„ 1ì£¼ì¼)

**Day 1-3: ì‘ë‹µ ìºì‹±**
```
Day 1: ê°œë°œ ë° ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
Day 2: í†µí•© í…ŒìŠ¤íŠ¸ ë° ìŠ¤í…Œì´ì§• ë°°í¬
Day 3: í”„ë¡œë•ì…˜ ë°°í¬ (10% â†’ 50% â†’ 100%)
```

**Day 4-5: ë°°ì¹˜ ë¡œê¹…**
```
Day 4: ê°œë°œ ë° í…ŒìŠ¤íŠ¸
Day 5: ë°°í¬
```

### Week 2

**Day 1-2: ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”**
```
Day 1: ì¿¼ë¦¬ ë¶„ì„ ë° ì¸ë±ìŠ¤ ê³„íš
Day 2: ë°°í¬ ë° ê²€ì¦
```

**Day 3-5: í†µí•© í…ŒìŠ¤íŠ¸ ë° ëª¨ë‹ˆí„°ë§**
```
ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê²€ì¦
```

---

## ğŸ“ˆ ì˜ˆìƒ íš¨ê³¼

### ê°œì„  ì „í›„ ë¹„êµ

```
ë©”íŠ¸ë¦­           ê°œì„  ì „    ê°œì„  í›„    ê°œì„ ë„
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
P50 ì‘ë‹µ ì‹œê°„    0.8s      0.75s      6% â†“
P95 ì‘ë‹µ ì‹œê°„    1.8s      1.55s      14% â†“
P99 ì‘ë‹µ ì‹œê°„    4.2s      3.65s      13% â†“
ë©”ëª¨ë¦¬ ì‚¬ìš©      280MB     310MB      11% â†‘
GCP í˜¸ì¶œ        1,000/h   100/h      90% â†“
ë¡œê·¸ ì˜¤ë²„í—¤ë“œ    10ms      5ms        50% â†“

ì¢…í•© ê°œì„ : ì•½ 12% ì„±ëŠ¥ í–¥ìƒ
```

### ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥

```
ì‘ë‹µ ì‹œê°„ ê°œì„ :
  - ì‚¬ìš©ì ë§Œì¡±ë„ â†‘ 5-10%
  - í¬ê¸°ìœ¨ â†“ 2-3%
  - ì²˜ë¦¬ëŸ‰ â†‘ 10%

ë¹„ìš© ì ˆê°:
  - GCP í˜¸ì¶œ ë¹„ìš© â†“ 90%
  - ì¸ìŠ¤í„´ìŠ¤ ê°œìˆ˜ â†“ 10-20%
  - ë„¤íŠ¸ì›Œí¬ ë¹„ìš© â†“ 50%
```

---

## ğŸ›¡ï¸ ë¡¤ë°± ê³„íš

### ìºì‹± ë¡¤ë°±
```python
# Feature flagë¡œ ì¦‰ì‹œ ë¹„í™œì„±í™” ê°€ëŠ¥
ENABLE_CACHE = os.getenv("ENABLE_CACHE", "true") == "true"

if ENABLE_CACHE:
    response = cache_manager.get(message)
    if response:
        return response
```

### ë°°ì¹˜ ë¡œê¹… ë¡¤ë°±
```python
# ë™ê¸°ì‹ ë¡œê¹…ìœ¼ë¡œ ë³µêµ¬
if USE_BATCH_LOGGING:
    batch_logger.add_log(entry)
else:
    cloud_logging_client.log_struct(entry)  # ë™ê¸°ì‹
```

---

## âœ… ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ìºì‹± êµ¬í˜„ ì™„ë£Œ
- [ ] ë°°ì¹˜ ë¡œê¹… êµ¬í˜„ ì™„ë£Œ
- [ ] DB ìµœì í™” ì™„ë£Œ
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ìŠ¤í…Œì´ì§• ë°°í¬ ì„±ê³µ
- [ ] í”„ë¡œë•ì…˜ ë°°í¬ ì„±ê³µ
- [ ] ì„±ëŠ¥ ë©”íŠ¸ë¦­ í™•ì¸
- [ ] Regression ì—†ìŒ í™•ì¸
- [ ] íŒ€ êµìœ¡ ì™„ë£Œ

---

**ë¹ ë¥¸ ê°œì„ ì„ í†µí•œ í”„ë¡œë•ì…˜ ì„±ëŠ¥ ìµœì í™”** âœ…
