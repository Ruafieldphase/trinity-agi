"""
ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸

Legacy System vs Lumen Gateway ì„±ëŠ¥ ë¹„êµ
- ì‘ë‹µ ì‹œê°„ ì¸¡ì •
- Confidence ë¹„êµ
- í˜ë¥´ì†Œë‚˜ ì„ íƒ ì •í™•ë„
- í†µê³„ ë¶„ì„ ë° ì‹œê°í™”
"""

import asyncio
import json
import statistics
import time
from datetime import datetime
from typing import Any, Dict, List

import httpx


class PerformanceBenchmark:
    """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ í´ë˜ìŠ¤"""

    def __init__(self, ion_api_url: str = "http://localhost:8000", iterations: int = 100):
        self.ion_api_url = ion_api_url
        self.iterations = iterations
        self.results = {"lumen": [], "legacy": []}

    async def _call_api(
        self, query: str, user_id: str, force_legacy: bool = False
    ) -> Dict[str, Any]:
        """
        Ion API í˜¸ì¶œ (ë‹¨ì¼ ìš”ì²­)

        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
            user_id: ì‚¬ìš©ì ID
            force_legacy: Legacy ê°•ì œ ì‚¬ìš© (Feature Flag ë¬´ì‹œ)

        Returns:
            Dict: ì‘ë‹µ ë°ì´í„° + ë©”íƒ€ë°ì´í„°
        """
        async with httpx.AsyncClient(timeout=30.0) as client:
            start_time = time.time()

            payload = {
                "user_id": user_id,
                "query": query,
                "options": {"style": "concise", "force_legacy": force_legacy},  # ì¶”í›„ êµ¬í˜„ í•„ìš”
            }

            try:
                response = await client.post(
                    f"{self.ion_api_url}/api/v2/recommend/personalized",
                    json=payload,
                    headers={"Content-Type": "application/json"},
                )

                elapsed_time = (time.time() - start_time) * 1000  # ms

                if response.status_code == 200:
                    data = response.json()
                    return {
                        "success": True,
                        "response_time_ms": elapsed_time,
                        "persona": data.get("primary_persona"),
                        "confidence": data.get("confidence"),
                        "algorithm": data.get("metadata", {}).get("algorithm"),
                        "ab_group": data.get("metadata", {}).get("ab_group"),
                        "lumen_persona": data.get("metadata", {}).get("lumen_persona"),
                        "error": None,
                    }
                else:
                    return {
                        "success": False,
                        "response_time_ms": elapsed_time,
                        "error": f"HTTP {response.status_code}",
                    }

            except Exception as e:
                elapsed_time = (time.time() - start_time) * 1000
                return {"success": False, "response_time_ms": elapsed_time, "error": str(e)}

    async def run_benchmark(self):
        """ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        print(f"\n{'='*70}")
        print("ğŸ”¬ Performance Benchmark: Legacy vs Lumen Gateway")
        print(f"{'='*70}\n")
        print("ğŸ“Š ì„¤ì •:")
        print(f"  â€¢ Iterations: {self.iterations}")
        print(f"  â€¢ API Endpoint: {self.ion_api_url}")
        print("  â€¢ Test Queries: 4ê°€ì§€ í˜ë¥´ì†Œë‚˜ íƒ€ì…\n")

        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ (ê° í˜ë¥´ì†Œë‚˜ë³„)
        test_queries = [
            ("ì°½ì˜ì ì´ê³  í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•´ì¤˜", "moon", "Lua"),
            ("ì´ ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•´ì¤˜", "square", "Elro"),
            ("ì „ì²´ì ì¸ íŒ¨í„´ì„ ê´€ì°°í•˜ê³  ë©”íƒ€ ë¶„ì„í•´ì¤˜", "earth", "Riri"),
            ("ì—¬ëŸ¬ ê´€ì ì„ í†µí•©í•´ì„œ ì„¤ëª…í•´ì¤˜", "pen", "Nana"),
        ]

        # Lumen Gateway ë²¤ì¹˜ë§ˆí¬
        print("ğŸš€ Phase 1: Lumen Gateway ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘...")
        lumen_results = []

        for i in range(self.iterations):
            query, expected_persona_key, expected_persona_name = test_queries[i % len(test_queries)]
            user_id = f"benchmark_lumen_{i}"

            result = await self._call_api(query, user_id, force_legacy=False)
            result["iteration"] = i + 1
            result["query_type"] = expected_persona_key
            result["expected_persona"] = expected_persona_name
            lumen_results.append(result)

            if (i + 1) % 10 == 0:
                success_count = sum(1 for r in lumen_results if r["success"])
                print(
                    f"  Progress: {i+1}/{self.iterations} iterations "
                    f"(Success: {success_count}/{i+1})"
                )

        self.results["lumen"] = lumen_results
        print(f"âœ… Lumen Gateway ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ: {len(lumen_results)} iterations\n")

        # Legacy System ë²¤ì¹˜ë§ˆí¬
        print("ğŸ”„ Phase 2: Legacy System ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘...")
        print("âš ï¸  ì£¼ì˜: Legacy ëª¨ë“œ ê°•ì œ í™œì„±í™” í•„ìš” (LUMEN_GATE_ENABLED=false)\n")

        # í˜„ì¬ëŠ” Feature Flagë¥¼ ìˆ˜ë™ìœ¼ë¡œ ë³€ê²½í•´ì•¼ í•¨
        # ì¶”í›„ APIì—ì„œ force_legacy íŒŒë¼ë¯¸í„° ì§€ì› í•„ìš”

        print("â¸ï¸  Legacy ë²¤ì¹˜ë§ˆí¬ëŠ” ìˆ˜ë™ ì„¤ì • í›„ ì¬ì‹¤í–‰ í•„ìš”")
        print("   1. .envì—ì„œ LUMEN_GATE_ENABLED=false ì„¤ì •")
        print("   2. Ion API ì¬ì‹œì‘")
        print("   3. ì´ ìŠ¤í¬ë¦½íŠ¸ ì¬ì‹¤í–‰\n")

    def analyze_results(self):
        """ê²°ê³¼ ë¶„ì„"""
        print(f"\n{'='*70}")
        print("ğŸ“Š ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼")
        print(f"{'='*70}\n")

        # Lumen Gateway ë¶„ì„
        lumen_results = [r for r in self.results["lumen"] if r["success"]]

        if not lumen_results:
            print("âŒ Lumen Gateway ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\n")
            return

        print(f"ğŸŒŸ Lumen Gateway ë¶„ì„ ({len(lumen_results)} successful iterations):\n")

        # ì‘ë‹µ ì‹œê°„ í†µê³„
        response_times = [r["response_time_ms"] for r in lumen_results]
        print("â±ï¸  ì‘ë‹µ ì‹œê°„:")
        print(f"  â€¢ í‰ê· : {statistics.mean(response_times):.2f}ms")
        print(f"  â€¢ ì¤‘ì•™ê°’: {statistics.median(response_times):.2f}ms")
        print(f"  â€¢ ìµœì†Œ: {min(response_times):.2f}ms")
        print(f"  â€¢ ìµœëŒ€: {max(response_times):.2f}ms")
        print(f"  â€¢ í‘œì¤€í¸ì°¨: {statistics.stdev(response_times):.2f}ms\n")

        # Confidence í†µê³„
        confidences = [r["confidence"] for r in lumen_results if r.get("confidence")]
        if confidences:
            print("ğŸ¯ Confidence:")
            print(f"  â€¢ í‰ê· : {statistics.mean(confidences)*100:.2f}%")
            print(f"  â€¢ ì¤‘ì•™ê°’: {statistics.median(confidences)*100:.2f}%")
            print(f"  â€¢ ìµœì†Œ: {min(confidences)*100:.2f}%")
            print(f"  â€¢ ìµœëŒ€: {max(confidences)*100:.2f}%\n")

        # ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš© ë¶„í¬
        algorithms = {}
        for r in lumen_results:
            algo = r.get("algorithm", "unknown")
            algorithms[algo] = algorithms.get(algo, 0) + 1

        print("ğŸ”§ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš© ë¶„í¬:")
        for algo, count in algorithms.items():
            percentage = (count / len(lumen_results)) * 100
            print(f"  â€¢ {algo}: {count} ({percentage:.1f}%)")
        print()

        # í˜ë¥´ì†Œë‚˜ ì •í™•ë„
        correct_personas = sum(
            1 for r in lumen_results if r.get("persona") == r.get("expected_persona")
        )
        persona_accuracy = (correct_personas / len(lumen_results)) * 100
        print("ğŸ­ í˜ë¥´ì†Œë‚˜ ì„ íƒ ì •í™•ë„:")
        print(f"  â€¢ ì •í™•ë„: {correct_personas}/{len(lumen_results)} ({persona_accuracy:.1f}%)\n")

        # ì„±ê³µë¥ 
        total_requests = len(self.results["lumen"])
        success_rate = (len(lumen_results) / total_requests) * 100
        print("âœ… ì„±ê³µë¥ :")
        print(f"  â€¢ {len(lumen_results)}/{total_requests} ({success_rate:.1f}%)\n")

    def save_results(self, output_path: str = "outputs/benchmark_results.json"):
        """ê²°ê³¼ ì €ì¥"""
        import os

        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        summary = {
            "timestamp": datetime.now().isoformat(),
            "iterations": self.iterations,
            "api_endpoint": self.ion_api_url,
            "results": self.results,
            "summary": {
                "lumen": self._summarize_results(self.results["lumen"]),
                "legacy": self._summarize_results(self.results["legacy"]),
            },
        }

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}\n")

    def _summarize_results(self, results: List[Dict]) -> Dict:
        """ê²°ê³¼ ìš”ì•½"""
        if not results:
            return {"status": "no_data"}

        successful = [r for r in results if r["success"]]

        if not successful:
            return {"status": "all_failed"}

        response_times = [r["response_time_ms"] for r in successful]
        confidences = [r["confidence"] for r in successful if r.get("confidence")]

        return {
            "total_requests": len(results),
            "successful_requests": len(successful),
            "success_rate": len(successful) / len(results),
            "response_time": {
                "mean": statistics.mean(response_times),
                "median": statistics.median(response_times),
                "min": min(response_times),
                "max": max(response_times),
                "stdev": statistics.stdev(response_times) if len(response_times) > 1 else 0,
            },
            "confidence": {
                "mean": statistics.mean(confidences) if confidences else 0,
                "median": statistics.median(confidences) if confidences else 0,
                "min": min(confidences) if confidences else 0,
                "max": max(confidences) if confidences else 0,
            },
        }


async def main():
    """ë©”ì¸ ì‹¤í–‰"""
    import argparse

    parser = argparse.ArgumentParser(description="Performance Benchmark: Legacy vs Lumen")
    parser.add_argument(
        "--iterations", type=int, default=100, help="Number of iterations (default: 100)"
    )
    parser.add_argument(
        "--api-url",
        type=str,
        default="http://localhost:8000",
        help="Ion API URL (default: http://localhost:8000)",
    )
    parser.add_argument(
        "--output",
        type=str,
        default="outputs/benchmark_results.json",
        help="Output JSON file path (default: outputs/benchmark_results.json)",
    )

    args = parser.parse_args()

    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    benchmark = PerformanceBenchmark(ion_api_url=args.api_url, iterations=args.iterations)

    await benchmark.run_benchmark()

    # ê²°ê³¼ ë¶„ì„
    benchmark.analyze_results()

    # ê²°ê³¼ ì €ì¥
    benchmark.save_results(args.output)

    print(f"{'='*70}")
    print("âœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
    print(f"{'='*70}\n")


if __name__ == "__main__":
    asyncio.run(main())
