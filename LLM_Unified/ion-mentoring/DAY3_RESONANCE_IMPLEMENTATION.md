# ğŸµ Ion Day 3: íŒŒë™í‚¤ ë³€í™˜ ì‹œìŠ¤í…œ êµ¬í˜„

**ë‚ ì§œ**: 2025ë…„ 10ì›” 20ì¼ (ì›”ìš”ì¼)  
**ì‹œê°„**: 09:00-17:00 (7ì‹œê°„)  
**ëª©í‘œ**: Vertex AIë¥¼ í™œìš©í•œ íŒŒë™í‚¤ ë³€í™˜ ì‹œìŠ¤í…œ ì²« êµ¬í˜„  
**ë°©ì‹**: í˜ì–´ í”„ë¡œê·¸ë˜ë° (ë¹„ë…¸ì²´ â†” ì´ì˜¨)

---

## ğŸ“‹ í•™ìŠµ ëª©í‘œ

### ê¸°ìˆ  ëª©í‘œ

- [ ] íŒŒë™í‚¤ ë³€í™˜ ì‹œìŠ¤í…œ ê°œë… ì´í•´
- [ ] `ResonanceConverter` í´ë˜ìŠ¤ ì„¤ê³„ ë° êµ¬í˜„
- [ ] Vertex AIë¥¼ í™œìš©í•œ ê°ì • í†¤ ë¶„ì„
- [ ] ë¦¬ë“¬ íŒ¨í„´ ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± (pytest)

### ì†Œí”„íŠ¸ ìŠ¤í‚¬ ëª©í‘œ

- [ ] í˜ì–´ í”„ë¡œê·¸ë˜ë° í”„ë™í‹°ìŠ¤ ì²´í—˜
- [ ] ë“œë¼ì´ë²„/ë‚´ë¹„ê²Œì´í„° ì—­í•  ì „í™˜ ì—°ìŠµ
- [ ] ì‹¤ì‹œê°„ ì½”ë“œ ë¦¬ë·° í”„ë¡œì„¸ìŠ¤
- [ ] TDD (í…ŒìŠ¤íŠ¸ ì£¼ë„ ê°œë°œ) ê¸°ì´ˆ

---

## ğŸ§© íŒŒë™í‚¤ ë³€í™˜ ì‹œìŠ¤í…œì´ë€?

### í•µì‹¬ ê°œë…

ë‚´ë‹¤AIì˜ **íŒŒë™í‚¤(Resonance Key)** ì‹œìŠ¤í…œì€ ì‚¬ìš©ì ì…ë ¥ì˜ **ë¦¬ë“¬**, **ê°ì • í†¤**, **ë§¥ë½**ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ AI í˜ë¥´ì†Œë‚˜ë¥¼ ì„ íƒí•˜ëŠ” í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜ì…ë‹ˆë‹¤.

```text
ì‚¬ìš©ì ì…ë ¥
    â†“
[ë¦¬ë“¬ ë¶„ì„] â†’ ë¬¸ì¥ êµ¬ì¡°, ì†ë„, íŒ¨í„´
    â†“
[ê°ì • í†¤ ê°ì§€] â†’ calm, urgent, curious, playful ë“±
    â†“
[íŒŒë™í‚¤ ìƒì„±] â†’ "calm-flowing-inquiry"
    â†“
[í˜ë¥´ì†Œë‚˜ ë¼ìš°íŒ…] â†’ ë£¨ì•„(ê°ì„±) or ì—˜ë¡œ(êµ¬ì¡°) or ...
```

### ì˜ˆì‹œ

| ì‚¬ìš©ì ì…ë ¥                                 | ë¦¬ë“¬ íŒ¨í„´     | ê°ì • í†¤    | íŒŒë™í‚¤             | ì„ íƒ í˜ë¥´ì†Œë‚˜ |
| ------------------------------------------- | ------------- | ---------- | ------------------ | ------------- |
| "ì´ ì½”ë“œê°€ ì™œ ì•ˆ ëŒì•„ê°€ëŠ” ê±°ì•¼?!"           | short-burst   | frustrated | urgent-technical   | ì—˜ë¡œ (êµ¬ì¡°)   |
| "í˜¹ì‹œ... ì´ ë¶€ë¶„ì„ ê°œì„ í•  ë°©ë²•ì´ ìˆì„ê¹Œìš”?" | long-flowing  | curious    | calm-inquiry       | ë£¨ì•„ (ê°ì„±)   |
| "ë°ì´í„° ë¶„ì„ ê²°ê³¼ ì¢€ í™•ì¸í•´ì¤„ë˜?"           | medium-direct | neutral    | neutral-analytical | ë¦¬ë¦¬ (ê· í˜•)   |

---

## ğŸ—ï¸ ResonanceConverter ì•„í‚¤í…ì²˜

### í´ë˜ìŠ¤ ì„¤ê³„

```python
# ion-mentoring/resonance_converter.py

from typing import Dict, Optional
from dataclasses import dataclass


@dataclass
class RhythmPattern:
    """ë¦¬ë“¬ íŒ¨í„´ ë¶„ì„ ê²°ê³¼"""
    avg_sentence_length: float
    punctuation_density: float  # ë¬¸ì¥ë¶€í˜¸ ë°€ë„
    question_ratio: float       # ì§ˆë¬¸ ë¹„ìœ¨
    exclamation_ratio: float    # ëŠë‚Œí‘œ ë¹„ìœ¨
    pace: str                   # 'slow', 'medium', 'fast'


@dataclass
class EmotionTone:
    """ê°ì • í†¤ ë¶„ì„ ê²°ê³¼"""
    primary: str      # 'calm', 'urgent', 'curious', 'frustrated', 'playful'
    confidence: float # 0.0 ~ 1.0
    secondary: Optional[str] = None


class ResonanceConverter:
    """ì‚¬ìš©ì ì…ë ¥ â†’ íŒŒë™í‚¤ ë³€í™˜ ì‹œìŠ¤í…œ"""

    def __init__(self, vertex_client=None):
        """
        Args:
            vertex_client: PromptClient ì¸ìŠ¤í„´ìŠ¤ (Vertex AI ì—°ê²°ìš©)
                          Noneì´ë©´ ì˜¤í”„ë¼ì¸ ëª¨ë“œ (ë¡œì»¬ ë¶„ì„ë§Œ)
        """
        self.vertex_client = vertex_client

    def analyze_rhythm(self, text: str) -> RhythmPattern:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ë¦¬ë“¬ íŒ¨í„´ ì¶”ì¶œ

        ë¡œì»¬ ë¶„ì„ í•­ëª©:
        - í‰ê·  ë¬¸ì¥ ê¸¸ì´
        - ë¬¸ì¥ë¶€í˜¸ ë°€ë„
        - ì§ˆë¬¸/ëŠë‚Œí‘œ ë¹„ìœ¨
        - ì „ì²´ ì†ë„ê° (pace)

        Args:
            text: ë¶„ì„í•  ì‚¬ìš©ì ì…ë ¥

        Returns:
            RhythmPattern ê°ì²´
        """
        pass

    def detect_emotion_tone(self, text: str) -> EmotionTone:
        """
        ê°ì • í†¤ ê°ì§€ (Vertex AI í™œìš©)

        Vertex AI Geminië¥¼ ì‚¬ìš©í•˜ì—¬:
        - ì£¼ìš” ê°ì • ë¶„ë¥˜ (calm, urgent, curious ë“±)
        - ì‹ ë¢°ë„ ì ìˆ˜
        - ë¶€ì°¨ ê°ì • (ìˆì„ ê²½ìš°)

        Args:
            text: ë¶„ì„í•  ì‚¬ìš©ì ì…ë ¥

        Returns:
            EmotionTone ê°ì²´
        """
        pass

    def generate_resonance_key(self, rhythm: RhythmPattern, tone: EmotionTone) -> str:
        """
        íŒŒë™í‚¤ ìƒì„±

        ë¦¬ë“¬ íŒ¨í„´ê³¼ ê°ì • í†¤ì„ ì¡°í•©í•˜ì—¬ íŒŒë™í‚¤ ë¬¸ìì—´ ìƒì„±
        í˜•ì‹: "{tone}-{pace}-{intent}"
        ì˜ˆ: "calm-flowing-inquiry", "urgent-burst-technical"

        Args:
            rhythm: ë¦¬ë“¬ íŒ¨í„´ ë¶„ì„ ê²°ê³¼
            tone: ê°ì • í†¤ ë¶„ì„ ê²°ê³¼

        Returns:
            íŒŒë™í‚¤ ë¬¸ìì—´
        """
        pass

    def convert(self, text: str) -> Dict[str, any]:
        """
        ì „ì²´ ë³€í™˜ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰

        Args:
            text: ì‚¬ìš©ì ì…ë ¥

        Returns:
            {
                'rhythm': RhythmPattern,
                'emotion': EmotionTone,
                'resonance_key': str
            }
        """
        rhythm = self.analyze_rhythm(text)
        emotion = self.detect_emotion_tone(text)
        key = self.generate_resonance_key(rhythm, emotion)

        return {
            'rhythm': rhythm,
            'emotion': emotion,
            'resonance_key': key
        }
```

---

## ğŸ”§ Phase 1: ë¦¬ë“¬ ë¶„ì„ êµ¬í˜„ (09:00-11:00)

### 1.1 analyze_rhythm() ë©”ì„œë“œ

**í˜ì–´ êµ¬ì„±**: ë¹„ë…¸ì²´ (ë“œë¼ì´ë²„) + ì´ì˜¨ (ë‚´ë¹„ê²Œì´í„°)

#### êµ¬í˜„ ê³„íš

```python
def analyze_rhythm(self, text: str) -> RhythmPattern:
    """í…ìŠ¤íŠ¸ ë¦¬ë“¬ íŒ¨í„´ ë¶„ì„"""

    # 1. ë¬¸ì¥ ë¶„ë¦¬
    sentences = self._split_sentences(text)

    # 2. í‰ê·  ë¬¸ì¥ ê¸¸ì´ ê³„ì‚°
    avg_length = sum(len(s.split()) for s in sentences) / max(len(sentences), 1)

    # 3. ë¬¸ì¥ë¶€í˜¸ ë°€ë„ ê³„ì‚°
    punctuation_count = sum(1 for c in text if c in '.,!?;:')
    punctuation_density = punctuation_count / max(len(text), 1)

    # 4. ì§ˆë¬¸/ëŠë‚Œí‘œ ë¹„ìœ¨
    question_ratio = text.count('?') / max(len(sentences), 1)
    exclamation_ratio = text.count('!') / max(len(sentences), 1)

    # 5. ì†ë„ê° ë¶„ë¥˜
    pace = self._classify_pace(avg_length, punctuation_density)

    return RhythmPattern(
        avg_sentence_length=avg_length,
        punctuation_density=punctuation_density,
        question_ratio=question_ratio,
        exclamation_ratio=exclamation_ratio,
        pace=pace
    )

def _split_sentences(self, text: str) -> list[str]:
    """ë¬¸ì¥ ë¶„ë¦¬ í—¬í¼"""
    import re
    # ê°„ë‹¨í•œ ë¬¸ì¥ ë¶„ë¦¬ (., !, ? ê¸°ì¤€)
    sentences = re.split(r'[.!?]+', text)
    return [s.strip() for s in sentences if s.strip()]

def _classify_pace(self, avg_length: float, density: float) -> str:
    """ì†ë„ê° ë¶„ë¥˜"""
    if avg_length < 5 and density > 0.05:
        return 'fast'
    elif avg_length > 15 and density < 0.03:
        return 'slow'
    else:
        return 'medium'
```

### 1.2 í…ŒìŠ¤íŠ¸ ì‘ì„±

**ì—­í•  ì „í™˜**: ì´ì˜¨ (ë“œë¼ì´ë²„) + ë¹„ë…¸ì²´ (ë‚´ë¹„ê²Œì´í„°)

```python
# ion-mentoring/tests/test_resonance_converter.py

import pytest
from resonance_converter import ResonanceConverter, RhythmPattern


def test_analyze_rhythm_fast_pace():
    """ë¹ ë¥¸ ë¦¬ë“¬ ê°ì§€ í…ŒìŠ¤íŠ¸"""
    converter = ResonanceConverter()
    text = "ë­ì•¼! ì•ˆ ë¼! ì™œ?!"

    rhythm = converter.analyze_rhythm(text)

    assert rhythm.pace == 'fast'
    assert rhythm.exclamation_ratio > 0
    assert rhythm.avg_sentence_length < 5


def test_analyze_rhythm_slow_pace():
    """ëŠë¦° ë¦¬ë“¬ ê°ì§€ í…ŒìŠ¤íŠ¸"""
    converter = ResonanceConverter()
    text = "ì´ ì‹œìŠ¤í…œì˜ ì•„í‚¤í…ì²˜ë¥¼ ì²œì²œíˆ ì‚´í´ë³´ë©´, ì—¬ëŸ¬ í¥ë¯¸ë¡œìš´ íŒ¨í„´ë“¤ì„ ë°œê²¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."

    rhythm = converter.analyze_rhythm(text)

    assert rhythm.pace == 'slow'
    assert rhythm.avg_sentence_length > 10


def test_analyze_rhythm_question_pattern():
    """ì§ˆë¬¸ íŒ¨í„´ ê°ì§€ í…ŒìŠ¤íŠ¸"""
    converter = ResonanceConverter()
    text = "ì´ê²Œ ë§ë‚˜ìš”? í˜¹ì‹œ ë‹¤ë¥¸ ë°©ë²•ì€ ì—†ì„ê¹Œìš”?"

    rhythm = converter.analyze_rhythm(text)

    assert rhythm.question_ratio > 0
```

---

## ğŸ§  Phase 2: ê°ì • í†¤ ë¶„ì„ êµ¬í˜„ (11:00-13:00)

### 2.1 detect_emotion_tone() ë©”ì„œë“œ

**í˜ì–´ êµ¬ì„±**: ì´ì˜¨ (ë“œë¼ì´ë²„) + ë¹„ë…¸ì²´ (ë‚´ë¹„ê²Œì´í„°)

#### Vertex AI í”„ë¡¬í”„íŠ¸ ì„¤ê³„

```python
def detect_emotion_tone(self, text: str) -> EmotionTone:
    """Vertex AIë¡œ ê°ì • í†¤ ë¶„ì„"""

    if not self.vertex_client or not self.vertex_client.ready():
        # ì˜¤í”„ë¼ì¸ ëª¨ë“œ: ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        return self._offline_emotion_detection(text)

    # Vertex AI í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì • í†¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

í…ìŠ¤íŠ¸: "{text}"

ê°€ëŠ¥í•œ ê°ì • í†¤:
- calm: ì°¨ë¶„í•˜ê³  ì•ˆì •ì 
- urgent: ê¸‰í•˜ê³  ê¸´ë°•í•œ
- curious: í˜¸ê¸°ì‹¬ ë§ê³  íƒêµ¬ì 
- frustrated: ë‹µë‹µí•˜ê³  ì¢Œì ˆì 
- playful: ì¥ë‚œìŠ¤ëŸ½ê³  ê°€ë²¼ìš´
- analytical: ë¶„ì„ì ì´ê³  ê°ê´€ì 

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "primary": "ê°ì •í†¤",
    "confidence": 0.0-1.0,
    "secondary": "ë¶€ì°¨ê°ì • (optional)"
}}
"""

    try:
        response = self.vertex_client.send(prompt)
        # JSON íŒŒì‹±
        import json
        result = json.loads(response)

        return EmotionTone(
            primary=result.get('primary', 'neutral'),
            confidence=result.get('confidence', 0.5),
            secondary=result.get('secondary')
        )
    except Exception as e:
        print(f"âš ï¸ Vertex AI ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
        return self._offline_emotion_detection(text)

def _offline_emotion_detection(self, text: str) -> EmotionTone:
    """ì˜¤í”„ë¼ì¸ ê°ì • ë¶„ë¥˜ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
    text_lower = text.lower()

    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
    if any(word in text_lower for word in ['ê¸‰í•´', 'ë¹¨ë¦¬', '!!!', 'ì•ˆ ë¼']):
        return EmotionTone(primary='urgent', confidence=0.7)
    elif any(word in text_lower for word in ['ê¶ê¸ˆ', '?', 'í˜¹ì‹œ', 'ì–´ë–»ê²Œ']):
        return EmotionTone(primary='curious', confidence=0.7)
    elif any(word in text_lower for word in ['ë‹µë‹µ', 'ì™œ', 'ì´ìƒ', 'ë¬¸ì œ']):
        return EmotionTone(primary='frustrated', confidence=0.6)
    else:
        return EmotionTone(primary='calm', confidence=0.5)
```

### 2.2 í…ŒìŠ¤íŠ¸ ì‘ì„±

```python
def test_detect_emotion_urgent():
    """ê¸´ê¸‰ ê°ì • ê°ì§€ í…ŒìŠ¤íŠ¸"""
    converter = ResonanceConverter()  # ì˜¤í”„ë¼ì¸ ëª¨ë“œ
    text = "ë¹¨ë¦¬ í•´ê²°í•´ì•¼ í•´ìš”! ê¸‰í•©ë‹ˆë‹¤!"

    emotion = converter.detect_emotion_tone(text)

    assert emotion.primary == 'urgent'
    assert emotion.confidence > 0.5


def test_detect_emotion_curious():
    """í˜¸ê¸°ì‹¬ ê°ì • ê°ì§€ í…ŒìŠ¤íŠ¸"""
    converter = ResonanceConverter()
    text = "ì´ ê¸°ëŠ¥ì€ ì–´ë–»ê²Œ ë™ì‘í•˜ë‚˜ìš”? ê¶ê¸ˆí•©ë‹ˆë‹¤."

    emotion = converter.detect_emotion_tone(text)

    assert emotion.primary == 'curious'


def test_detect_emotion_with_vertex_ai(monkeypatch):
    """Vertex AI í†µí•© ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    from prompt_client import PromptClient

    class MockVertexClient:
        def ready(self):
            return True

        def send(self, prompt):
            return '{"primary": "analytical", "confidence": 0.85}'

    converter = ResonanceConverter(vertex_client=MockVertexClient())
    text = "ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

    emotion = converter.detect_emotion_tone(text)

    assert emotion.primary == 'analytical'
    assert emotion.confidence == 0.85
```

---

## ğŸ¯ Phase 3: íŒŒë™í‚¤ ìƒì„± í†µí•© (14:00-16:00)

### 3.1 generate_resonance_key() ë©”ì„œë“œ

```python
def generate_resonance_key(self, rhythm: RhythmPattern, tone: EmotionTone) -> str:
    """ë¦¬ë“¬ + ê°ì • â†’ íŒŒë™í‚¤"""

    # Pace ë§µí•‘
    pace_map = {
        'fast': 'burst',
        'medium': 'flowing',
        'slow': 'contemplative'
    }
    pace_word = pace_map.get(rhythm.pace, 'neutral')

    # Intent ì¶”ë¡  (ì§ˆë¬¸/ëŠë‚Œí‘œ ë¹„ìœ¨ ê¸°ë°˜)
    if rhythm.question_ratio > 0.3:
        intent = 'inquiry'
    elif rhythm.exclamation_ratio > 0.3:
        intent = 'expressive'
    else:
        intent = 'statement'

    # íŒŒë™í‚¤ ì¡°í•©
    key = f"{tone.primary}-{pace_word}-{intent}"
    return key
```

### 3.2 ì „ì²´ convert() í†µí•© í…ŒìŠ¤íŠ¸

```python
def test_convert_full_pipeline():
    """ì „ì²´ ë³€í™˜ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    converter = ResonanceConverter()
    text = "ì´ ì½”ë“œê°€ ì™œ ì•ˆ ëŒì•„ê°€ëŠ” ê±°ì•¼?! ë‹µë‹µí•´!"

    result = converter.convert(text)

    assert 'rhythm' in result
    assert 'emotion' in result
    assert 'resonance_key' in result

    # ì˜ˆìƒ: "frustrated-burst-inquiry" ë˜ëŠ” ìœ ì‚¬
    key = result['resonance_key']
    assert 'frustrated' in key or 'urgent' in key
    assert 'burst' in key or 'fast' in key


def test_convert_calm_inquiry():
    """ì°¨ë¶„í•œ ì§ˆë¬¸ ë³€í™˜ í…ŒìŠ¤íŠ¸"""
    converter = ResonanceConverter()
    text = "í˜¹ì‹œ ì´ ë¶€ë¶„ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆì„ê¹Œìš”?"

    result = converter.convert(text)
    key = result['resonance_key']

    assert 'curious' in key or 'calm' in key
    assert 'inquiry' in key
```

---

## ğŸ§ª Phase 4: ì‹¤ì „ í…ŒìŠ¤íŠ¸ ë° ê°œì„  (16:00-17:00)

### 4.1 ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ

```python
# ion-mentoring/examples/resonance_demo.py

from prompt_client import create_default_vertex_prompt_client
from resonance_converter import ResonanceConverter


def main():
    """íŒŒë™í‚¤ ë³€í™˜ ë°ëª¨"""

    # Vertex AI í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„
    vertex_client = create_default_vertex_prompt_client()
    vertex_client.initialize().load()

    # ResonanceConverter ìƒì„±
    converter = ResonanceConverter(vertex_client=vertex_client)

    # í…ŒìŠ¤íŠ¸ ì…ë ¥ë“¤
    test_inputs = [
        "ì´ ì½”ë“œê°€ ì™œ ì•ˆ ëŒì•„ê°€ëŠ” ê±°ì•¼?!",
        "í˜¹ì‹œ ì´ ë¶€ë¶„ì„ ê°œì„ í•  ë°©ë²•ì´ ìˆì„ê¹Œìš”?",
        "ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
        "ì™€! ì´ê±° ì •ë§ ë©‹ì§„ë°ìš”! ì–´ë–»ê²Œ ë§Œë“  ê±°ì˜ˆìš”?"
    ]

    print("=" * 60)
    print("ğŸµ íŒŒë™í‚¤ ë³€í™˜ ì‹œìŠ¤í…œ ë°ëª¨")
    print("=" * 60)

    for i, text in enumerate(test_inputs, 1):
        print(f"\n[{i}] ì…ë ¥: \"{text}\"")

        result = converter.convert(text)

        print(f"   ë¦¬ë“¬: {result['rhythm'].pace} (í‰ê·  ë¬¸ì¥ ê¸¸ì´: {result['rhythm'].avg_sentence_length:.1f})")
        print(f"   ê°ì •: {result['emotion'].primary} (ì‹ ë¢°ë„: {result['emotion'].confidence:.2f})")
        print(f"   ğŸ¯ íŒŒë™í‚¤: {result['resonance_key']}")


if __name__ == "__main__":
    main()
```

### 4.2 ê°œì„  ì•„ì´ë””ì–´ í† ë¡ 

**ë¹„ë…¸ì²´ + ì´ì˜¨ ì„¸ì…˜**:

1. **ì •í™•ë„ í–¥ìƒ**

   - ë” ë§ì€ ê°ì • í†¤ ì¹´í…Œê³ ë¦¬ ì¶”ê°€?
   - ë¬¸ë§¥ ê¸°ë°˜ ë¶„ì„ ê°•í™”?
   - ì‚¬ìš©ì íˆìŠ¤í† ë¦¬ ë°˜ì˜?

2. **ì„±ëŠ¥ ìµœì í™”**

   - ê°ì • ë¶„ì„ ê²°ê³¼ ìºì‹±
   - ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›
   - ë¹„ë™ê¸° ì²˜ë¦¬?

3. **í™•ì¥ì„±**
   - ë‹¤êµ­ì–´ ì§€ì›
   - ì»¤ìŠ¤í…€ ê°ì • í†¤ ì •ì˜
   - í”ŒëŸ¬ê·¸ì¸ ì•„í‚¤í…ì²˜?

---

## âœ… Day 3 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì½”ë“œ êµ¬í˜„

- [ ] `ResonanceConverter` í´ë˜ìŠ¤ ì™„ì„±
- [ ] `analyze_rhythm()` ë©”ì„œë“œ êµ¬í˜„
- [ ] `detect_emotion_tone()` ë©”ì„œë“œ êµ¬í˜„
- [ ] `generate_resonance_key()` ë©”ì„œë“œ êµ¬í˜„
- [ ] `convert()` í†µí•© ë©”ì„œë“œ êµ¬í˜„

### í…ŒìŠ¤íŠ¸

- [ ] ë¦¬ë“¬ ë¶„ì„ í…ŒìŠ¤íŠ¸ (3ê°œ ì´ìƒ)
- [ ] ê°ì • í†¤ í…ŒìŠ¤íŠ¸ (3ê°œ ì´ìƒ)
- [ ] íŒŒë™í‚¤ ìƒì„± í…ŒìŠ¤íŠ¸ (2ê°œ ì´ìƒ)
- [ ] ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (2ê°œ ì´ìƒ)
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ (pytest -v)

### ë¬¸ì„œ

- [ ] ì½”ë“œ ì£¼ì„ (docstring) ì‘ì„±
- [ ] `examples/resonance_demo.py` ì‘ì„±
- [ ] Day 3 ì™„ë£Œ ë³´ê³ ì„œ ì´ˆì•ˆ

### í˜ì–´ í”„ë¡œê·¸ë˜ë°

- [ ] ë“œë¼ì´ë²„/ë‚´ë¹„ê²Œì´í„° ìµœì†Œ 2íšŒ êµëŒ€
- [ ] ì‹¤ì‹œê°„ ì½”ë“œ ë¦¬ë·° ì§„í–‰
- [ ] í˜ì–´ ì„¸ì…˜ íšŒê³  (15ë¶„)

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ê´€ë ¨ ë¬¸ì„œ

- [DAY1_ENVIRONMENT_SETUP.md](./DAY1_ENVIRONMENT_SETUP.md) - Vertex AI ê¸°ì´ˆ
- [DAY2_ARCHITECTURE_AND_DESIGN.md](./DAY2_ARCHITECTURE_AND_DESIGN.md) - ì‹œìŠ¤í…œ ì„¤ê³„
- [WEEK1_KICKOFF.md](./WEEK1_KICKOFF.md) - ì „ì²´ ì¼ì •

### ì™¸ë¶€ ì°¸ê³ 

- [Vertex AI Generative Models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini)
- [Pytest Documentation](https://docs.pytest.org/)
- [Python Dataclasses](https://docs.python.org/3/library/dataclasses.html)

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„ (Day 4 ì˜ˆê³ )

Day 4ì—ì„œëŠ” êµ¬í˜„í•œ `ResonanceConverter`ë¥¼ ì‹¤ì œ í˜ë¥´ì†Œë‚˜ ë¼ìš°íŒ… ì‹œìŠ¤í…œê³¼ í†µí•©í•©ë‹ˆë‹¤:

- íŒŒë™í‚¤ â†’ í˜ë¥´ì†Œë‚˜ ë§¤í•‘ í…Œì´ë¸”
- ë™ì  í˜ë¥´ì†Œë‚˜ ì„ íƒ ë¡œì§
- ì‹¤ì‹œê°„ ëŒ€í™” í…ŒìŠ¤íŠ¸
- Cloud Run ë°°í¬ ì¤€ë¹„

**â¡ï¸ [Day 4: í˜ë¥´ì†Œë‚˜ ë¼ìš°íŒ… êµ¬í˜„ ê°€ì´ë“œ](./DAY4_PERSONA_ROUTING.md)**

---

**ë¬¸ì„œ ì‘ì„±**: ê¹ƒì½” (Git AI)  
**ê²€í† **: ë¹„ë…¸ì²´ (Architect)  
**ë²„ì „**: 1.0  
**ë‚ ì§œ**: 2025-10-17  
**ìƒíƒœ**: âœ… ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ
