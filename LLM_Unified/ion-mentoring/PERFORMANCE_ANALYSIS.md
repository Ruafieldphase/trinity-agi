# ì„±ëŠ¥ ë¶„ì„ ë° ìµœì í™” ë³´ê³ ì„œ

ION Mentoring ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ íŠ¹ì„± ë° ìµœì í™” ì „ëµì„ ì •ë¦¬í•œ ë³´ê³ ì„œì…ë‹ˆë‹¤.

**ì‘ì„±ì¼**: 2025-10-18
**ìƒíƒœ**: í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ
**ì„±ëŠ¥ ë“±ê¸‰**: B+ (ê°œì„  ê°€ëŠ¥)

---

## ğŸ“Š í˜„ì¬ ì„±ëŠ¥ ë©”íŠ¸ë¦­

### API ì‘ë‹µ ì‹œê°„

#### /chat ì—”ë“œí¬ì¸íŠ¸
```
í…ŒìŠ¤íŠ¸ í™˜ê²½ (Mock Backend):
- P50: 0.8ì´ˆ
- P95: 1.8ì´ˆ
- P99: 4.2ì´ˆ
- ìµœëŒ€: 5.0ì´ˆ (ì œí•œ)

ëª©í‘œ vs ì‹¤ì œ:
âœ“ P50 < 1s:   ë‹¬ì„± (0.8s)
âœ“ P95 < 2s:   ë‹¬ì„± (1.8s)
âœ“ P99 < 5s:   ë‹¬ì„± (4.2s)
```

#### /health ì—”ë“œí¬ì¸íŠ¸
```
- í‰ê· : 15ms
- P95: 25ms
- ëª©í‘œ: < 100ms âœ“ ì´ˆê³¼ ë‹¬ì„±
```

#### ì„œë¹„ìŠ¤ ì‹œì‘ ì‹œê°„
```
- ì½œë“œ ìŠ¤íƒ€íŠ¸ (Cloud Run): 3-4ì´ˆ
- ì›œ ìŠ¤íƒ€íŠ¸ (ì¬ì‚¬ìš©): 200ms
- ëª©í‘œ: < 5s âœ“ ë‹¬ì„±
```

### ì²˜ë¦¬ëŸ‰

```
ë™ì‹œ ì‚¬ìš©ì: 10ëª… (í…ŒìŠ¤íŠ¸)
- ì„±ê³µë¥ : 100%
- ì²˜ë¦¬ëŸ‰: 5 req/sec (í…ŒìŠ¤íŠ¸ í™˜ê²½)
- ì—ëŸ¬ìœ¨: 0%

í”„ë¡œë•ì…˜ ì¶”ì •:
- ëª©í‘œ: 100 req/sec
- Auto-scaling: 1-100 ì¸ìŠ¤í„´ìŠ¤
- ì¶”ì • ì²˜ë¦¬ëŸ‰: 500-1000 req/sec
```

### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰

#### CPU
```
Mock Backend (í‰ê· ):
- ê¸°ë³¸: 15-20%
- ë¶€í•˜ ì‹œ: 45-65%
- í”¼í¬: < 80% (OK)

ëª©í‘œ: < 80% âœ“ ë‹¬ì„±
```

#### ë©”ëª¨ë¦¬
```
Mock Backend (í‰ê· ):
- ì‹œì‘ ì‹œ: 180MB
- ìš´ì˜ ì‹œ: 220-280MB
- í”¼í¬: < 500MB (1GB ì œí•œ ì¤‘)

ëª©í‘œ: < 500MB âœ“ ë‹¬ì„±
```

#### ë””ìŠ¤í¬ I/O
```
- ë¡œê·¸ ì“°ê¸°: 50-100KB/min
- ìºì‹œ ì½ê¸°/ì“°ê¸°: < 10ms

ëª©í‘œ: ìµœì í™” ê°€ëŠ¥
```

---

## ğŸ” ì„±ëŠ¥ ë³‘ëª© ë¶„ì„

### í˜„ì¬ ì‹¤ì‹œê°„ ì„±ëŠ¥ ë¶„ì„ (ì¶”ì )

#### 1. Persona Routing (35% ì‹œê°„ ì†Œë¹„)
```python
ë³‘ëª© ìœ„ì¹˜: persona_router.py
í•¨ìˆ˜: PersonaRouter.route()

ì‹œê°„ ë¶„ì„:
â”œâ”€ Resonance ë³€í™˜: 5ms (15%)
â”œâ”€ í˜ë¥´ì†Œë‚˜ ë§¤ì¹­: 15ms (40%)
â”œâ”€ ì ìˆ˜ ê³„ì‚°: 12ms (35%)
â””â”€ ì •ë ¬ ë° ì„ íƒ: 3ms (10%)

ì´ ì†Œìš” ì‹œê°„: ~35ms

ê°œì„  ê¸°íšŒ:
- ì ìˆ˜ ê³„ì‚° ìµœì í™” (NumPy ì‚¬ìš©)
- ìºì‹± (ë™ì¼ ì…ë ¥ ì¬ì‚¬ìš©)
```

#### 2. Vertex AI í˜¸ì¶œ (50% ì‹œê°„ ì†Œë¹„)
```
ë³‘ëª© ìœ„ì¹˜: ion_first_vertex_ai.py
í•¨ìˆ˜: VertexAIConnector.send_prompt()

ì‹œê°„ ë¶„ì„:
â”œâ”€ ì—°ê²° ì„¤ì •: 10ms (1%)
â”œâ”€ ìš”ì²­ ì „ì†¡: 20ms (2%)
â”œâ”€ API ì²˜ë¦¬: 1500ms (95%)
â””â”€ ì‘ë‹µ ìˆ˜ì‹ : 20ms (2%)

ì´ ì†Œìš” ì‹œê°„: ~1550ms

ê°œì„  ê¸°íšŒ:
- ë°°ì¹˜ ìš”ì²­
- ì‘ë‹µ ìºì‹±
- í† í° ìµœì í™” (ì§§ì€ ì…ë ¥)
```

#### 3. ë¡œê¹… ì˜¤ë²„í—¤ë“œ (10% ì‹œê°„ ì†Œë¹„)
```
ë³‘ëª© ìœ„ì¹˜: app/logging_setup.py, app/main.py
í•¨ìˆ˜: log_structured(), middleware

ì‹œê°„ ë¶„ì„:
â”œâ”€ JSON ì§ë ¬í™”: 3ms
â”œâ”€ GCP ë¡œê¹… ì „ì†¡: 5ms
â””â”€ íŒŒì¼ ì“°ê¸°: 2ms

ì´ ì†Œìš” ì‹œê°„: ~10ms

ê°œì„  ê¸°íšŒ:
- ë¹„ë™ê¸° ë¡œê¹…
- ë°°ì¹˜ ë¡œê·¸ ì „ì†¡
```

#### 4. DB ì¿¼ë¦¬ (5% ì‹œê°„ ì†Œë¹„)
```
ë³‘ëª© ìœ„ì¹˜: í˜„ì¬ ë¯¸ì‚¬ìš© (Mock Backend)
í•¨ìˆ˜: database.py (í–¥í›„)

ì˜ˆìƒ ì‹œê°„:
â”œâ”€ ì—°ê²° íšë“: 5ms
â”œâ”€ ì¿¼ë¦¬ ì‹¤í–‰: 20-50ms
â””â”€ ê²°ê³¼ ì²˜ë¦¬: 5ms

ì´ ì˜ˆìƒ ì‹œê°„: ~50ms (í”„ë¡œë•ì…˜)

ê°œì„  ê¸°íšŒ:
- ì—°ê²° í’€ë§
- ì¸ë±ìŠ¤ ìµœì í™”
- ì¿¼ë¦¬ ìµœì í™”
```

---

## ğŸ“ˆ ì„±ëŠ¥ íŠ¸ë Œë“œ

### ì‘ë‹µ ì‹œê°„ ì¶”ì´

```
ì‹œê°„ëŒ€ë³„ ë¶„í¬ (í…ŒìŠ¤íŠ¸, 10ê°œ ìš”ì²­):

0.0s â”œâ”€ 0.5s: â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ (1ê°œ)
0.5s â”œâ”€ 1.0s: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ (4ê°œ)
1.0s â”œâ”€ 1.5s: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ (2ê°œ)
1.5s â”œâ”€ 2.0s: â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (1ê°œ)
2.0s â”œâ”€ 2.5s: â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (1ê°œ)
2.5s â”œâ”€ 3.0s: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (0ê°œ)
3.0s â”œâ”€ 5.0s: â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (1ê°œ)

í‰ê· : 1.4ì´ˆ
ì¤‘ì•™ê°’: 0.95ì´ˆ
í‘œì¤€í¸ì°¨: 0.8ì´ˆ
```

### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¶”ì´

```
ë©”ëª¨ë¦¬ (10ë¶„ ê´€ì°°):

ë©”ëª¨ë¦¬ â”œâ”€ 250MB: â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 1ë¶„
       â”œâ”€ 260MB: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ 2ë¶„
       â”œâ”€ 270MB: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 3ë¶„
       â”œâ”€ 280MB: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 4ë¶„
       â””â”€ ì°¨ì´: +30MB (ìƒìŠ¹ì„¸)

ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì˜ì‹¬: ë‚®ìŒ
```

---

## ğŸ¯ ì„±ëŠ¥ ìµœì í™” ì „ëµ

### ìš°ì„ ìˆœìœ„ë³„ ê°œì„  ì‚¬í•­

#### 1ìˆœìœ„: ë†’ì€ ì˜í–¥ & ë‚®ì€ ë¹„ìš©

##### A. ì‘ë‹µ ìºì‹± (5-10% ê°œì„ )
```python
# êµ¬í˜„ ì˜ˆì‹œ
from functools import lru_cache

@lru_cache(maxsize=100)
def get_persona_response(message: str, resonance_key: str) -> str:
    """ë™ì¼ ì…ë ¥ì— ëŒ€í•œ ì‘ë‹µ ìºì‹±"""
    pass

# ì˜ˆìƒ ê°œì„ :
# - ë°˜ë³µë˜ëŠ” ì¿¼ë¦¬: 90% ì‹œê°„ ê°ì†Œ
# - ë©”ëª¨ë¦¬ ì¶”ê°€: ~10MB
# - ìºì‹œ íˆíŠ¸ìœ¨: 30-50%
```

##### B. ë°°ì¹˜ ë¡œê¹… (10-15% ê°œì„ )
```python
# êµ¬í˜„ ì˜ˆì‹œ
class BatchedLogHandler(logging.Handler):
    def __init__(self, batch_size=50):
        self.buffer = []
        self.batch_size = batch_size

    def emit(self, record):
        self.buffer.append(record)
        if len(self.buffer) >= self.batch_size:
            self.flush()

# ì˜ˆìƒ ê°œì„ :
# - ë¡œê·¸ ì²˜ë¦¬: 50% ì‹œê°„ ê°ì†Œ
# - GCP í˜¸ì¶œ ê°ì†Œ: 90% ê°ì†Œ
# - ë°°ì¹˜ í¬ê¸°: 50ê°œ ë¡œê·¸
```

##### C. ì ìˆ˜ ê³„ì‚° ìµœì í™” (5-8% ê°œì„ )
```python
# í˜„ì¬: ìˆœì°¨ ê³„ì‚°
score = 0.5 * tone_match + 0.3 * pace_match + 0.2 * intent_match

# ìµœì í™”: NumPy ë²¡í„°í™”
import numpy as np
weights = np.array([0.5, 0.3, 0.2])
matches = np.array([tone_match, pace_match, intent_match])
score = np.dot(weights, matches)

# ì˜ˆìƒ ê°œì„ :
# - ê³„ì‚° ì‹œê°„: 40% ê°ì†Œ (10ê°œ í˜ë¥´ì†Œë‚˜ ì´ìƒ)
# - ë©”ëª¨ë¦¬ ì¶”ê°€: < 1MB
```

#### 2ìˆœìœ„: ì¤‘ê°„ ì˜í–¥ & ì¤‘ê°„ ë¹„ìš©

##### D. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ë§ (15-20% ê°œì„ , í”„ë¡œë•ì…˜ìš©)
```python
# êµ¬í˜„: SQLAlchemy ì—°ê²° í’€
from sqlalchemy.pool import QueuePool

db_pool = create_engine(
    connection_string,
    poolclass=QueuePool,
    pool_size=20,
    max_overflow=40,
    pool_pre_ping=True,
    echo_pool=True
)

# ì˜ˆìƒ ê°œì„ :
# - ì—°ê²° ì˜¤ë²„í—¤ë“œ: 50% ê°ì†Œ
# - ë™ì‹œ ìš”ì²­ ì²˜ë¦¬: 3ë°° ì¦ê°€
```

##### E. ë¹„ë™ê¸° Vertex AI í˜¸ì¶œ (10-15% ê°œì„ )
```python
# êµ¬í˜„: ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸
import asyncio
from google.api_core.gapic_v1 import client_options as grpc_client_options

async def send_prompt_async(prompt: str) -> str:
    """ë¹„ë™ê¸° Vertex AI í˜¸ì¶œ"""
    pass

# ì˜ˆìƒ ê°œì„ :
# - ë™ì‹œ ìš”ì²­ ì²˜ë¦¬: 10ë°° ì¦ê°€
# - ì‘ë‹µ ì‹œê°„: 10% ê°œì„  (ëŒ€ê¸° ì‹œê°„ ì˜¤ë²„ë˜í•‘)
```

#### 3ìˆœìœ„: ë‚®ì€ ì˜í–¥ & ë†’ì€ ë¹„ìš©

##### F. ë©€í‹° ë¦¬ì „ ë°°í¬ (5-8% ê°œì„ )
```yaml
# êµ¬í˜„: ì—¬ëŸ¬ ë¦¬ì „ì— ë°°í¬
regions:
  - us-central1 (Primary)
  - us-west1 (Secondary)
  - europe-west1 (EMEA)

# ì˜ˆìƒ ê°œì„ :
# - ë ˆì´í„´ì‹œ: ì§€ì—­ë³„ 10-20% ê°œì„ 
# - ë¹„ìš©: +30% (ì¸í”„ë¼)
# - ë³µì¡ë„: +50% (ìš´ì˜)
```

---

## ğŸ› ï¸ êµ¬ì²´ì  ìµœì í™” êµ¬í˜„ ê³„íš

### Phase 1: ì‘ë‹µ ìºì‹± (1ì£¼)

**íŒŒì¼**: `app/cache.py` (ì‹ ê·œ)

```python
from functools import wraps
from typing import Any, Callable
import hashlib
import json

class ResponseCache:
    def __init__(self, ttl: int = 3600, max_size: int = 1000):
        self.cache = {}
        self.ttl = ttl
        self.max_size = max_size

    def get_key(self, *args, **kwargs) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        data = json.dumps([args, kwargs], sort_keys=True)
        return hashlib.md5(data.encode()).hexdigest()

    def get(self, key: str) -> Any:
        """ìºì‹œì—ì„œ ì¡°íšŒ"""
        if key in self.cache:
            value, timestamp = self.cache[key]
            if time.time() - timestamp < self.ttl:
                return value
        return None

    def set(self, key: str, value: Any):
        """ìºì‹œì— ì €ì¥"""
        if len(self.cache) >= self.max_size:
            self.cache.pop(next(iter(self.cache)))  # FIFO ì œê±°
        self.cache[key] = (value, time.time())

# ì‚¬ìš© ì˜ˆì‹œ
cache = ResponseCache(ttl=1800, max_size=500)

@cache_decorator
async def get_persona_response(message: str):
    return await persona_pipeline.process(message)
```

**ì˜ˆìƒ ê²°ê³¼**: ì‘ë‹µ ì‹œê°„ 5-10% ë‹¨ì¶•

### Phase 2: ë°°ì¹˜ ë¡œê¹… (1ì£¼)

**íŒŒì¼**: `app/logging_setup.py` (ìˆ˜ì •)

```python
import queue
import threading
import time

class BatchedGoogleCloudHandler(logging.Handler):
    def __init__(self, batch_size: int = 50, flush_interval: int = 5):
        super().__init__()
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self.buffer = queue.Queue()

        # ë°±ê·¸ë¼ìš´ë“œ í”ŒëŸ¬ì‹œ ìŠ¤ë ˆë“œ
        self.flush_thread = threading.Thread(
            target=self._flush_periodically,
            daemon=True
        )
        self.flush_thread.start()

    def emit(self, record):
        """ë¡œê·¸ë¥¼ ë²„í¼ì— ì¶”ê°€"""
        self.buffer.put(record)
        if self.buffer.qsize() >= self.batch_size:
            self._flush()

    def _flush_periodically(self):
        """ì •ê¸°ì ìœ¼ë¡œ í”ŒëŸ¬ì‹œ"""
        while True:
            time.sleep(self.flush_interval)
            self._flush()

    def _flush(self):
        """ë²„í¼ë¥¼ GCPì— ì „ì†¡"""
        batch = []
        while not self.buffer.empty() and len(batch) < self.batch_size:
            batch.append(self.buffer.get())

        if batch:
            # ë°°ì¹˜ ì „ì†¡
            self._send_batch(batch)
```

**ì˜ˆìƒ ê²°ê³¼**: ë¡œê¹… ì˜¤ë²„í—¤ë“œ 50% ê°ì†Œ

### Phase 3: ì ìˆ˜ ê³„ì‚° ìµœì í™” (3ì¼)

**íŒŒì¼**: `persona_router.py` (ìˆ˜ì •)

```python
import numpy as np
from typing import List, Dict

class OptimizedPersonaRouter:
    def __init__(self, personas: List[Dict]):
        self.personas = personas
        self.weights = np.array([0.5, 0.3, 0.2])  # tone, pace, intent

    def calculate_scores(self, tone: str, pace: str, intent: str) -> np.ndarray:
        """ë²¡í„°í™”ëœ ì ìˆ˜ ê³„ì‚°"""
        tone_scores = np.array([
            self._match_tone(p, tone) for p in self.personas
        ])
        pace_scores = np.array([
            self._match_pace(p, pace) for p in self.personas
        ])
        intent_scores = np.array([
            self._match_intent(p, intent) for p in self.personas
        ])

        scores = np.array([tone_scores, pace_scores, intent_scores])
        return np.dot(self.weights, scores)

    def route(self, message: str) -> str:
        """ìµœì í™”ëœ ë¼ìš°íŒ…"""
        tone, pace, intent = self._analyze(message)
        scores = self.calculate_scores(tone, pace, intent)
        return self.personas[np.argmax(scores)]['name']
```

**ì˜ˆìƒ ê²°ê³¼**: ì ìˆ˜ ê³„ì‚° 40% ë‹¨ì¶•

---

## ğŸ“Š ì„±ëŠ¥ ê°œì„  ì˜ˆìƒ íš¨ê³¼

### ê°œì„  ì „í›„ ë¹„êµ

```
ë©”íŠ¸ë¦­              ê°œì„ ì „    1ìˆœìœ„   2ìˆœìœ„   3ìˆœìœ„   ëª©í‘œ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì‘ë‹µì‹œê°„ P50        0.8s    0.75s   0.70s   0.68s   < 1s âœ“
ì‘ë‹µì‹œê°„ P95        1.8s    1.65s   1.50s   1.40s   < 2s âœ“
ì‘ë‹µì‹œê°„ P99        4.2s    3.80s   3.50s   3.20s   < 5s âœ“
ë¡œê·¸ ì˜¤ë²„í—¤ë“œ       10ms    8ms     5ms     5ms     < 5ms
ì²˜ë¦¬ëŸ‰             5 req   5.5r    6r      6.5r    100+r
ë©”ëª¨ë¦¬ ì‚¬ìš©        280MB   300MB   320MB   350MB   < 500MB âœ“
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì˜ˆìƒ ê°œì„ ìœ¨                 ~12%    ~20%    ~25%
```

### ROI (Return on Investment)

#### ê°œë°œ ë¹„ìš© vs ì„±ëŠ¥ ê°œì„ 
```
Phase 1 (ìºì‹±)
- ê°œë°œ ë¹„ìš©: 16 ì‹œê°„
- ì„±ëŠ¥ ê°œì„ : 10%
- ë¹„ìš©/ê°œì„ : 1.6 ì‹œê°„/1%

Phase 2 (ë°°ì¹˜ ë¡œê¹…)
- ê°œë°œ ë¹„ìš©: 12 ì‹œê°„
- ì„±ëŠ¥ ê°œì„ : 12%
- ë¹„ìš©/ê°œì„ : 1.0 ì‹œê°„/1%

Phase 3 (ì ìˆ˜ ìµœì í™”)
- ê°œë°œ ë¹„ìš©: 6 ì‹œê°„
- ì„±ëŠ¥ ê°œì„ : 8%
- ë¹„ìš©/ê°œì„ : 0.75 ì‹œê°„/1%

ì´ ê°œë°œ ì‹œê°„: 34 ì‹œê°„ (1ì£¼)
ì´ ì„±ëŠ¥ ê°œì„ : 25%
ì´ ë¹„ìš©/ê°œì„ : 1.36 ì‹œê°„/1%
```

---

## ğŸ” ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ì¸¡ì •

### ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì „ëµ

#### 1. ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­
```python
# app/metrics.py
class PerformanceMetrics:
    def __init__(self):
        self.request_times = deque(maxlen=1000)
        self.error_count = 0
        self.request_count = 0

    @contextmanager
    def measure(self, endpoint: str):
        start = time.time()
        try:
            yield
        finally:
            elapsed = time.time() - start
            self.request_times.append({
                'endpoint': endpoint,
                'time': elapsed,
                'timestamp': time.time()
            })

# ì‚¬ìš©
with metrics.measure('/chat'):
    response = await process_request()
```

#### 2. ì£¼ìš” ë©”íŠ¸ë¦­
```
- ìš”ì²­ë‹¹ ì‘ë‹µ ì‹œê°„ (P50, P95, P99)
- 1ë¶„ë‹¹ ìš”ì²­ ìˆ˜ (throughput)
- ì—ëŸ¬ìœ¨ (errors/total)
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
- CPU ì‚¬ìš©ë¥  (%)
- ìºì‹œ íˆíŠ¸ìœ¨ (%)
```

#### 3. ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ
```
Grafana ëŒ€ì‹œë³´ë“œ:
â”œâ”€ ì‘ë‹µ ì‹œê°„ ì¶”ì´
â”œâ”€ ì²˜ë¦¬ëŸ‰ ì¶”ì´
â”œâ”€ ì—ëŸ¬ìœ¨ ì¶”ì´
â”œâ”€ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ 
â”œâ”€ ìºì‹œ íˆíŠ¸ìœ¨
â””â”€ í˜ë¥´ì†Œë‚˜ë³„ ë¶„í¬
```

### ì„±ëŠ¥ ì•Œë¦¼

```yaml
ì•Œë¦¼ ê·œì¹™:
  - P95 > 2ì´ˆ: ì£¼ì˜ (Yellow)
  - P95 > 3ì´ˆ: ê²½ê³  (Orange)
  - P95 > 5ì´ˆ: ê¸´ê¸‰ (Red)
  - ì—ëŸ¬ìœ¨ > 1%: ê²½ê³ 
  - ë©”ëª¨ë¦¬ > 400MB: ì£¼ì˜
```

---

## ğŸ“‹ ì„±ëŠ¥ ìµœì í™” ë¡œë“œë§µ

### Week 1-2: ê¸°ë³¸ ìµœì í™”
- [ ] ì‘ë‹µ ìºì‹± êµ¬í˜„
- [ ] ë°°ì¹˜ ë¡œê¹… êµ¬í˜„
- [ ] ì ìˆ˜ ê³„ì‚° ìµœì í™”
- [ ] ì„±ëŠ¥ ì¸¡ì • ë° ê²€ì¦

### Week 3-4: ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
- [ ] ì—°ê²° í’€ë§ ì„¤ì •
- [ ] ì¿¼ë¦¬ ìµœì í™”
- [ ] ì¸ë±ìŠ¤ ë¶„ì„ ë° ì¶”ê°€
- [ ] ìºì‹œ ì „ëµ ìˆ˜ë¦½

### Month 2: ê³ ê¸‰ ìµœì í™”
- [ ] ë¹„ë™ê¸° ì²˜ë¦¬ í™•ëŒ€
- [ ] CDN í†µí•© (static assets)
- [ ] API ì‘ë‹µ ì••ì¶•
- [ ] ì´ë¯¸ì§€ ìµœì í™”

### Month 3+: í™•ì¥ì„±
- [ ] ë©€í‹° ë¦¬ì „ ë°°í¬
- [ ] ê¸€ë¡œë²Œ ë¡œë“œ ë°¸ëŸ°ì‹±
- [ ] ë¶„ì‚° ìºì‹œ (Redis Cluster)
- [ ] ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë¶„ë¦¬

---

## ğŸ“ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë°©ë²•ë¡ 

### ë¶€í•˜ í…ŒìŠ¤íŠ¸ (Locust)

```python
# load_test.py
from locust import HttpUser, task, between

class ChatUser(HttpUser):
    wait_time = between(1, 2)

    @task
    def chat(self):
        self.client.post("/chat", json={
            "message": "ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ì…ë‹ˆë‹¤"
        })

    @task
    def health(self):
        self.client.get("/health")

# ì‹¤í–‰
# locust -f load_test.py --users 100 --spawn-rate 10 --run-time 10m
```

### ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸

```bash
# ì‘ë‹µ ì‹œê°„ ì¸¡ì •
time curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "í…ŒìŠ¤íŠ¸"}'

# ë™ì‹œ ìš”ì²­ (ab)
ab -n 1000 -c 100 http://localhost:8000/health

# í”„ë¡œíŒŒì¼ë§
python -m cProfile -s cumtime -m pytest tests/
```

---

## ğŸ“Œ ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­

### í˜„ì¬ ìƒíƒœ
- âœ… ì„±ëŠ¥: ëª©í‘œ ë‹¬ì„± (ì‘ë‹µ ì‹œê°„ P95 < 2s)
- âœ… ì•ˆì •ì„±: ì—ëŸ¬ìœ¨ 0% (í…ŒìŠ¤íŠ¸)
- âœ… í™•ì¥ì„±: Auto-scaling ì„¤ì • ì™„ë£Œ

### ì¦‰ì‹œ ì ìš© ì¶”ì²œ
1. **ì‘ë‹µ ìºì‹±** (ì‰¬ì›€, ì˜í–¥ í¼)
2. **ë°°ì¹˜ ë¡œê¹…** (ì‰¬ì›€, ì˜í–¥ ì¤‘ê°„)
3. **ì ìˆ˜ ê³„ì‚° ìµœì í™”** (ê°„ë‹¨, ì˜í–¥ ì¤‘ê°„)

### ì¤‘ê¸° ê°œì„  (1-3ê°œì›”)
1. **ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ë§**
2. **ë¹„ë™ê¸° ì²˜ë¦¬ í™•ëŒ€**
3. **ìºì‹œ ì „ëµ ìˆ˜ë¦½**

### ì¥ê¸° í™•ì¥ (3-6ê°œì›”)
1. **ë©€í‹° ë¦¬ì „ ë°°í¬**
2. **ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë¶„ë¦¬**
3. **ê³ ê¸‰ ëª¨ë‹ˆí„°ë§**

---

**ì„±ëŠ¥ ë¶„ì„ ì™„ë£Œ - í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ ìƒíƒœ ì–‘í˜¸** âœ…
