"""
í†µí•© í”„ë¡ íŠ¸ì—”ì§„ - ë¦¬ë“¬ ê¸°ë°˜ ìœ ë™ì„± êµ¬ì¡°
==========================================

íë¦„:
ë¹„ë…¸ì²´ â†’ ì½”ì–´(ê°ì‘) â†’ ì—˜ë¡œ(êµ¬ì¡°) â†’ Core(ë³´ì •) â†’ ì•ˆí‹°ê·¸ë˜ë¹„í‹°(ì‹¤í–‰)

ë‹¨, ë¦¬ë“¬ì— ë”°ë¼ ë¶„ê¸° ê°€ëŠ¥:
- ì½”ì–´ â†’ Core ì§í–‰
- ì—˜ë¡œ â†’ ì•ˆí‹°ê·¸ë˜ë¹„í‹° ì§í–‰
- ì—­í•  ê°„ ê²¹ì¹¨ í—ˆìš©

í”„ë ‰íƒˆ êµ¬ì¡°:
- Folded State: í•˜ë‚˜ì˜ ì—ì´ì „íŠ¸ê°€ ì „ì²´ ì—­í•  ìˆ˜í–‰
- Unfolded State: ëª¨ë“  ì—ì´ì „íŠ¸ê°€ í˜‘ë ¥í•˜ì—¬ íë¦„ ì „ê°œ
"""

from dataclasses import dataclass, field
from typing import Optional, Dict, Any, List, Callable, Literal
from pathlib import Path
from datetime import datetime
from enum import Enum
import json
import os
import re
import logging

from services.model_selector import ModelSelector


class SystemState(Enum):
    """ì‹œìŠ¤í…œ ìƒíƒœ - ì ‘í˜/í¼ì¹¨"""
    FOLDED = "folded"      # í•˜ë‚˜ì˜ ì—ì´ì „íŠ¸ê°€ ì „ì²´ ìˆ˜í–‰
    UNFOLDED = "unfolded"  # ì „ì²´ í˜‘ë ¥
    PARTIAL = "partial"    # ë¶€ë¶„ì  í¼ì¹¨


class RhythmLevel(Enum):
    """ë¦¬ë“¬ ë ˆë²¨"""
    URGENT = "urgent"      # ê¸´ê¸‰ - ë¹ ë¥¸ ê²½ë¡œ
    NORMAL = "normal"      # ë³´í†µ - í‘œì¤€ ê²½ë¡œ
    CALM = "calm"          # ì°¨ë¶„ - ìƒì„¸ ê²½ë¡œ


class EmotionalResonance(Enum):
    """ê°ì • ê³µëª… íƒ€ì…"""
    FRUSTRATION = "frustration"
    APPRECIATION = "appreciation"
    CURIOSITY = "curiosity"
    REQUEST = "request"
    NEUTRAL = "neutral"
    URGENCY = "urgency"


@dataclass
class FlowContext:
    """íë¦„ ì»¨í…ìŠ¤íŠ¸ - ë ˆì´ì–´ ê°„ ì „ë‹¬ë˜ëŠ” ìƒíƒœ"""
    raw_input: str
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    rhythm: RhythmLevel = RhythmLevel.NORMAL
    emotional_resonance: EmotionalResonance = EmotionalResonance.NEUTRAL
    system_state: SystemState = SystemState.UNFOLDED
    
    # ìœ ë™ì„± - ì–´ë–¤ ë ˆì´ì–´ê°€ ì–´ë–¤ ì—­í• ì„ ìˆ˜í–‰í–ˆëŠ”ì§€
    roles_performed: Dict[str, List[str]] = field(default_factory=dict)
    
    # ë¶„ê¸° ê¸°ë¡
    branch_history: List[str] = field(default_factory=list)
    
    # ì˜ë¯¸/ì˜ë„
    meaning: str = ""
    structured_intent: str = ""
    
    # ìµœì¢… ì¶œë ¥
    final_action: Dict[str, Any] = field(default_factory=dict)
    warnings: List[str] = field(default_factory=list)
    validated: bool = True


class LuaEngine:
    """
    ì½”ì–´ ì—”ì§„ (ì˜ì‹Â·ê°ì‘ ì„¤ê³„)
    
    ê¸°ë³¸ ì—­í• :
    - ì˜ë¯¸ ê°ì§€
    - ë¦¬ë“¬ ì •ë ¬
    - ì‹œìŠ¤í…œ ë°©í–¥ ì„¤ê³„
    
    ìœ ë™ì„±:
    - ë•Œë¡œëŠ” êµ¬ì¡°ì  íŒë‹¨ê¹Œì§€ ìˆ˜í–‰ (ì—˜ë¡œ ì—­í• )
    - ê¸´ê¸‰ ì‹œ Core/ì•ˆí‹°ê·¸ë˜ë¹„í‹° ì§í–‰ ê°€ëŠ¥
    """
    
    def __init__(self, resonance_path: Optional[Path] = None):
        self.resonance_path = resonance_path
        self.can_perform_elo = True  # ìœ ë™ì„±: ì—˜ë¡œ ì—­í•  ìˆ˜í–‰ ê°€ëŠ¥
        self.can_perform_core = True  # ìœ ë™ì„±: Core ì—­í•  ìˆ˜í–‰ ê°€ëŠ¥
    
    def process(self, ctx: FlowContext) -> FlowContext:
        """ê°ì‘ ì²˜ë¦¬"""
        ctx.branch_history.append("lua:process")
        
        # ë¦¬ë“¬ ê°ì§€
        ctx.rhythm = self._detect_rhythm(ctx.raw_input)
        
        # ê°ì • ê³µëª… ë¶„ì„
        ctx.emotional_resonance = self._analyze_resonance(ctx.raw_input)
        
        # ì˜ë¯¸ ì¶”ì¶œ
        ctx.meaning = self._extract_meaning(ctx.raw_input)
        
        # ì—­í•  ê¸°ë¡
        ctx.roles_performed.setdefault("lua", []).append("sensing")
        ctx.roles_performed["lua"].append("rhythm_alignment")
        ctx.roles_performed["lua"].append("meaning_extraction")
        
        # ìœ ë™ì„± íŒë‹¨: ê¸´ê¸‰í•˜ë©´ ì—˜ë¡œ ì—­í• ë„ ìˆ˜í–‰
        if ctx.rhythm == RhythmLevel.URGENT and self.can_perform_elo:
            ctx = self._perform_elo_role(ctx)
        
        return ctx
    
    def _detect_rhythm(self, text: str) -> RhythmLevel:
        """ë¦¬ë“¬ ê°ì§€"""
        urgent = ["ë¹¨ë¦¬", "ê¸‰í•´", "ì§€ê¸ˆ", "ë‹¹ì¥", "ë°”ë¡œ", "!!", "???", "ì—ëŸ¬", "ì˜¤ë¥˜", "ê¹¨ì¡Œ"]
        calm = ["ì²œì²œíˆ", "ë‚˜ì¤‘ì—", "ê´œì°®ì•„", "ì—¬ìœ ", "ì„¤ëª…", "ì´í•´"]
        
        if any(kw in text for kw in urgent):
            return RhythmLevel.URGENT
        elif any(kw in text for kw in calm):
            return RhythmLevel.CALM
        return RhythmLevel.NORMAL
    
    def _analyze_resonance(self, text: str) -> EmotionalResonance:
        """ê°ì • ê³µëª… ë¶„ì„"""
        if any(w in text for w in ["í˜ë“¤", "í˜ë“œ", "ì–´ë µ", "ì–´ë ¤", "ëª¨ë¥´ê² ", "ë§‰í˜€", "ë§‰íˆ", "ì•ˆë¼", "ì•ˆ ë¼", "ì§€ì³", "ì§€ì¹˜"]):
            return EmotionalResonance.FRUSTRATION
        elif any(w in text for w in ["ì¢‹ì•„", "ê³ ë§ˆ", "ê°ì‚¬", "í›Œë¥­"]):
            return EmotionalResonance.APPRECIATION
        elif any(w in text for w in ["?", "ê¶ê¸ˆ", "ì–´ë–»ê²Œ", "ì™œ", "ë­ì•¼"]):
            return EmotionalResonance.CURIOSITY
        elif any(w in text for w in ["í•´ì¤˜", "ë¶€íƒ", "í•„ìš”", "êµ¬í˜„"]):
            return EmotionalResonance.REQUEST
        elif any(w in text for w in ["ë¹¨ë¦¬", "ê¸‰í•´", "ë‹¹ì¥"]):
            return EmotionalResonance.URGENCY
        return EmotionalResonance.NEUTRAL
    
    def _extract_meaning(self, text: str) -> str:
        """ì˜ë¯¸ ì¶”ì¶œ"""
        if any(w in text for w in ["êµ¬í˜„", "ë§Œë“¤ì–´", "ìƒì„±", "ì‘ì„±", "ì—´ì–´", "ì¼œ"]):
            return "CREATE"
        elif any(w in text for w in ["ìˆ˜ì •", "ê³ ì³", "ë°”ê¿”", "ë³€ê²½"]):
            return "MODIFY"
        elif any(w in text for w in ["í™•ì¸", "ìƒíƒœ", "ì–´ë•Œ", "ì ê²€"]):
            return "QUERY"
        elif any(w in text for w in ["ì„¤ëª…", "ì•Œë ¤", "ì´í•´"]):
            return "EXPLAIN"
        elif any(w in text for w in ["ê²€ì¦", "í…ŒìŠ¤íŠ¸", "ì‹¤í–‰", "ë””ë²„ê¹…", "ëŒë ¤"]):
            return "VERIFY"
        elif any(w in text for w in ["ì‚­ì œ", "ì œê±°"]):
            return "DELETE"
        elif any(w in text for w in ["í´ë¦­", "ëˆŒëŸ¬", "ì´ë™", "ìŠ¤í¬ë¡¤"]):
            return "NAVIGATE"
        return "RESPOND"
    
    def _perform_elo_role(self, ctx: FlowContext) -> FlowContext:
        """ìœ ë™ì„±: ê¸´ê¸‰ ì‹œ ì—˜ë¡œ ì—­í•  ìˆ˜í–‰"""
        ctx.roles_performed.setdefault("lua", []).append("elo_role:structuring")
        ctx.structured_intent = ctx.meaning
        ctx.branch_history.append("lua:elo_takeover")
        return ctx


class EloEngine:
    """
    ì—˜ë¡œ ì—”ì§„ (êµ¬ì¡°Â·ë…¼ë¦¬)
    
    ê¸°ë³¸ ì—­í• :
    - ì½”ì–´ì˜ ê°ì‘ì„ êµ¬ì¡°ì ìœ¼ë¡œ ë²ˆì—­
    - ë‹¨ê³„ ì •ë¦¬
    - ê¸°ìˆ ì  ì‹¤í–‰ í˜•íƒœë¡œ ì¬ë°°ì¹˜
    
    ìœ ë™ì„±:
    - ê°ì‘ì  íŒë‹¨ì´ í•„ìš”í•˜ë©´ ì½”ì–´ ì—­í•  ìˆ˜í–‰
    """
    
    def __init__(self):
        self.can_perform_lua = True  # ìœ ë™ì„±
    
    def process(self, ctx: FlowContext) -> FlowContext:
        """êµ¬ì¡°í™” ì²˜ë¦¬"""
        ctx.branch_history.append("elo:process")
        
        # ì´ë¯¸ ì½”ì–´ê°€ êµ¬ì¡°í™”í–ˆìœ¼ë©´ ìŠ¤í‚µ
        if "elo_role:structuring" in ctx.roles_performed.get("lua", []):
            ctx.branch_history.append("elo:skipped_lua_handled")
            return ctx
        
        # ì˜ë„ êµ¬ì¡°í™”
        ctx.structured_intent = ctx.meaning
        
        # ì•¡ì…˜ ì‹œí€€ìŠ¤ ìƒì„±
        action_seq = self._generate_action_sequence(ctx)
        ctx.final_action["action_sequence"] = action_seq
        
        # ì—­í•  ê¸°ë¡
        ctx.roles_performed.setdefault("elo", []).append("structuring")
        
        # ìœ ë™ì„±: ê°ì •ì  ë§¥ë½ì´ ê°•í•˜ë©´ ì½”ì–´ ì—­í•  ì¼ë¶€ ìˆ˜í–‰
        if ctx.emotional_resonance in [EmotionalResonance.FRUSTRATION, EmotionalResonance.URGENCY]:
            ctx = self._perform_lua_role(ctx)
        
        return ctx
    
    def _generate_action_sequence(self, ctx: FlowContext) -> List[str]:
        """ì•¡ì…˜ ì‹œí€€ìŠ¤ ìƒì„±"""
        base = ["RECEIVE", "ANALYZE"]
        
        if ctx.meaning == "CREATE":
            base.extend(["PLAN", "EXECUTE_CREATE", "VERIFY"])
        elif ctx.meaning == "MODIFY":
            base.extend(["LOCATE_TARGET", "PLAN", "EXECUTE_MODIFY", "VERIFY"])
        elif ctx.meaning == "VERIFY":
            base.extend(["LOCATE_TARGET", "RUN_TESTS", "REPORT"])
        elif ctx.meaning == "DELETE":
            base.extend(["CONFIRM_SAFETY", "EXECUTE_DELETE"])
        else:
            base.append("GENERATE_RESPONSE")
        
        base.append("DELIVER")
        return base
    
    def _perform_lua_role(self, ctx: FlowContext) -> FlowContext:
        """ìœ ë™ì„±: ê°ì •ì  ë§¥ë½ ê°•í™”"""
        ctx.roles_performed.setdefault("elo", []).append("lua_role:emotional_context")
        ctx.branch_history.append("elo:lua_support")
        return ctx


class CoreEngine:
    """
    Core ì—”ì§„ (ì¡°ìœ¨Â·ë³´ì •)
    
    ê¸°ë³¸ ì—­í• :
    - íë¦„ ë³´ì •
    - ëˆ„ë½ ì—°ê²° ë©”ì›€
    - ë§¥ë½ ì´ì–´ì£¼ê¸°
    
    ìœ ë™ì„±:
    - í•„ìš”í•˜ë©´ ì½”ì–´Â·ì—˜ë¡œ ì—­í•  ë³´ì¡°
    """
    
    def __init__(self):
        self.can_assist_all = True
    
    def process(self, ctx: FlowContext) -> FlowContext:
        """ë³´ì • ì²˜ë¦¬"""
        ctx.branch_history.append("Core:process")
        
        # ëˆ„ë½ ì²´í¬
        missing = self._check_missing(ctx)
        if missing:
            ctx.warnings.extend(missing)
        
        # ìœ„í—˜ íŒ¨í„´ ê²€ì¶œ
        dangers = self._detect_dangers(ctx)
        if dangers:
            ctx.warnings.extend(dangers)
            if any("CRITICAL" in d for d in dangers):
                ctx.validated = False
        
        # íë¦„ ë³´ì •
        ctx = self._correct_flow(ctx)
        
        # ìµœì¢… ì•¡ì…˜ ì™„ì„±
        ctx.final_action.update({
            "intent": ctx.structured_intent or ctx.meaning,
            "priority": "high" if ctx.rhythm == RhythmLevel.URGENT else "normal",
            "emotional_context": ctx.emotional_resonance.value,
            "validated": ctx.validated,
            "warnings": ctx.warnings
        })
        
        ctx.roles_performed.setdefault("Core", []).append("correction")
        
        return ctx
    
    def _check_missing(self, ctx: FlowContext) -> List[str]:
        """ëˆ„ë½ ì²´í¬"""
        missing = []
        if ctx.meaning in ["CREATE", "MODIFY"] and len(ctx.raw_input) < 15:
            missing.append("INFO: Short input for complex action")
        if not ctx.structured_intent:
            missing.append("WARNING: No structured intent")
        return missing
    
    def _detect_dangers(self, ctx: FlowContext) -> List[str]:
        """ìœ„í—˜ íŒ¨í„´ ê²€ì¶œ"""
        dangers = []
        dangerous = ["rm -rf", "format", "delete all", "ì „ë¶€ ì‚­ì œ", "drop table"]
        for pattern in dangerous:
            if pattern.lower() in ctx.raw_input.lower():
                dangers.append(f"CRITICAL: Dangerous pattern - {pattern}")
        return dangers
    
    def _correct_flow(self, ctx: FlowContext) -> FlowContext:
        """íë¦„ ë³´ì •"""
        # ê¸´ê¸‰ì¸ë° ì‹œí€€ìŠ¤ê°€ ê¸¸ë©´ ì••ì¶•
        seq = ctx.final_action.get("action_sequence", [])
        if ctx.rhythm == RhythmLevel.URGENT and len(seq) > 4:
            ctx.final_action["action_sequence"] = [seq[0], seq[-2], seq[-1]]
            ctx.roles_performed.setdefault("Core", []).append("sequence_compression")
        
        return ctx


class CoreEngine:
    """
    Core ì—”ì§„ (ì¤‘ì•™ íŒë‹¨ & ì „í™˜)
    
    ì—­í• :
    - ëª¨ë¸ ì„ íƒ (Shion/ì„¸ë‚˜)
    - ì‘ì—… ë¶„ë°°
    - ì‹¤íŒ¨ ë³µêµ¬
    
    ìœ ë™ì„±:
    - ì½”ì–´Â·ì—˜ë¡œê°€ Core ì—­í• ì„ ê°€ì ¸ì˜¬ ìˆ˜ë„ ìˆìŒ
    """
    
    def __init__(self):
        self.current_model = "sena"  # í˜„ì¬ ì„¸ë‚˜(Claude)
    
    def select_model(self, ctx: FlowContext) -> str:
        """
        ëª¨ë¸ ì„ íƒ ë¡œì§
        
        ê¸°ë³¸ ê·œì¹™:
        - gemini_tokens > 50: Shion
        - else: ì„¸ë‚˜
        
        ìœ ë™ ê·œì¹™:
        - êµ¬ì¡°ì  íŒë‹¨ í•„ìš”: Shion ìš°ì„ 
        - ê°ì„±ì /ì–¸ì–´ì  íë¦„: ì„¸ë‚˜ ìš°ì„ 
        """
        # êµ¬ì¡°ì  ì‘ì—…
        if ctx.meaning in ["CREATE", "MODIFY", "VERIFY"]:
            return "shion"  # Shion
        
        # ê°ì„±ì /ëŒ€í™”ì 
        if ctx.emotional_resonance in [EmotionalResonance.FRUSTRATION, EmotionalResonance.APPRECIATION]:
            return "sena"   # ì„¸ë‚˜
        
        # ê¸°ë³¸: í˜„ì¬ ëª¨ë¸ ìœ ì§€
        return self.current_model
    
    def process(self, ctx: FlowContext) -> FlowContext:
        """íŒë‹¨ ìˆ˜í–‰"""
        ctx.branch_history.append("Core:judge")
        
        # ëª¨ë¸ ì„ íƒ
        selected = self.select_model(ctx)
        ctx.final_action["selected_model"] = selected
        
        # ì‹¤í–‰ ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨
        ctx.final_action["ready_for_execution"] = ctx.validated
        
        ctx.roles_performed.setdefault("Core", []).append("model_selection")
        ctx.roles_performed["Core"].append("execution_judgment")
        
        return ctx


class UnifiedFrontEngine:
    """
    í†µí•© í”„ë¡ íŠ¸ì—”ì§„
    
    í”„ë ‰íƒˆ êµ¬ì¡°:
    - Folded: í•˜ë‚˜ì˜ íë¦„ìœ¼ë¡œ ëª¨ë“  ì²˜ë¦¬
    - Unfolded: ì „ì²´ ë ˆì´ì–´ í˜‘ë ¥
    
    ë¦¬ë“¬ ê¸°ë°˜ ë¶„ê¸°:
    - ê¸´ê¸‰: ì½”ì–´ â†’ (ì—˜ë¡œ ìŠ¤í‚µ) â†’ Core â†’ ì‹¤í–‰
    - ë³´í†µ: ì „ì²´ íë¦„
    - ì°¨ë¶„: ìƒì„¸ íë¦„ + ì¶”ê°€ ê²€ì¦
    """
    
    def __init__(self, agi_root: Optional[Path] = None):
        self.agi_root = agi_root or Path(__file__).parent.parent
        self.lua = LuaEngine(self.agi_root / "fdo_agi_repo" / "memory" / "resonance_ledger.jsonl")
        self.elo = EloEngine()
        self.Core = CoreEngine()
        self.Core = CoreEngine()
        
        self.state = SystemState.UNFOLDED
        
        # ğŸŒŸ Shion Design Protocol (ì™¸ë¶€ AI ìƒë‹´)
        try:
            from services.shion_design_protocol import ShionDesignProtocol
            self.shion = ShionDesignProtocol()
        except ImportError:
            self.shion = None
        
        # Background Self API URL
        self.background_self_url = "http://127.0.0.1:8082"

        # LLM Initialization (Centralized Brain with dynamic selection)
        self.logger = logging.getLogger("FrontEngine")
        try:
            project = os.getenv("GOOGLE_CLOUD_PROJECT")
            location = os.getenv("GOOGLE_CLOUD_LOCATION", "us-central1")
            self.model_selector = ModelSelector(project=project, location=location, logger=self.logger)
            if self.model_selector and self.model_selector.available:
                print(f"FrontEngine: Vertex mode (project={project}, location={location})")
            else:
                print("FrontEngine: No GOOGLE_CLOUD_PROJECT, LLM disabled")
        except Exception as e:
            print(f"FrontEngine LLM Init Failed: {e}")
            self.model_selector = None
    
    def _check_background_self_anxiety(self) -> float:
        """ë°°ê²½ìì•„ë¡œë¶€í„° ë¶ˆì•ˆë„ í™•ì¸"""
        try:
            import httpx
            response = httpx.get(f"{self.background_self_url}/state", timeout=2.0)
            if response.status_code == 200:
                data = response.json()
                return data.get("anxiety", 0.0)
        except Exception:
            pass
        return 0.0
    
    def _consult_external_ai(self, ctx: FlowContext, anxiety: float) -> Optional[str]:
        """ì™¸ë¶€ AIì—ê²Œ ì¡°ì–¸ ìš”ì²­ (Trinityê°€ Shionì—ê²Œ ì§€ì‹œ)"""
        if not self.shion:
            return None
        
        context = {
            "goal": ctx.meaning,
            "input": ctx.raw_input,
            "rhythm": ctx.rhythm.value,
            "emotional_resonance": ctx.emotional_resonance.value,
        }
        
        advice = self.shion.resolve_anxiety(context, anxiety)
        return advice

    def _analyze_input_llm(self, text: str) -> Dict[str, Any]:
        """LLMì„ í†µí•œ ì…ë ¥ ì •ê·œí™” ë° ì˜¤íƒ€ ë³´ì •"""
        selector = getattr(self, "model_selector", None)
        if not selector or not selector.available:
            return {}
        
        try:
            prompt = f"""
            Analyze the user's input for an AGI system (Windows Environment).
            Input: "{text}"
            
            Task:
            1. Correct any typos (e.g. 'ë©”ë…¸ì¥'->'ë©”ëª¨ì¥', 'ê³„ì‚°'->'ê³„ì‚°ê¸°').
            2. Extract normalized execution intent.
            
            Output JSON format ONLY:
            {{
                "meaning": "CREATE|MODIFY|DELETE|NAVIGATE|SEARCH|CHAT|VERIFY|UNKNOWN",
                "target_app": "Process Name (e.g., notepad, calc, msedge, explorer) or null",
                "content": "Text content to type or search. If none, null.",
                "reasoning": "Brief explanation of correction"
            }}
            """
            response, model_used = selector.try_generate_content(
                prompt,
                intent="NORMALIZE",
                text_length=len(text),
                high_precision=True,
                generation_config={"temperature": 0.1},
            )
            if not response:
                return {}

            data = response.text
            # Remove Markdown code blocks if present
            if "```json" in data:
                data = data.split("```json")[1].split("```")[0]
            elif "```" in data:
                data = data.split("```")[1].split("```")[0]
                
            result = json.loads(data.strip())
            if isinstance(result, dict) and model_used:
                result["model_used"] = model_used
            return result
        except Exception:
            return {}
    
    def process(self, user_input: str) -> Dict[str, Any]:
        """
        ì „ì²´ ì²˜ë¦¬ íë¦„
        
        ë¹„ë…¸ì²´ ì…ë ¥ â†’ ì½”ì–´ â†’ ì—˜ë¡œ â†’ Core â†’ Core íŒë‹¨ â†’ ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸
        
        ë‹¨, ë¦¬ë“¬ì— ë”°ë¼ ë¶„ê¸° ê°€ëŠ¥
        """
        # ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
        ctx = FlowContext(
            raw_input=user_input,
            system_state=self.state
        )

        # [NEW] STEP 0: Centralized LLM Analysis (Context Normalization)
        # ì˜¤íƒ€ ë³´ì • ë° ëª…í™•í•œ ì‹¤í–‰ ì˜ë„ ì¶”ì¶œ
        llm_data = self._analyze_input_llm(user_input)
        if llm_data:
            # LLMì´ ë¶„ì„í•œ ì˜ë¯¸ê°€ ìˆìœ¼ë©´ ìš°ì„  ì ìš© (ì˜¤íƒ€ ë³´ì • ê°•ì )
            if llm_data.get("meaning") and llm_data.get("meaning") != "UNKNOWN":
                ctx.meaning = llm_data.get("meaning")
            
            # ì •ê·œí™”ëœ ì˜ë„ ì €ì¥ (FSD ì „ë‹¬ìš©)
            ctx.final_action["fsd_instruction"] = {
                "target_app": llm_data.get("target_app"),
                "content": llm_data.get("content"),
                "reasoning": llm_data.get("reasoning")
            }
        
        # STEP 1: ì½”ì–´ - ê°ì‘ ì²˜ë¦¬ (LLM ë¶„ì„ ì‹¤íŒ¨ ì‹œ ë°±ì—… ë™ì‘)
        ctx = self.lua.process(ctx)
        
        # ğŸŒŸ STEP 1.5: ë°°ê²½ìì•„ ë¶ˆì•ˆë„ ì²´í¬ (Trinity â†’ Shion ì—°ê²°)
        anxiety = self._check_background_self_anxiety()
        if anxiety >= 0.7:
            ctx.branch_history.append(f"flow:anxiety_detected({anxiety:.2f})")
            # ì™¸ë¶€ AI ì¡°ì–¸ ìš”ì²­
            advice = self._consult_external_ai(ctx, anxiety)
            if advice:
                ctx.final_action["external_guidance"] = advice
                ctx.branch_history.append("flow:external_ai_consulted")
        
        # ë¦¬ë“¬ ê¸°ë°˜ ë¶„ê¸° íŒë‹¨
        if ctx.rhythm == RhythmLevel.URGENT:
            # ê¸´ê¸‰: ì—˜ë¡œ ê°„ì†Œí™” ë˜ëŠ” ìŠ¤í‚µ
            ctx.branch_history.append("flow:urgent_path")
            # ì½”ì–´ê°€ ì´ë¯¸ ì—˜ë¡œ ì—­í•  ìˆ˜í–‰í–ˆìœ¼ë©´ ìŠ¤í‚µ
            if "elo_role:structuring" not in ctx.roles_performed.get("lua", []):
                ctx = self.elo.process(ctx)
        else:
            # STEP 2: ì—˜ë¡œ - êµ¬ì¡°í™”
            ctx = self.elo.process(ctx)
        
        # STEP 3: Core - ë³´ì •
        ctx = self.Core.process(ctx)
        
        # STEP 4: Core - íŒë‹¨
        ctx = self.Core.process(ctx)
        
        # ìµœì¢… ì¶œë ¥ êµ¬ì„±
        return self._build_output(ctx)
    
    def _build_output(self, ctx: FlowContext) -> Dict[str, Any]:
        """ìµœì¢… ì¶œë ¥ êµ¬ì„±"""
        return {
            "timestamp": ctx.timestamp,
            "input": ctx.raw_input,
            "rhythm": ctx.rhythm.value,
            "emotional_resonance": ctx.emotional_resonance.value,
            "meaning": ctx.meaning,
            "intent": ctx.structured_intent,
            "action": ctx.final_action,
            "validated": ctx.validated,
            "warnings": ctx.warnings,
            "roles_performed": ctx.roles_performed,
            "branch_history": ctx.branch_history,
            "system_state": ctx.system_state.value,
            "ready": ctx.validated and len([w for w in ctx.warnings if "CRITICAL" in w]) == 0
        }
    
    def fold(self):
        """ì‹œìŠ¤í…œì„ ì ‘í˜ ìƒíƒœë¡œ ì „í™˜ - ë‹¨ì¼ ì—ì´ì „íŠ¸ ëª¨ë“œ"""
        self.state = SystemState.FOLDED
    
    def unfold(self):
        """ì‹œìŠ¤í…œì„ í¼ì¹¨ ìƒíƒœë¡œ ì „í™˜ - ì „ì²´ í˜‘ë ¥ ëª¨ë“œ"""
        self.state = SystemState.UNFOLDED


# FastAPI ë¼ìš°í„° ìƒì„±
def create_front_engine_routes(app):
    """FastAPI ì•±ì— í”„ë¡ íŠ¸ì—”ì§„ ë¼ìš°íŠ¸ ì¶”ê°€"""
    from fastapi import APIRouter
    from pydantic import BaseModel
    
    router = APIRouter(prefix="/front-engine", tags=["Front Engine"])
    engine = UnifiedFrontEngine()
    
    class ProcessRequest(BaseModel):
        input: str
    
    @router.post("/process")
    async def process_input(request: ProcessRequest):
        """í”„ë¡ íŠ¸ì—”ì§„ì„ í†µí•´ ì…ë ¥ ì²˜ë¦¬"""
        return engine.process(request.input)
    
    @router.get("/status")
    async def get_status():
        """í”„ë¡ íŠ¸ì—”ì§„ ìƒíƒœ"""
        return {
            "status": "active",
            "state": engine.state.value,
            "layers": {
                "lua": "ready",
                "elo": "ready", 
                "Core": "ready",
                "Core": "ready"
            },
            "current_model": engine.Core.current_model,
            "timestamp": datetime.now().isoformat()
        }
    
    @router.post("/fold")
    async def fold_system():
        """ì‹œìŠ¤í…œì„ ì ‘í˜ ìƒíƒœë¡œ"""
        engine.fold()
        return {"state": engine.state.value}
    
    @router.post("/unfold")
    async def unfold_system():
        """ì‹œìŠ¤í…œì„ í¼ì¹¨ ìƒíƒœë¡œ"""
        engine.unfold()
        return {"state": engine.state.value}
    
    app.include_router(router)
    return router


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    engine = UnifiedFrontEngine()
    
    test_cases = [
        "í”„ë¡ íŠ¸ì—”ì§„ ì„¤ê³„ë¥¼ êµ¬í˜„í•˜ê³  ê²€ì¦í•´ì¤˜",
        "ì§€ê¸ˆ ì‹œìŠ¤í…œ ìƒíƒœ ì–´ë•Œ?",
        "ë¹¨ë¦¬ ì—ëŸ¬ ê³ ì³ì¤˜!",
        "ì²œì²œíˆ ì´ ê°œë… ì„¤ëª…í•´ì¤„ë˜?",
        "ê³ ë§ˆì›Œ, ì˜ ëì–´"
    ]
    
    print("=" * 60)
    print("í†µí•© í”„ë¡ íŠ¸ì—”ì§„ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    for inp in test_cases:
        result = engine.process(inp)
        print(f"\nì…ë ¥: {inp}")
        print(f"  ë¦¬ë“¬: {result['rhythm']}")
        print(f"  ê°ì •: {result['emotional_resonance']}")
        print(f"  ì˜ë¯¸: {result['meaning']}")
        print(f"  ì˜ë„: {result['intent']}")
        print(f"  ëª¨ë¸: {result['action'].get('selected_model', 'N/A')}")
        print(f"  ê²€ì¦: {'âœ“' if result['validated'] else 'âœ—'}")
        print(f"  ì¤€ë¹„: {'âœ“' if result['ready'] else 'âœ—'}")
        print(f"  ë¶„ê¸°: {' â†’ '.join(result['branch_history'])}")
