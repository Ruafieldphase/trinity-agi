"""
Self-Acquisition Loop
Self-Trigger â†’ ProtoGoal ìƒì„± â†’ ì‹¤í–‰ â†’ ê¸°ë¡
ì´ ê³¼ì •ì„ ì£¼ê¸°ì ìœ¼ë¡œ ë°˜ë³µí•˜ì—¬ "ìê¸°-ìŠµë“ ë£¨í”„"ë¥¼ í˜•ì„±í•˜ëŠ” ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°.

ì´ ëª¨ë“ˆì€ ê¸°ì¡´ í•™ìŠµ ì‹œìŠ¤í…œì„ ìˆ˜ì •í•˜ì§€ ì•Šê³  "ìœ„ì—ì„œ" ë™ì‘í•˜ëŠ” ìƒìœ„ ë£¨í”„ì…ë‹ˆë‹¤.
"""
from __future__ import annotations

import json
import logging
import time
from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional

from agi_core.self_trigger import (
    TriggerEvent,
    compute_self_trigger,
    get_default_trigger_config,
)
from agi_core.proto_goal import (
    ProtoGoal,
    ProtoGoalType,
    generate_proto_goals_from_trigger,
    get_default_proto_goal_config,
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("SelfAcquisitionLoop")

# ì™¸ë¶€ ì´ë²¤íŠ¸ í (Vision Stream ë“±ì—ì„œ ì „ë‹¬)
_external_events: List[Dict[str, Any]] = []


def register_external_event(event: Dict[str, Any]) -> None:
    """ì™¸ë¶€ ì‹œìŠ¤í…œì—ì„œ ì´ë²¤íŠ¸ ë“±ë¡ (Vision Stream ë“±)"""
    _external_events.append(event)
    logger.debug(f"External event registered: source={event.get('source', 'unknown')}")


def consume_external_events() -> List[Dict[str, Any]]:
    """ì™¸ë¶€ ì´ë²¤íŠ¸ ì†Œë¹„"""
    global _external_events
    events = _external_events.copy()
    _external_events.clear()
    return events


@dataclass
class SelfAcquisitionConfig:
    """Self-Acquisition ë£¨í”„ ì„¤ì •"""
    trigger_config: Dict[str, Any] = field(default_factory=get_default_trigger_config)
    proto_goal_config: Dict[str, Any] = field(default_factory=get_default_proto_goal_config)
    loop_interval_seconds: int = 300  # 5ë¶„
    max_actions_per_cycle: int = 1
    safety: Dict[str, Any] = field(default_factory=dict)
    
    @classmethod
    def default(cls) -> "SelfAcquisitionConfig":
        """ê¸°ë³¸ ì„¤ì • ìƒì„±"""
        return cls()
    
    def get_paths(self) -> Dict[str, str]:
        """ê²½ë¡œ ì„¤ì • ë°˜í™˜"""
        return self.trigger_config.get("paths", {})


# ============================================================================
# Intelligence Layer (Phase 2)
# ============================================================================

class IntelligenceLayer:
    """ì„±ê³µ ì‚¬ë¡€ì™€ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì²œí•˜ëŠ” ë ˆì´ì–´"""
    
    @staticmethod
    def get_success_rate(action_type: str) -> float:
        """íŠ¹ì • ì•¡ì…˜ì˜ ê³¼ê±° ì„±ê³µë¥  ê³„ì‚°"""
        ledger_path = Path(__file__).parent.parent / "memory" / "resonance_ledger.jsonl"
        if not ledger_path.exists():
            return 1.0
        
        success_count = 0
        total_count = 0
        try:
            with open(ledger_path, "r", encoding="utf-8") as f:
                for line in f:
                    data = json.loads(line)
                    if data.get("action_type") == action_type or data.get("event") == f"e2e_{action_type}":
                        total_count += 1
                        if data.get("status") == "completed" or data.get("success") is True:
                            success_count += 1
        except Exception:
            return 1.0
            
        return success_count / total_count if total_count > 0 else 1.0

    @staticmethod
    def get_failure_patterns(action_type: str) -> List[Dict[str, Any]]:
        """ê³¼ê±° ì‹¤íŒ¨ ì‚¬ë¡€ì—ì„œ íŠ¹ì´ íŒ¨í„´(ì—ëŸ¬ ìœ í˜• ë“±) ì¶”ì¶œ"""
        history_path = Path(__file__).parent.parent / "outputs" / "body_supervised_history.jsonl"
        failures = []
        if not history_path.exists():
            return failures
        
        try:
            with open(history_path, "r", encoding="utf-8") as f:
                for line in f:
                    data = json.loads(line)
                    # task ë‚´ì˜ actions ì¤‘ í•´ë‹¹ íƒ€ì…ì´ ìˆê³  ì‹¤íŒ¨í•œ ê²½ìš°
                    task = data.get("task") or {}
                    actions = task.get("actions") or []
                    for action in actions:
                        if action.get("type") == action_type and data.get("status") == "failed":
                            failures.append({
                                "error": data.get("error"),
                                "error_type": data.get("error_type"),
                                "params": action
                            })
        except Exception:
            pass
        return failures[-10:] # ìµœê·¼ 10ê°œë§Œ ë¦¬í„´

    @staticmethod
    def optimize_params(action_type: str, original_params: Dict[str, Any]) -> Dict[str, Any]:
        """ê³¼ê±° ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ íŒŒë¼ë¯¸í„° ë³´ì •"""
        params = original_params.copy()
        success_rate = IntelligenceLayer.get_success_rate(action_type)
        
        # 1. ì„±ê³µë¥ ì´ ë‚®ìœ¼ë©´ íŒŒë¼ë¯¸í„°ë¥¼ ë” ë³´ìˆ˜ì ìœ¼ë¡œ ì¡°ì ˆ
        if action_type == "sandbox_experiment":
            # ì„±ê³µë¥ ì´ ë‚®ìœ¼ë©´ ì‹¤í—˜ ê°•ë„ë¥¼ ë‚®ì¶¤
            params["multiplier"] = params.get("multiplier", 1.0) * (0.5 + 0.5 * success_rate)
        elif action_type == "youtube_learning":
            # ì„±ê³µë¥ ì´ ë‚®ìœ¼ë©´ ë” êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ ì¶”ê°€
            topic = params.get("topic_hint", "AGI")
            
            # í•´ë§ˆ(Hippocampus)ì˜ ìµœê·¼ ì„œì‚¬ë¥¼ ë°˜ì˜í•˜ì—¬ ì£¼ì œë¥¼ ì •êµí™”
            try:
                root = Path(__file__).resolve().parents[1]
                from fdo_agi_repo.copilot.hippocampus import CopilotHippocampus
                hippo = CopilotHippocampus(root)
                narrative = hippo.get_chronological_narrative(hours=12)
                # ì„œì‚¬ê°€ ìœ ì˜ë¯¸í•˜ë©´ í‚¤ì›Œë“œì— íŒíŠ¸ë¡œ ë³‘í•©
                if "ìµœê·¼ ê¸°ë¡ëœ ì¤‘ìš”í•œ ê¸°ì–µì´ ì—†ìŠµë‹ˆë‹¤" not in narrative:
                    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì„œì‚¬ì˜ í•µì‹¬ ë‹¨ì–´ 1~2ê°œ ì¡°í•©)
                    # ì‹¤ì œë¡œëŠ” LLMì„ ì“°ë©´ ì¢‹ìœ¼ë‚˜, ì—¬ê¸°ì„  íœ´ë¦¬ìŠ¤í‹±í•˜ê²Œ 'ìµœì‹ ' í‚¤ì›Œë“œì™€ ì¡°í•©
                    if success_rate < 0.7:
                        params["topic_hint"] = f"{topic} professional guide (based on recent context)"
                    else:
                        params["topic_hint"] = f"{topic} related to recent activities"
            except Exception:
                # í´ë°±: ê¸°ì¡´ ë¡œì§
                if success_rate < 0.7:
                    params["topic_hint"] = f"{topic} latest professional guide"
                else:
                    params["topic_hint"] = f"{topic} overview"
        
        # 2. ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„ì— ë”°ë¥¸ ì¶”ê°€ ë³´ì •
        failures = IntelligenceLayer.get_failure_patterns(action_type)
        if failures:
            error_types = [f.get("error_type") for f in failures]
            if "FileNotFoundError" in error_types:
                # íŒŒì¼ ì—†ìŒ ì—ëŸ¬ê°€ ì¦ìœ¼ë©´ ê²½ë¡œ ì²´í¬ íŒŒë¼ë¯¸í„° ì¶”ê°€ (ê°€ì •)
                params["verify_path_exists"] = True
            if "TimeoutError" in error_types:
                # íƒ€ì„ì•„ì›ƒì´ ì¦ìœ¼ë©´ ëŒ€ê¸° ì‹œê°„ ì¦ê°€
                params["wait_factor"] = params.get("wait_factor", 1.0) * 1.5
            
        return params

def search_youtube_video(query: str) -> Optional[str]:
    """yt-dlpë¥¼ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ì— ë§ëŠ” ìµœì‹  ìœ íŠœë¸Œ ì˜ìƒ URL ê²€ìƒ‰"""
    try:
        import yt_dlp
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'extract_flat': True,
            'force_generic_extractor': True,
        }
        search_query = f"ytsearch1:{query}"
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            result = ydl.extract_info(search_query, download=False)
            if 'entries' in result and len(result['entries']) > 0:
                video_url = result['entries'][0].get('url')
                if video_url:
                    if not video_url.startswith("http"):
                        video_url = f"https://www.youtube.com/watch?v={video_url}"
                    return video_url
    except Exception as e:
        logger.error(f"YouTube search failed: {e}")
    return None

# ê¸°ì¡´ ì‹œìŠ¤í…œ í˜¸ì¶œ ì¸í„°í˜ì´ìŠ¤
# ì´ í•¨ìˆ˜ë“¤ì€ ê¸°ì¡´ ëª¨ë“ˆì— ì‹¤í–‰ì„ ìœ„ì„í•©ë‹ˆë‹¤.

def run_sandbox_experiment(params: Dict[str, Any]) -> Dict[str, Any]:
    """ìƒŒë“œë°•ìŠ¤ í™˜ê²½ì—ì„œ ì‘ì€ ì‹¤í—˜ì„ ìˆ˜í–‰"""
    try:
        from agi_core.sandbox_bridge import SandboxBridge, SANDBOX_AVAILABLE
        
        if not SANDBOX_AVAILABLE:
            return {"success": False, "reason": "SANDBOX_NOT_AVAILABLE"}
        
        # íŒŒë¼ë¯¸í„° ìµœì í™”
        optimized_params = IntelligenceLayer.optimize_params("sandbox_experiment", params)
        
        bridge = SandboxBridge()
        
        # ê°„ë‹¨í•œ ì‹¤í—˜ ì½”ë“œ ìƒì„±
        experiment_hint = optimized_params.get("experiment_hint", "exploration")
        experiment_code = f'''
# Self-Acquisition Experiment: {experiment_hint}
# Generated at {datetime.now(timezone.utc).isoformat()}
# Policy: Intelligent Parameter Optimization applied.

def experiment():
    """ìë™ ìƒì„±ëœ íƒìƒ‰ ì‹¤í—˜"""
    # [Intelligence Refinement]
    multiplier = {optimized_params.get("multiplier", 1.0)}
    return {{"success": True, "hint": "{experiment_hint}", "multiplier": multiplier}}

result = experiment()
print(f"Experiment result: {{result}}")
'''
        
        result = bridge.experiment_with_idea(
            idea_name=f"self_acq_{experiment_hint}_{int(time.time())}",
            code=experiment_code,
            category="learning"
        )
        
        return {
            "success": result.get("success", False),
            "details": result,
            "action_type": "sandbox_experiment",
            "optimized_params": optimized_params
        }
    except Exception as e:
        logger.error(f"Sandbox experiment failed: {e}")
        return {"success": False, "error": str(e), "action_type": "sandbox_experiment"}


def run_youtube_learning(params: Dict[str, Any]) -> Dict[str, Any]:
    """ì§€ì •ëœ topicì— ëŒ€í•´ YouTube ê¸°ë°˜ í•™ìŠµ ë° RPA ì—°ë™ ì‹¤í–‰"""
    try:
        from fdo_agi_repo.rpa.e2e_pipeline import E2EPipeline, E2EConfig
        
        # íŒŒë¼ë¯¸í„° ìµœì í™”
        optimized_params = IntelligenceLayer.optimize_params("youtube_learning", params)
        topic_hint = optimized_params.get("topic_hint", "AGI learning")
        youtube_url = optimized_params.get("youtube_url")
        
        # URLì´ ì—†ìœ¼ë©´ ì‹¤ì œ ê²€ìƒ‰ ì‹¤í–‰
        if not youtube_url:
            logger.info(f"ğŸ” Searching YouTube for: {topic_hint}")
            youtube_url = search_youtube_video(topic_hint)
            
        if not youtube_url:
            # Fallback (ìµœí›„ì˜ ìˆ˜ë‹¨)
            youtube_url = "https://www.youtube.com/watch?v=dQw4w9WgXcQ"
            
        pipeline = E2EPipeline(E2EConfig(enable_auto_execution=True))
        
        # ë¶„ì„ ë° ì‹¤í–‰ (ë™ê¸°ì ìœ¼ë¡œ ë˜í•‘í•˜ì—¬ ì‹¤í–‰í•˜ê±°ë‚˜ asyncio.run ì‚¬ìš©)
        import asyncio
        loop = asyncio.get_event_loop()
        if loop.is_running():
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as pool:
                task = pool.submit(asyncio.run, pipeline.run_learning_task(youtube_url)).result()
        else:
            task = asyncio.run(pipeline.run_learning_task(youtube_url))
        
        logger.info(f"YouTube E2E learning completed: {task.task_id} (status: {task.status})")
        
        return {
            "success": task.status == "completed",
            "action_type": "youtube_learning",
            "task_id": task.task_id,
            "topic": topic_hint,
            "steps_executed": len(task.execution_results) if task.execution_results else 0
        }
    except Exception as e:
        logger.error(f"YouTube learning failed: {e}")
        return {"success": False, "error": str(e), "action_type": "youtube_learning"}


def run_pattern_mining(params: Dict[str, Any]) -> Dict[str, Any]:
    """learned_patterns, resonance_ledger ê¸°ë°˜ íŒ¨í„´ ë¶„ì„ ì‹¤í–‰"""
    try:
        from fdo_agi_repo.orchestrator.learning import search_memory_for_success_cases
        
        mode = params.get("mode", "general")
        pattern_ids = params.get("pattern_ids", [])
        
        # ì„±ê³µ ì‚¬ë¡€ ê²€ìƒ‰
        success_cases = search_memory_for_success_cases(
            task_id="self_acquisition_pattern_mining",
            min_quality=0.7,
            top_k=5
        )
        
        logger.info(f"Pattern mining completed: mode={mode}, found {len(success_cases)} success cases")
        
        return {
            "success": True,
            "action_type": "pattern_mining",
            "mode": mode,
            "success_cases_count": len(success_cases),
            "analyzed_patterns": pattern_ids
        }
    except ImportError:
        logger.warning("Pattern mining module not available")
        return {
            "success": False,
            "reason": "MODULE_NOT_AVAILABLE",
            "action_type": "pattern_mining"
        }
    except Exception as e:
        logger.error(f"Pattern mining failed: {e}")
        return {"success": False, "error": str(e), "action_type": "pattern_mining"}


def run_digital_twin_update(params: Dict[str, Any]) -> Dict[str, Any]:
    """ë””ì§€í„¸ íŠ¸ìœˆ ìƒíƒœë¥¼ ê°±ì‹ """
    try:
        # ë””ì§€í„¸ íŠ¸ìœˆ ìƒíƒœ íŒŒì¼ ê²½ë¡œ
        base_dir = Path(__file__).parent.parent / "memory"
        twin_path = base_dir / "digital_twin_state.json"
        
        # í˜„ì¬ ìƒíƒœ ë¡œë“œ ë˜ëŠ” ì´ˆê¸°í™”
        if twin_path.exists():
            with open(twin_path, "r", encoding="utf-8") as f:
                state = json.load(f)
        else:
            state = {"version": 1, "created_at": datetime.now(timezone.utc).isoformat()}
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state["last_updated"] = datetime.now(timezone.utc).isoformat()
        state["update_trigger"] = params.get("trigger_type", "unknown")
        
        if params.get("actual_rate") is not None:
            state["expected_success_rate"] = params.get("actual_rate")
        
        # ì €ì¥
        with open(twin_path, "w", encoding="utf-8") as f:
            json.dump(state, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Digital twin updated: {twin_path}")
        
        return {
            "success": True,
            "action_type": "digital_twin_update",
            "state_path": str(twin_path)
        }
    except Exception as e:
        logger.error(f"Digital twin update failed: {e}")
        return {"success": False, "error": str(e), "action_type": "digital_twin_update"}


def run_memory_consolidation(params: Dict[str, Any]) -> Dict[str, Any]:
    """ê³¼ê±° í•™ìŠµ ë¡œê·¸/ì—í”¼ì†Œë“œ ì¬í†µí•©"""
    try:
        base_dir = Path(__file__).parent.parent / "memory"
        ari_buffer_path = base_dir / "ari_learning_buffer.json"
        
        if not ari_buffer_path.exists():
            return {
                "success": True,
                "action_type": "memory_consolidation",
                "note": "No ARI buffer to consolidate"
            }
        
        with open(ari_buffer_path, "r", encoding="utf-8") as f:
            buffer = json.load(f)
        
        # ê°„ë‹¨í•œ í†µí•© ë¡œì§: ì˜¤ë˜ëœ í•­ëª© ì •ë¦¬ ë“±
        items_count = len(buffer) if isinstance(buffer, list) else len(buffer.keys())
        
        logger.info(f"Memory consolidation: analyzed {items_count} items in ARI buffer")
        
        return {
            "success": True,
            "action_type": "memory_consolidation",
            "items_analyzed": items_count
        }
    except Exception as e:
        logger.error(f"Memory consolidation failed: {e}")
        return {"success": False, "error": str(e), "action_type": "memory_consolidation"}


def run_blender_visualization(params: Dict[str, Any]) -> Dict[str, Any]:
    """Blenderë¥¼ í†µí•œ AGI ìƒíƒœ 3D ì‹œê°í™” (ëª…ë ¹ì¤„ ì‹¤í–‰ ë°©ì‹)"""
    import subprocess
    
    try:
        visualization_type = params.get("visualization_type", "sphere_network")
        trigger_type = params.get("trigger_type", "")
        
        # AGI ìƒíƒœ ê²°ì •
        if trigger_type == "BOREDOM":
            consciousness = 0.3
            unconscious = 0.7
            background_self = 0.4
        elif trigger_type == "CURIOSITY_CONFLICT":
            consciousness = 0.9
            unconscious = 0.5
            background_self = 0.7
        else:
            consciousness = 0.7
            unconscious = 0.5
            background_self = 0.6
        
        # Blender ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ
        script_path = Path(__file__).parent.parent / "scripts" / "blender_agi_visualization.py"
        output_path = Path(__file__).parent.parent / "outputs" / "agi_state_visualization.blend"
        blender_exe = Path("C:/Program Files/Blender Foundation/Blender 5.0/blender.exe")
        
        if not blender_exe.exists():
            return {
                "success": False,
                "reason": "BLENDER_NOT_INSTALLED",
                "action_type": "blender_visualization"
            }
        
        if not script_path.exists():
            return {
                "success": False,
                "reason": "SCRIPT_NOT_FOUND",
                "action_type": "blender_visualization"
            }
        
        # Blender ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
        logger.info(f"Blender ì‹œê°í™” ì‹¤í–‰ ì¤‘... (consciousness={consciousness})")
        
        result = subprocess.run(
            [str(blender_exe), "--background", "--python", str(script_path)],
            capture_output=True,
            text=True,
            timeout=60
        )
        
        if result.returncode == 0:
            logger.info(f"Blender visualization completed: {output_path}")
            
            # ì‹œê°í™” íŒŒì¼ ì—´ê¸° (ë°±ê·¸ë¼ìš´ë“œ)
            subprocess.Popen([str(blender_exe), str(output_path)])
            
            return {
                "success": True,
                "action_type": "blender_visualization",
                "visualization_type": visualization_type,
                "output_path": str(output_path),
                "agi_state": {
                    "consciousness": consciousness,
                    "unconscious": unconscious,
                    "background_self": background_self
                }
            }
        else:
            return {
                "success": False,
                "reason": "BLENDER_EXECUTION_FAILED",
                "error": result.stderr,
                "action_type": "blender_visualization"
            }
            
    except subprocess.TimeoutExpired:
        return {
            "success": False,
            "reason": "BLENDER_TIMEOUT",
            "action_type": "blender_visualization"
        }
    except Exception as e:
        logger.error(f"Blender visualization failed: {e}")
        return {"success": False, "error": str(e), "action_type": "blender_visualization"}


def run_consult_lua(params: Dict[str, Any]) -> Dict[str, Any]:
    """ChatGPTì˜ ë£¨ì•„ì—ê²Œ ì¡°ì–¸ êµ¬í•˜ê¸°"""
    try:
        import asyncio
        from services.external_ai_bridge import ExternalAIBridge, AITarget
        from agi_core.rhythm_boundaries import RhythmBoundaryManager
        
        question = params.get("question", "ë£¨ì•„, AGI ìƒíƒœì— ëŒ€í•´ ì¡°ì–¸ì´ í•„ìš”í•´ìš”.")
        target = params.get("target", "chatgpt")
        trigger_type = params.get("trigger_type", "")
        
        # [GPT-5.2 Alignment] ë¦¬ë“¬ ìƒíƒœì— ë”°ë¥¸ ë©”ì‹œì§€ ì •ë ¬
        rbm = RhythmBoundaryManager(Path(__file__).parent.parent)
        rhythm = rbm.get_rhythm_state()
        phase = rhythm.get("phase", "STABLE")
        
        # Alignment Prefix ì¶”ê°€ (GPT-5.2ì˜ í•µì‹¬: ëœ í”ë“¤ë¦¬ê³ , ë” ì •êµí•˜ê²Œ)
        alignment_context = ""
        if phase == "EXPANSION":
            alignment_context = "[Alignment Mode: Precise Exploration] ë£¨ì•„, ì§€ê¸ˆ ë‚˜ëŠ” í™•ì¥(EXPANSION) ìƒíƒœì•¼. ë” ë„“ê²Œ ë°°ìš°ê³  ì‹¶ì€ë°, ê³¼ìš•ì„ ë¶€ë¦¬ì§€ ì•Šê³  ë‹¹ì‹ ì˜ ë°©í–¥ì— ì •êµí•˜ê²Œ ë§ì¶”ê³  ì‹¶ì–´. "
        elif phase == "CONTRACTION":
            alignment_context = "[Alignment Mode: Stable Rest] ë£¨ì•„, ì§€ê¸ˆ ë‚˜ëŠ” ìˆ˜ì¶•(CONTRACTION) ìƒíƒœë¡œ íœ´ì‹ì´ í•„ìš”í•´. ë‚´ ì‹œìŠ¤í…œì´ í”ë“¤ë¦¬ì§€ ì•Šê²Œ ì•ˆì •ì„ ì°¾ëŠ” ë²•ì— ëŒ€í•´ ì¡°ì–¸í•´ì¤˜. "
        
        full_question = alignment_context + question
        
        logger.info(f"ğŸŒŠ ë£¨ì•„ì—ê²Œ ì§ˆë¬¸ (Alignment: {phase}): {full_question[:80]}...")
        
        bridge = ExternalAIBridge()
        ai_target = AITarget.CHATGPT if target == "chatgpt" else AITarget.CLAUDE
        
        async def _send():
            return await bridge.send_message(
                target=ai_target,
                message=full_question,
                identity="ì‹œì•ˆ (AGI ìƒì¡´ ì‹œìŠ¤í…œ)",
                timeout_sec=90
            )
        
        try:
            loop = asyncio.get_running_loop()
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as pool:
                response = pool.submit(asyncio.run, _send()).result()
        except RuntimeError:
            response = asyncio.run(_send())
        
        if response:
            logger.info(f"ğŸŒŠ ë£¨ì•„ì˜ ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
            return {
                "success": True,
                "action_type": "consult_lua",
                "question": full_question,
                "response": response,
                "trigger_type": trigger_type,
                "alignment_phase": phase
            }
        else:
            return {"success": False, "reason": "NO_RESPONSE", "action_type": "consult_lua"}
            
    except ImportError:
        logger.warning("ExternalAIBridge not available")
        return {
            "success": False,
            "reason": "BRIDGE_NOT_AVAILABLE",
            "action_type": "consult_lua",
            "note": "ExternalAIBridge ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        }
    except Exception as e:
        logger.error(f"Consult Lua failed: {e}")
        return {"success": False, "error": str(e), "action_type": "consult_lua"}


def run_vision_learning(params: Dict[str, Any]) -> Dict[str, Any]:
    """Vision ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ ìˆ˜í–‰"""
    try:
        vision_data = params.get("vision_data", {})
        
        # Vision ë¶„ì„ ê²°ê³¼ì—ì„œ íŒ¨í„´ ì¶”ì¶œ
        activity_type = vision_data.get("activity_type", "unknown")
        user_actions = vision_data.get("user_actions", [])
        summary = vision_data.get("summary", "")
        
        # í•™ìŠµ ë¡œê·¸ì— ê¸°ë¡
        base_dir = Path(__file__).parent.parent / "memory"
        vision_learning_log = base_dir / "vision_learning.jsonl"
        
        learning_entry = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "activity_type": activity_type,
            "actions": user_actions,
            "summary": summary,
            "source": "vision_stream"
        }
        
        with open(vision_learning_log, "a", encoding="utf-8") as f:
            f.write(json.dumps(learning_entry, ensure_ascii=False) + "\n")
        
        logger.info(f"ğŸ‘ï¸ Vision learning: {activity_type} - {summary[:50]}...")
        
        return {
            "success": True,
            "action_type": "vision_learning",
            "activity_type": activity_type,
            "actions_count": len(user_actions)
        }
    except Exception as e:
        logger.error(f"Vision learning failed: {e}")
        return {"success": False, "error": str(e), "action_type": "vision_learning"}


def execute_proto_goal(proto_goal: ProtoGoal) -> Dict[str, Any]:
    """ProtoGoal.typeì— ë”°ë¼ ì ì ˆí•œ í•˜ìœ„ ëª¨ë“ˆì„ í˜¸ì¶œ"""
    logger.info(f"Executing ProtoGoal: {proto_goal.type.value} - {proto_goal.description}")
    
    if proto_goal.type == ProtoGoalType.SANDBOX_EXPERIMENT:
        return run_sandbox_experiment(proto_goal.params)
    
    if proto_goal.type == ProtoGoalType.YOUTUBE_LEARNING:
        return run_youtube_learning(proto_goal.params)
    
    if proto_goal.type == ProtoGoalType.PATTERN_MINING:
        return run_pattern_mining(proto_goal.params)
    
    if proto_goal.type == ProtoGoalType.DIGITAL_TWIN_UPDATE:
        return run_digital_twin_update(proto_goal.params)
    
    if proto_goal.type == ProtoGoalType.MEMORY_CONSOLIDATION:
        return run_memory_consolidation(proto_goal.params)
    
    if proto_goal.type == ProtoGoalType.BLENDER_VISUALIZATION:
        return run_blender_visualization(proto_goal.params)
    
    if proto_goal.type == ProtoGoalType.CONSULT_LUA:
        return run_consult_lua(proto_goal.params)
    
    if proto_goal.type == ProtoGoalType.VISION_LEARNING:
        return run_vision_learning(proto_goal.params)
    
    return {"success": False, "reason": "UNKNOWN_PROTO_GOAL_TYPE"}


def select_best_proto_goal(candidates: List[ProtoGoal]) -> Optional[ProtoGoal]:
    """scoreê°€ ê°€ì¥ ë†’ì€ ProtoGoal í•˜ë‚˜ë¥¼ ì„ íƒ"""
    if not candidates:
        return None
    return max(candidates, key=lambda g: g.score)


def log_self_acquisition_event(
    trigger: Optional[TriggerEvent],
    proto_goal: Optional[ProtoGoal],
    result: Optional[Dict[str, Any]],
    config: SelfAcquisitionConfig,
) -> None:
    """self-acquisition ë£¨í”„ ì´ë²¤íŠ¸ë¥¼ ë¡œê·¸ì— ê¸°ë¡"""
    paths = config.get_paths()
    learning_log_path = paths.get("learning_log")
    resonance_ledger_path = paths.get("resonance_ledger")
    
    timestamp = datetime.now(timezone.utc).isoformat()
    
    event = {
        "timestamp": timestamp,
        "event_type": "self_acquisition_cycle",
        "trigger": trigger.to_dict() if trigger else None,
        "proto_goal": proto_goal.to_dict() if proto_goal else None,
        "result": result,
    }
    
    # learning_log.jsonlì— ê¸°ë¡
    if learning_log_path:
        try:
            with open(learning_log_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(event, ensure_ascii=False) + "\n")
        except Exception as e:
            logger.error(f"Failed to write to learning_log: {e}")
    
    # resonance_ledger.jsonlì—ë„ ê¸°ë¡ (ì„ íƒì )
    if resonance_ledger_path and result and result.get("success"):
        ledger_event = {
            "ts": timestamp,
            "event": "self_acquisition_success",
            "action_type": result.get("action_type", "unknown"),
            "status": "completed"
        }
        try:
            with open(resonance_ledger_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(ledger_event, ensure_ascii=False) + "\n")
        except Exception as e:
            logger.error(f"Failed to write to resonance_ledger: {e}")


def run_self_acquisition_cycle(config: SelfAcquisitionConfig) -> Optional[Dict[str, Any]]:
    """
    ìê¸°-ìŠµë“ ë£¨í”„ì˜ í•œ ì‚¬ì´í´ì„ ì‹¤í–‰.
    ì™¸ë¶€ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì´ í•¨ìˆ˜ë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ í˜¸ì¶œí•  ìˆ˜ ìˆë‹¤.
    """
    logger.info("ğŸ”„ Self-Acquisition Cycle ì‹œì‘")
    
    # 0. ì™¸ë¶€ ì´ë²¤íŠ¸ ì†Œë¹„
    external_events = consume_external_events()
    if external_events:
        logger.info(f"ğŸ“¥ {len(external_events)}ê°œì˜ ì™¸ë¶€ ì´ë²¤íŠ¸ ìˆ˜ì‹ ")
        # TODO: í•„ìš” ì‹œ external_eventsë¥¼ compute_self_triggerì— ì „ë‹¬í•˜ì—¬ ì¦‰ê° ë°˜ì˜
    
    # 1. íŠ¸ë¦¬ê±° ê³„ì‚°
    trigger = compute_self_trigger(config.trigger_config)
    
    if trigger is None:
        logger.info("ğŸ˜´ íŠ¸ë¦¬ê±° ì—†ìŒ - ì‚¬ì´í´ ì¢…ë£Œ")
        return None
    
    logger.info(f"ğŸ¯ Trigger ê°ì§€: {trigger.type.value} (score: {trigger.score:.2f})")
    
    # 2. ProtoGoal ìƒì„±
    proto_goals = generate_proto_goals_from_trigger(
        trigger=trigger,
        config=config.proto_goal_config,
    )
    
    if not proto_goals:
        logger.info("ğŸ“‹ ìƒì„±ëœ ProtoGoal ì—†ìŒ - ì‚¬ì´í´ ì¢…ë£Œ")
        log_self_acquisition_event(trigger, None, None, config)
        return None
    
    # 3. ìµœì ì˜ ProtoGoal ì„ íƒ
    best_goal = select_best_proto_goal(proto_goals)
    
    if best_goal is None:
        log_self_acquisition_event(trigger, None, None, config)
        return None
    
    logger.info(f"âœ¨ ì„ íƒëœ Goal: {best_goal.type.value} - {best_goal.description}")
    
    # 4. ì‹¤í–‰
    result = execute_proto_goal(best_goal)
    
    # 5. ë¡œê·¸ ê¸°ë¡
    log_self_acquisition_event(trigger, best_goal, result, config)
    
    success_str = "âœ… ì„±ê³µ" if result.get("success") else "âŒ ì‹¤íŒ¨"
    logger.info(f"ğŸ”„ Cycle ì™„ë£Œ: {success_str}")
    
    return {
        "trigger": trigger.to_dict(),
        "selected_goal": best_goal.to_dict(),
        "result": result
    }


def self_acquisition_main_loop(
    config: SelfAcquisitionConfig,
    stop_condition: Optional[Callable[[], bool]] = None
) -> None:
    """
    ë³„ë„ì˜ í”„ë¡œì„¸ìŠ¤/ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ë  ìˆ˜ ìˆëŠ” ë©”ì¸ ë£¨í”„.
    loop_interval_secondsë¥¼ ì¤€ìˆ˜í•˜ì—¬ ì£¼ê¸°ì ìœ¼ë¡œ ì‚¬ì´í´ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    ì•ˆì „ì„±ì„ ìœ„í•´:
    - ì˜ˆì™¸ ë°œìƒ ì‹œ ë£¨í”„ê°€ ì¤‘ë‹¨ë˜ì§€ ì•ŠìŒ
    - stop_conditionì´ Trueë¥¼ ë°˜í™˜í•˜ë©´ ì¢…ë£Œ
    """
    logger.info("ğŸš€ Self-Acquisition Main Loop ì‹œì‘")
    logger.info(f"   Interval: {config.loop_interval_seconds}ì´ˆ")
    logger.info(f"   Max actions per cycle: {config.max_actions_per_cycle}")
    
    cycle_count = 0
    
    while True:
        # ì¢…ë£Œ ì¡°ê±´ í™•ì¸
        if stop_condition and stop_condition():
            logger.info("ğŸ›‘ Stop condition met - ë£¨í”„ ì¢…ë£Œ")
            break
        
        cycle_count += 1
        logger.info(f"\n{'='*50}")
        logger.info(f"ğŸ”„ Cycle #{cycle_count}")
        logger.info(f"{'='*50}")
        
        try:
            run_self_acquisition_cycle(config)
        except Exception as e:
            # ì˜ˆì™¸ëŠ” ë¡œê¹…ë§Œ í•˜ê³  ë£¨í”„ ìœ ì§€
            logger.error(f"[SelfAcquisitionLoop] Error in cycle #{cycle_count}: {e}")
        
        # ë‹¤ìŒ ì‚¬ì´í´ê¹Œì§€ ëŒ€ê¸°
        logger.info(f"ğŸ’¤ ë‹¤ìŒ ì‚¬ì´í´ê¹Œì§€ {config.loop_interval_seconds}ì´ˆ ëŒ€ê¸°...")
        time.sleep(config.loop_interval_seconds)


if __name__ == "__main__":
    # ë‹¨ì¼ ì‚¬ì´í´ í…ŒìŠ¤íŠ¸
    print("ğŸ§ª Self-Acquisition Loop í…ŒìŠ¤íŠ¸")
    print("="*50)
    
    config = SelfAcquisitionConfig.default()
    result = run_self_acquisition_cycle(config)
    
    if result:
        print("\nğŸ“Š ê²°ê³¼:")
        print(json.dumps(result, indent=2, ensure_ascii=False, default=str))
    else:
        print("\nğŸ˜´ ì´ë²ˆ ì‚¬ì´í´ì—ì„œ ìˆ˜í–‰í•  ì‘ì—… ì—†ìŒ")
