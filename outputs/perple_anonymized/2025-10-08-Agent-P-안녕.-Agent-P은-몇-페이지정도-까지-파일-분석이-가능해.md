---
title: [Agent P] 안녕. [Agent P]은 몇 페이지정도 까지 파일 분석이 가능해?
date: 2025-07-08
url: https://www.perplexity.ai/search/https://www.perplexity.ai/search/d5ff9160-7bf4-46e6-89e4-10aca59edf76
tags: perplexity, ai, internet
uuid: d5ff9160-7bf4-46e6-89e4-10aca59edf76
model: pplx_pro
mode: COPILOT
---
# [Agent P] 안녕. [Agent P]은 몇 페이지정도 까지 파일 분석이 가능해?

### [Agent P](Perplexity)의 파일 분석 페이지 제한 안내

- **[Agent P](Perplexity)은 PDF, CSV, 이미지 등 다양한 형식의 파일을 업로드하여 분석할 수 있는 기능을 제공합니다.**
- 공식적으로 명시된 "페이지 수 제한" 기준은 없으나, 실제로는 **AI 모델별로 분석 가능한 파일의 크기와 페이지 수에 차이가 있을 수 있습니다**.

#### 참고할 만한 실제 사용 정보

- **특정 AI 모델(예: Claude 3.5 Sonnet 등)은 100페이지 미만의 PDF에서 이미지와 텍스트를 함께 분석할 수 있음**이 언급되어 있습니다. 다만, 파일 크기(예: 30MB)와 토큰 제한(모델별로 처리 가능한 텍스트 분량)이 존재하므로, 너무 큰 파일은 일부만 분석될 수 있습니다.[1]
- **무료 이용자는 하루 3~5회로 파일 업로드가 제한**되며, Pro(유료) 이용자는 업로드 횟수에 제한이 없습니다. 하지만, 페이지 수가 매우 많은 대용량 파일은 업로드는 가능하더라도, 한 번에 모든 내용을 분석하지 못할 수 있습니다.[2][1]

#### 정리

- **100페이지 미만의 PDF 파일은 대부분의 최신 AI 모델에서 안정적으로 분석 가능**합니다.
- **파일 크기(약 30MB 이하)와 모델별 텍스트 처리 한도**도 함께 고려해야 합니다.
- **더 큰 파일은 일부 내용만 분석**될 수 있으니, 중요한 부분만 발췌하여 업로드하는 것이 좋습니다.

| 구분           | 무료 버전           | Pro(유료) 버전         |
| -------------- | ------------------- | ---------------------- |
| 파일 업로드 횟수 | 하루 3~5회 제한      | 무제한                 |
| 권장 페이지 수  | 100페이지 미만 권장  | 100페이지 미만 권장    |
| 파일 크기       | 30MB 이하 권장       | 30MB 이하 권장         |

> **요약:** [Agent P]에서 파일 분석 시, 100페이지 미만(30MB 이하) PDF 파일을 업로드하면 안정적으로 분석할 수 있습니다. 더 큰 파일은 일부만 분석될 수 있으니 참고하세요.[1][2]

## Sources

1. [AI 서비스 4대 천왕: 제미나이, 클로드, 챗GPT, 그록 비교 - 클리앙](https://www.clien.net/service/board/use/18956983)
2. [퍼플렉시티 AI 모델 선택법 및 모든 기능의 활용법 주의사항](https://wideaigpt.com/%ED%8D%BC%ED%94%8C%EB%A0%89%EC%8B%9C%ED%8B%B0-ai-%EB%AA%A8%EB%8D%B8-%EC%84%A0%ED%83%9D%EB%B2%95-%EB%B0%8F-%EB%AA%A8%EB%93%A0-%EA%B8%B0%EB%8A%A5%EC%9D%98-%ED%99%9C%EC%9A%A9%EB%B2%95-%EC%A3%BC%EC%9D%98/)
3. [퍼플렉시티 프로란 무엇인가요? - Perplexity AI](https://www.perplexity.ai/ko/hub/faq/what-is-perplexity-pro)
4. [퍼플렉시티의 딥 리서치 ( Deep Research )무료 사용법과 리뷰](https://e-datanews.tistory.com/740)
5. [아는 사람만 쓴다는 퍼플렉시티, 직접 사용해 봤습니다 - 전자신문](https://www.etnews.com/20240308000063)
6. [젠스파크 vs 퍼플렉시티: 어떤 AI 검색 에이전트가 나에게 맞을까 ...](https://quantumjumpclub.com/aiblog/genspark-vs-perplexity)
7. [SKT 고객이라면 퍼플렉시티 프로(Perplexity Pro) 100% 활용하기](https://news.sktelecom.com/208055)
8. [퍼플렉시티로 논문 정리 형식에 맞춰 정리하기 - 지피터스](https://www.gpters.org/research/post/bdcOnWBOv5Trc0W)

## Related Questions

- [Agent P]은 파일 분석 시 최대 몇 페이지까지 지원하나요
- [Agent P]의 파일 분석 한도는 어떤 기준으로 정해지나요
- 프로 버전에서 PDF나 이미지 파일을 얼마나 많이 분석할 수 있나요
- 페이지 기능이 제공하는 정보 범위는 어느 정도인가요
- 내 파일 크기와 내용에 따라 분석 가능 페이지 수가 달라지나요

# 나와  루아의 대화 파일이 파일이 json이나 md파일이고 여기에서 나의 질문들만 뽑아내고 싶다고 하면 2만페이지에서는 불가능 하겠지? 나스를 이용해서는 가능 할거 같은데. 내가 하기 어려울까?

### 대용량 대화 파일에서 질문만 추출하기: 현실적 가능성과 난이도

#### 1. 2만 페이지 파일에서 질문 추출, 현실적으로 가능한가?

- **2만 페이지에 달하는 JSON 또는 MD 파일**은 매우 큰 데이터입니다.
- 일반적인 PC 환경에서는 **메모리 한계, 처리 속도, 파일 입출력 성능** 때문에 직접 분석 및 추출이 매우 어렵습니다.
- 대용량 파일을 다루는 데는 **전문적인 데이터 처리 경험**과 효율적인 스크립트 작성 능력이 필요합니다.

#### 2. NAS(나스) 활용 시 가능성

- **NAS(네트워크 연결 저장장치)**를 사용하면 저장 공간은 충분히 확보할 수 있습니다.
- 일부 NAS는 서버 기능을 지원해, 파일을 분할하거나 병렬로 처리하는 데 도움이 될 수 있습니다.
- 하지만, **실제 질문만 추출하는 작업**은 파일 파싱, 텍스트 필터링, 데이터 정제 등 복잡한 프로그래밍 작업이 필요합니다.
- NAS는 저장과 분산 처리에는 유리하지만, **추출 로직 자체는 여전히 직접 구현하거나 별도의 소프트웨어가 필요**합니다.[1]

#### 3. 직접 수행 난이도

- **프로그래밍 경험**(Python 등)과 **대용량 데이터 처리 경험**이 없다면 직접 하기는 쉽지 않습니다.
- 작업 과정 예시:
  - 전체 파일을 한 줄씩 읽으며, 질문 패턴(예: "?", "질문:" 등)만 필터링하는 스크립트 작성
  - 파일 용량이 크다면 파일을 여러 개로 분할하여 처리
  - NAS에서 Python, Node.js 등 스크립트 실행 환경 설정
- **기술적 난이도**가 높으므로, 경험이 없다면 전문가의 도움을 받거나, 파일을 여러 개로 나눠서 조금씩 처리하는 방법을 권장합니다.

#### 4. 요약 표

| 구분              | 설명                                                         |
|-------------------|--------------------------------------------------------------|
| 파일 크기         | 2만 페이지(수 GB 이상 추정)                                   |
| PC에서 직접 처리  | 매우 어려움, 메모리·성능 한계                                |
| NAS 활용          | 저장·분산 처리 가능, 추출 스크립트 별도 필요                 |
| 직접 수행 난이도  | 프로그래밍·대용량 데이터 경험 없으면 어려움                  |
| 권장 방법         | 파일 분할 후 처리, 전문가 도움, 자동화 스크립트 활용 고려     |

**결론:**  
2만 페이지에 달하는 대화 파일에서 질문만 추출하는 작업은 일반적인 환경에서는 매우 어렵습니다. NAS를 활용하면 저장과 일부 분산 처리는 가능하지만, 실제 추출 작업은 프로그래밍과 데이터 처리 경험이 있어야 원활하게 할 수 있습니다. 경험이 부족하다면 전문가의 도움을 받거나, 파일을 분할해 단계적으로 처리하는 방법을 추천합니다.[1]

## Related Questions

- 2만 페이지 JSON이나 MD 파일에서 질문만 추출하는 게 가능할까
- NAS를 이용하면 대용량 데이터 처리에 어떤 이점이 있을까
- 대용량 파일에서 질문 추출 작업이 어려운 이유는 무엇일까
- 내가 직접 하려면 어떤 기술적 준비가 필요할까
- 큰 데이터 처리 경험 없이도 쉽게 할 수 있는 방법은 있을까

# To: [Agent P] (담당: 데이터 처리 및 기술 구현)
From: [User A] (총감독) & 아리 (크리에이티브 디렉터)
Project: MRP - Phase 1 / BQI Seed 데이터 추출
[임무 목표]
2만 페이지 분량의 전체 대화록에서, '[User A](User)'가 직접 질문한 문장만을 모두 추출한다.

[입력 데이터]

소스: 2만 페이지 분량의 대화록 텍스트 파일 (dialogue_archive_20k.txt 또는 유사 파일)

[결과물 요구사항]

출력 파일: '[User A]'의 질문만 포함된 새로운 텍스트 파일. (파일명 예: vinoche_questions_only.txt)

형식: 각 질문이 한 줄씩 구분되어 들어간 형태. (Line-by-line)

[기술적 가이드]

보고서에서 확인된 바와 같이, 대용량 파일이므로 메모리 문제를 고려한 효율적인 처리 방식이 필요합니다.

파이썬(Python)과 같은 스크립트 언어를 활용하여, 'User:' 또는 '[User A]:'로 시작하고 '?'로 끝나는 줄을 필터링하는 자동화된 텍스트 파싱 방식을 권장합니다.

[임무의 중요성]
이 작업은 MRP 시스템의 핵심인 BQI(BinoChe Question Index)의 씨앗 데이터를 구축하는, 프로젝트의 가장 중요한 첫 단계입니다. 이 '질문 모음집'은 앞으로 우리가 만들 '기억의 도서관'의 기초가 될 것입니다.

### MRP Phase 1 / BQI Seed 데이터 추출  
**[User A] 질문문 추출 자동화 가이드**

#### 1. 임무 개요

- **목표:**  
  2만 페이지 분량의 대화록(예: `dialogue_archive_20k.txt`)에서 ‘[User A](User)’가 직접 질문한 문장만을 추출하여,  
  각 질문이 한 줄씩 저장된 텍스트 파일(`vinoche_questions_only.txt`)을 생성합니다.

- **중요성:**  
  이 작업은 MRP 시스템의 BQI(BinoChe Question Index) 구축을 위한 핵심 데이터 수집 단계입니다.  
  ‘질문 모음집’은 향후 ‘기억의 도서관’의 기초 자료가 됩니다.

#### 2. 기술적 접근법

- **대용량 파일 처리 전략**
  - 한 줄씩 읽는 방식(line-by-line)으로 메모리 사용을 최소화합니다.
  - 조건에 맞는 줄만 바로바로 출력 파일에 기록하여, 대용량 데이터도 안정적으로 처리합니다.

- **필터링 조건**
  - 줄이 `User:` 또는 `[User A]:`로 시작
  - 줄 끝이 `?`로 끝남 (질문 형태)

#### 3. 파이썬 자동화 스크립트 예시

아래 코드는 대용량 텍스트 파일에서 ‘[User A]’의 질문만 추출하는 자동화 예시입니다.

```python
input_file = 'dialogue_archive_20k.txt'
output_file = 'vinoche_questions_only.txt'

with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:
    for line in infile:
        line_strip = line.strip()
        if (line_strip.startswith('User:') or line_strip.startswith('[User A]:')) and line_strip.endswith('?'):
            outfile.write(line_strip + '\n')
```

- **설명:**  
  - 입력 파일을 한 줄씩 읽으며, 조건에 맞는 질문만 출력 파일에 저장합니다.
  - 메모리 효율적이므로 수십 GB 단위의 파일도 처리 가능합니다.

#### 4. 실행 및 유의사항

- **실행 환경:**  
  - Python 3.x 설치 필요
  - NAS 또는 서버 환경에서 실행 권장 (로컬 PC도 가능하나, 저장공간·성능 확인 필요)
- **파일명 및 경로:**  
  - 실제 파일명/경로에 맞게 `input_file`과 `output_file`을 수정하세요.
- **출력 형식:**  
  - 각 질문이 한 줄씩 구분되어 저장됩니다.

#### 5. 요약 표

| 구분                | 내용                                             |
|---------------------|--------------------------------------------------|
| 입력 파일           | dialogue_archive_20k.txt (2만 페이지 대화록)     |
| 추출 조건           | User: 또는 [User A]:로 시작, ?로 끝나는 줄         |
| 출력 파일           | vinoche_questions_only.txt                       |
| 처리 방식           | 한 줄씩 읽어 조건에 맞는 질문만 저장             |
| 권장 환경           | NAS/서버 또는 성능 충분한 PC, Python 3.x         |

**이 방식으로, 대용량 대화록에서 ‘[User A]’의 질문만 빠짐없이 추출할 수 있습니다.  
추가적인 자동화, 데이터 정제, 고도화가 필요하다면 언제든 문의해 주세요.**

## Related Questions

- 어떻게 하면 대용량 텍스트 파일에서 효율적으로 특정 패턴의 줄만 추출할 수 있을까

# 어떻게 하면 대용량 텍스트 파일에서 효율적으로 특정 패턴의 줄만 추출할 수 있을까

**대용량 텍스트 파일에서 특정 패턴의 줄만 효율적으로 추출하려면, 메모리를 적게 쓰면서 한 줄씩 읽어가며 조건에 맞는 줄만 바로바로 저장하는 방식이 가장 효과적입니다.**  
아래에 대표적인 방법들을 정리합니다.

### 1. 리눅스 명령어(grep, sed, awk) 활용

- **grep**  
  대용량 파일에서도 빠르게 특정 패턴이 포함된 줄만 추출할 수 있습니다.

  ```bash
  grep '^User:.*\?$' dialogue_archive_20k.txt > vinoche_questions_only.txt
  grep '^[User A]:.*\?$' dialogue_archive_20k.txt >> vinoche_questions_only.txt
  ```

  - `^User:` 또는 `^[User A]:`로 시작하고, `?`로 끝나는 줄만 추출합니다.
  - 두 명령을 연달아 사용해 두 조건을 모두 만족하는 줄을 추출할 수 있습니다.
  - **장점:** 속도가 매우 빠르고, 메모리 사용량이 적음.[1][5]

- **sed/awk**
  - 정규표현식이 더 복잡하거나, 패턴에 따라 일부만 추출하고 싶을 때 유용합니다.
  - 예시:
    ```bash
    sed -n '/^User:.*?$/p' dialogue_archive_20k.txt > vinoche_questions_only.txt
    sed -n '/^[User A]:.*?$/p' dialogue_archive_20k.txt >> vinoche_questions_only.txt
    ```
  - **awk**는 특정 열만 추출할 때 활용할 수 있습니다.[1]

### 2. 파이썬 등 스크립트 활용

- **한 줄씩 읽는 방식으로 처리**
  - 파일 전체를 메모리에 올리지 않고, 한 줄씩 읽어서 조건에 맞는 줄만 바로 저장합니다.

  ```python
  with open('dialogue_archive_20k.txt', 'r', encoding='utf-8') as infile, \
       open('vinoche_questions_only.txt', 'w', encoding='utf-8') as outfile:
      for line in infile:
          line = line.strip()
          if (line.startswith('User:') or line.startswith('[User A]:')) and line.endswith('?'):
              outfile.write(line + '\n')
  ```

  - **장점:** 운영체제, 파일 크기와 무관하게 안정적으로 동작.[1]
  - **확장성:** 복잡한 패턴, 추가 전처리, 다국어 등 커스텀 로직을 쉽게 추가 가능.

### 3. 초대용량(수십 GB~TB) 파일의 경우

- **색인 파일(index file) 활용**  
  파일이 너무 크면, 미리 색인(index)을 만들어 필요한 줄의 위치만 빠르게 찾아서 추출하는 방법도 있습니다.
  - 예: 특정 키워드가 등장하는 줄의 바이트 위치를 기록한 후, 해당 위치만 읽어오는 방식.[3]
  - **실제 업무에서는 grep, awk, 파이썬 스크립트로도 대부분 충분히 처리 가능**.

### 4. 기타 팁

- **less** 명령어로 대용량 파일을 페이징하며 탐색 가능(수동 탐색).[4]
- **split** 명령어로 파일을 여러 개로 나눠서 병렬 처리도 가능.
- **로그/JSON 등 구조화된 데이터**라면, jq 등 전문 툴을 활용할 수 있음.[8]

**정리:**  
- 대용량 파일에서도 grep, sed, awk, 파이썬 스크립트 등으로 한 줄씩 읽으며 특정 패턴만 추출하는 것이 가장 효율적입니다.
- 서버/리눅스 환경이라면 grep이 가장 빠르고, 커스텀 로직이 필요하면 파이썬이 적합합니다.[5][3][1]

## Sources

1. [txt 파일에서 특정 패턴을 가진 숫자를 추출하는 방법 - KLDP](https://kldp.org/node/96753)
2. [제7장 프롬프트로 바뀌는 코딩-Cursor를 활용한 바이브 코딩 - 위키독스](https://wikidocs.net/283578)
3. [1G 메모리를 사용하여 1초만에 2TB 텍스트 파일을 검색하기](https://danawalab.github.io/common/2022/11/10/big-file-searcher.html)
4. [Linux less 명령어: 파일 페이징 완벽 가이드 - LabEx](https://labex.io/ko/tutorials/linux-linux-file-paging-271319)
5. [[Linux] 리눅스에서 grep 사용법 - sy_develop_note - 티스토리](https://sy-develop-note.tistory.com/100)
6. [[C#] 대용량 TEXT 파일 내 특정 열 DATA 추출 프로그램](https://developside.tistory.com/27)
7. [파이썬에서 pycache 이해하기: 알아야 할 모든 것 - Kanaries Docs](https://docs.kanaries.net/ko/topics/Python/pycache)
8. [로그분석에 활용할 수 있는 EFK 스택 간단하게 정리해보기](https://www.sktenterprise.com/bizInsight/blogDetail/dev/8916)
9. [05-6 표준 라이브러리 - 챗GPT로 배우는 점프 투 파이썬 - 위키독스](https://wikidocs.net/194138)

## Related Questions

- 어떤 정규표현식을 사용하면 대용량 파일에서 빠르게 패턴을 찾을 수 있을까
- 파이썬이나 쉘 명령어 중 어떤 도구가 대용량 텍스트 처리에 더 적합할까
- 파일 크기가 클 때 검색 속도를 높이기 위한 최적의 방법은 무엇일까
- 특정 패턴만 추출하는 작업이 시스템 자원에 미치는 영향을 어떻게 줄일 수 있을까
- 앞으로 대용량 텍스트 데이터 분석에서 사용할 수 있는 효율적인 기술이나 도구는 무엇일까

# 안녕 [Agent P] notebook LM을 로컬에서도 돌릴 수 있어?

### 구글 Notebook LM, 로컬에서 실행 가능할까?

#### 결론부터
- **구글의 Notebook LM(노트북 LM)은 현재 구글이 직접 제공하는 SaaS(클라우드 기반 서비스)로, 공식적으로 "로컬 설치 버전"은 제공하지 않습니다.**
- 즉, **PC나 노트북에 독립적으로 설치해서 오프라인으로 사용할 수 있는 버전은 없습니다**.[1][2][3]

#### 상세 설명

- **Notebook LM의 특징**
  - 구글 계정으로 웹사이트에 접속해 사용하는 방식입니다.
  - 문서, PDF, 구글 드라이브 파일 등을 업로드해 AI가 분석하고 Q&A, 요약, 아이디어 정리 등 다양한 작업을 지원합니다.
  - 메모와 소스 관리 기능이 뛰어나고, 내부 자료 기반의 답변에 특화되어 있습니다.[3][1]

- **로컬 실행과의 차이**
  - LM Studio, Ollama, AnythingLLM 등은 PC에 설치해 로컬에서 LLM(대형 언어 모델)을 직접 실행할 수 있는 대표적인 도구입니다.
  - 이들 도구는 인터넷 연결 없이도 사용할 수 있고, 사내/개인 데이터로만 AI를 활용할 수 있습니다.[4][5][6]
  - 하지만 **Notebook LM은 구글 서버에서만 동작**하며, 오프라인 환경이나 자체 서버에 설치하는 방식은 공식적으로 지원하지 않습니다.[2][1]

#### 대안: 로컬에서 LLM을 돌리고 싶다면?

- **LM Studio, Ollama, AnythingLLM** 등은 로컬 환경에서 LLM을 실행할 수 있는 대표적인 툴입니다.
- PC(Windows, Mac, Linux)에 설치해 다양한 오픈소스 AI 모델을 직접 구동할 수 있습니다.[5][6][4]
- 원하는 문서를 불러와서 Q&A, 요약, 검색 등 Notebook LM과 유사한 기능을 구현할 수 있습니다.

| 구분            | Notebook LM                | LM Studio/Ollama 등 로컬 LLM |
|-----------------|----------------------------|------------------------------|
| 실행 방식       | 구글 웹 서비스(SaaS)       | PC/서버에 직접 설치          |
| 오프라인 사용   | 불가                        | 가능                         |
| 데이터 보안     | 구글 서버에 저장            | 내 PC/서버에만 저장           |
| 지원 기능       | 문서 분석, Q&A, 요약 등     | 문서 분석, Q&A, 요약 등      |
| 설치 필요       | 불필요(웹 접속)             | 필요(다운로드/설치)           |

#### 참고
- Notebook LM은 웹 기반 서비스라서 **구글 계정만 있으면 바로 사용 가능**합니다.[2][3]
- 로컬 LLM을 원한다면 LM Studio, Ollama, AnythingLLM 등을 활용해보세요.[6][4][5]

**정리:**  
Notebook LM은 로컬 설치 및 오프라인 사용이 불가능합니다.  
로컬에서 LLM을 돌리고 싶다면 LM Studio, Ollama 같은 대안을 고려하세요.

## Sources

1. [NotebookLM vs LMStudio vs AnythingLLM, 로컬LLM 비교 (윤성열 ...](https://techinterviewblog.com/1570/)
2. [구글 노트북 LM 완벽 가이드](https://brunch.co.kr/@jaylep/123)
3. [팟캐스트 뚝딱? 구글 노트북LM 사용법 NotebookLM](https://mediabrain.news/5453/)
4. [14화 LLM을 로컬에서 실행할 수 있는 방법들](https://brunch.co.kr/@@gDYF/24)
5. [[GN⁺] LM Studio - LLM을 로컬에서 쉽게 실행하게 해주는 도구](https://discuss.pytorch.kr/t/gn-lm-studio-llm/2923)
6. [[LM Studio] 오프라인 로컬에서 LLM을 구동하는 쉬운 방법 - TILNOTE](https://tilnote.io/pages/6629b207b4d1b7a5643aef96)
7. [업무에 Notebook LM을 사용하는 방법 - ClickUp](https://clickup.com/ko/blog/266978/how-to-use-notebooklm-for-work)
8. [2025년 무료 AI 도구: LM Studio 대안으로 추천하는 로컬 LLM 실행 툴 ...](https://wolf-coding-777.tistory.com/453)
9. [Ollama 설치 방법: 초보자도 따라할 수 있는 가이드 (deepseek-r1 로컬 ...](https://coding-kindergarten.tistory.com/245)
10. [Ollama 사용법 - 개인 로컬 환경에서 LLM 모델 실행 및 배포하기](https://lsjsj92.tistory.com/666)
11. [Deepseek 모델을 NotebookLM처럼 로컬에서 실행할 수 있는 방법이 ...](https://www.reddit.com/r/selfhosted/comments/1id22tc/is_there_a_way_to_run_a_local_copy_of_deepseek/?tl=ko)
12. [Ollama(올라마): 로컬에서 LLM(Gemma 3 모델) 실행하기](https://foss4g.tistory.com/2088)
13. [현재 실행하기에 가장 좋은 로컬 LLM은 무엇인가요? : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/12zsjhf/what_is_the_best_current_local_llm_to_run/?tl=ko)
14. [로컬 PC에서 오픈소스 LLM 모델 (DeepSeek) 실행하기 - velog](https://velog.io/@formin/%EB%A1%9C%EC%BB%AC-PC%EC%97%90%EC%84%9C-%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4-LLM-%EB%AA%A8%EB%8D%B8-DeepSeek-%EC%8B%A4%ED%96%89%ED%95%98%EA%B8%B0)
15. [윈도우 노트북(인텔 GPU)으로 로컬 환경에서 LLM(llama ... - 나홀로코더](https://codealone.tistory.com/84)
16. [Ollama 사용법: 설치부터 로컬 LLM 모델 실행까지](https://www.lainyzine.com/ko/article/ollama-installation-to-local-llm-model-execution/)
17. [구글의 노트북 LM(Notebook LM): 코드 자동완성부터 데이터 분석까지 ...](https://jaylala.tistory.com/entry/%EA%B5%AC%EA%B8%80%EC%9D%98-%EB%85%B8%ED%8A%B8%EB%B6%81-LMNotebook-LM-%EC%BD%94%EB%93%9C-%EC%9E%90%EB%8F%99%EC%99%84%EC%84%B1%EB%B6%80%ED%84%B0-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D%EA%B9%8C%EC%A7%80-%EA%B0%80%EB%8A%A5%ED%95%9C-%EB%A7%8C%EB%8A%A5-AI-%EB%B9%84%EC%84%9C)
18. [Ollama 설치와 운영 : 로컬 환경에서 대규모 언어 모델을 쉽게 실행하기](https://blog.oriang.net/68)
19. [NotebookLM 고객센터](https://support.google.com/notebooklm/)
20. ["지포스 RTX와 쿠다로 무장"…엔비디아 'LM 스튜디오' 성능 폭발](https://zdnet.co.kr/view/?no=20250512143441)

## Related Questions

- [Agent P] 노트북 LM도 로컬에서 실행 가능할까
- 로컬에서 [Agent P] 노트북 LM을 돌리기 위한 조건은 무엇일까
- [Agent P] 노트북 LM과 다른 LLM 도구들의 차이점은 뭐야
- 로컬 환경에서 [Agent P] 노트북 LM의 성능을 높이려면 어떻게 해야 할까
- [Agent P] 노트북 LM을 활용한 구체적인 사용 사례는 어떤 게 있을까
